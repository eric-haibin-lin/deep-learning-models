INFO:root:Namespace(batch_size=128, drop_rate=0.0, gpu=2, lr=0.1, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='baseline.2', save_period=10, save_plot_dir='baseline.2', wd=0.0001)
[04:50:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.475000 val=0.556600 loss=1.428843 time: 17.755856
INFO:root:[Epoch 1] train=0.667107 val=0.674800 loss=0.934694 time: 16.216874
INFO:root:[Epoch 2] train=0.735877 val=0.741800 loss=0.750755 time: 15.776850
INFO:root:[Epoch 3] train=0.770653 val=0.768800 loss=0.656115 time: 15.867879
INFO:root:[Epoch 4] train=0.798458 val=0.763200 loss=0.587961 time: 16.065907
INFO:root:[Epoch 5] train=0.811498 val=0.782900 loss=0.543427 time: 15.177185
INFO:root:[Epoch 6] train=0.823718 val=0.804400 loss=0.511773 time: 16.081914
INFO:root:[Epoch 7] train=0.831230 val=0.812600 loss=0.484515 time: 15.775398
INFO:root:[Epoch 8] train=0.841587 val=0.825500 loss=0.458883 time: 16.355581
INFO:root:[Epoch 9] train=0.847436 val=0.800300 loss=0.439735 time: 15.417604
INFO:root:[Epoch 10] train=0.850781 val=0.817100 loss=0.426165 time: 17.335214
INFO:root:[Epoch 11] train=0.860036 val=0.840200 loss=0.407302 time: 16.712250
INFO:root:[Epoch 12] train=0.864002 val=0.832900 loss=0.395741 time: 17.272942
INFO:root:[Epoch 13] train=0.868409 val=0.847000 loss=0.381331 time: 16.943287
INFO:root:[Epoch 14] train=0.871675 val=0.835700 loss=0.374912 time: 16.693502
INFO:root:[Epoch 15] train=0.871835 val=0.839600 loss=0.364521 time: 17.021790
INFO:root:[Epoch 16] train=0.877143 val=0.824100 loss=0.353448 time: 15.568451
INFO:root:[Epoch 17] train=0.879728 val=0.819400 loss=0.347587 time: 15.250825
INFO:root:[Epoch 18] train=0.881751 val=0.816900 loss=0.338112 time: 16.128922
INFO:root:[Epoch 19] train=0.886338 val=0.859000 loss=0.328143 time: 16.679027
INFO:root:[Epoch 20] train=0.887400 val=0.853500 loss=0.326620 time: 15.746605
INFO:root:[Epoch 21] train=0.888281 val=0.829000 loss=0.319439 time: 16.429094
INFO:root:[Epoch 22] train=0.889603 val=0.856700 loss=0.314001 time: 17.708703
INFO:root:[Epoch 23] train=0.892167 val=0.845200 loss=0.308541 time: 16.421324
INFO:root:[Epoch 24] train=0.894992 val=0.834500 loss=0.302638 time: 17.780222
INFO:root:[Epoch 25] train=0.895152 val=0.843400 loss=0.302671 time: 16.185669
INFO:root:[Epoch 26] train=0.897796 val=0.836200 loss=0.294000 time: 16.303313
INFO:root:[Epoch 27] train=0.898578 val=0.839700 loss=0.289418 time: 16.286514
INFO:root:[Epoch 28] train=0.898337 val=0.852100 loss=0.292826 time: 18.450669
INFO:root:[Epoch 29] train=0.900341 val=0.832000 loss=0.284212 time: 16.332981
INFO:root:[Epoch 30] train=0.901763 val=0.866400 loss=0.283788 time: 17.712935
INFO:root:[Epoch 31] train=0.901963 val=0.852400 loss=0.278458 time: 18.238798
INFO:root:[Epoch 32] train=0.903105 val=0.849400 loss=0.278359 time: 15.691983
INFO:root:[Epoch 33] train=0.904087 val=0.843700 loss=0.274819 time: 16.934431
INFO:root:[Epoch 34] train=0.905008 val=0.858100 loss=0.270777 time: 16.261772
INFO:root:[Epoch 35] train=0.904207 val=0.857000 loss=0.269304 time: 16.303422
INFO:root:[Epoch 36] train=0.906831 val=0.861100 loss=0.265698 time: 17.992657
INFO:root:[Epoch 37] train=0.907352 val=0.844500 loss=0.262478 time: 17.149551
INFO:root:[Epoch 38] train=0.908854 val=0.873400 loss=0.259954 time: 18.569943
INFO:root:[Epoch 39] train=0.909936 val=0.843500 loss=0.258655 time: 15.938432
INFO:root:[Epoch 40] train=0.910056 val=0.834700 loss=0.255267 time: 17.429517
INFO:root:[Epoch 41] train=0.911338 val=0.846000 loss=0.256390 time: 19.386244
INFO:root:[Epoch 42] train=0.911919 val=0.867100 loss=0.252593 time: 18.079634
INFO:root:[Epoch 43] train=0.910317 val=0.864900 loss=0.253969 time: 15.631733
INFO:root:[Epoch 44] train=0.909696 val=0.868200 loss=0.254169 time: 15.913316
INFO:root:[Epoch 45] train=0.911979 val=0.857400 loss=0.252229 time: 17.303894
INFO:root:[Epoch 46] train=0.914663 val=0.839600 loss=0.247391 time: 18.999526
INFO:root:[Epoch 47] train=0.914824 val=0.848500 loss=0.243146 time: 17.229932
INFO:root:[Epoch 48] train=0.913001 val=0.856600 loss=0.248110 time: 16.093405
INFO:root:[Epoch 49] train=0.913301 val=0.869600 loss=0.244570 time: 17.984767
INFO:root:[Epoch 50] train=0.915224 val=0.869600 loss=0.246172 time: 16.002079
INFO:root:[Epoch 51] train=0.913522 val=0.870600 loss=0.244111 time: 16.279731
INFO:root:[Epoch 52] train=0.917248 val=0.868000 loss=0.235985 time: 16.239216
INFO:root:[Epoch 53] train=0.913682 val=0.871600 loss=0.242287 time: 16.895887
INFO:root:[Epoch 54] train=0.915845 val=0.857800 loss=0.236970 time: 17.252493
INFO:root:[Epoch 55] train=0.916747 val=0.867400 loss=0.237217 time: 19.045113
INFO:root:[Epoch 56] train=0.917969 val=0.861000 loss=0.233764 time: 17.348924
INFO:root:[Epoch 57] train=0.915986 val=0.873100 loss=0.237655 time: 17.174773
INFO:root:[Epoch 58] train=0.918930 val=0.874700 loss=0.231022 time: 16.572542
INFO:root:[Epoch 59] train=0.918510 val=0.869500 loss=0.231946 time: 17.346105
INFO:root:[Epoch 60] train=0.918189 val=0.862900 loss=0.231846 time: 15.592430
INFO:root:[Epoch 61] train=0.919631 val=0.856000 loss=0.231839 time: 16.898839
INFO:root:[Epoch 62] train=0.919331 val=0.847500 loss=0.231391 time: 16.381085
INFO:root:[Epoch 63] train=0.920092 val=0.859000 loss=0.228094 time: 16.834493
INFO:root:[Epoch 64] train=0.922696 val=0.856000 loss=0.221727 time: 16.070297
INFO:root:[Epoch 65] train=0.918490 val=0.874900 loss=0.230168 time: 16.332849
INFO:root:[Epoch 66] train=0.921434 val=0.876300 loss=0.226810 time: 17.591240
INFO:root:[Epoch 67] train=0.922416 val=0.873700 loss=0.223516 time: 17.255519
INFO:root:[Epoch 68] train=0.921014 val=0.865900 loss=0.223439 time: 16.495650
INFO:root:[Epoch 69] train=0.921114 val=0.868100 loss=0.223401 time: 17.078511
INFO:root:[Epoch 70] train=0.922135 val=0.859200 loss=0.223380 time: 16.077189
INFO:root:[Epoch 71] train=0.923137 val=0.869700 loss=0.217191 time: 17.055204
INFO:root:[Epoch 72] train=0.922776 val=0.864400 loss=0.221416 time: 16.407122
INFO:root:[Epoch 73] train=0.921615 val=0.872900 loss=0.222430 time: 16.034712
INFO:root:[Epoch 74] train=0.923578 val=0.872000 loss=0.216268 time: 16.629567
INFO:root:[Epoch 75] train=0.923738 val=0.859300 loss=0.217189 time: 16.363212
INFO:root:[Epoch 76] train=0.924960 val=0.878500 loss=0.215740 time: 16.556634
INFO:root:[Epoch 77] train=0.923377 val=0.876200 loss=0.216987 time: 16.223587
INFO:root:[Epoch 78] train=0.925501 val=0.862800 loss=0.213943 time: 18.045284
INFO:root:[Epoch 79] train=0.924419 val=0.869300 loss=0.216745 time: 19.134452
INFO:root:[Epoch 80] train=0.925200 val=0.870500 loss=0.212422 time: 18.276006
INFO:root:[Epoch 81] train=0.924579 val=0.864200 loss=0.214875 time: 16.159503
INFO:root:[Epoch 82] train=0.924479 val=0.857500 loss=0.212804 time: 15.945910
INFO:root:[Epoch 83] train=0.924119 val=0.875600 loss=0.212847 time: 16.554480
INFO:root:[Epoch 84] train=0.925401 val=0.870100 loss=0.209541 time: 16.985284
INFO:root:[Epoch 85] train=0.925801 val=0.854000 loss=0.211210 time: 17.407412
INFO:root:[Epoch 86] train=0.925381 val=0.853000 loss=0.215186 time: 19.549828
INFO:root:[Epoch 87] train=0.925501 val=0.875600 loss=0.210517 time: 17.029520
INFO:root:[Epoch 88] train=0.926202 val=0.856700 loss=0.209998 time: 16.652685
INFO:root:[Epoch 89] train=0.926783 val=0.871300 loss=0.208870 time: 16.908960
INFO:root:[Epoch 90] train=0.926222 val=0.865800 loss=0.208462 time: 16.194809
INFO:root:[Epoch 91] train=0.925341 val=0.862800 loss=0.211684 time: 16.054469
INFO:root:[Epoch 92] train=0.924800 val=0.867900 loss=0.212063 time: 15.957089
INFO:root:[Epoch 93] train=0.926222 val=0.871300 loss=0.208026 time: 17.092164
INFO:root:[Epoch 94] train=0.927784 val=0.866100 loss=0.207398 time: 16.043072
INFO:root:[Epoch 95] train=0.926242 val=0.874700 loss=0.205451 time: 16.731590
INFO:root:[Epoch 96] train=0.926643 val=0.874500 loss=0.206527 time: 16.104199
INFO:root:[Epoch 97] train=0.928766 val=0.869700 loss=0.202443 time: 18.061925
INFO:root:[Epoch 98] train=0.928926 val=0.877800 loss=0.205890 time: 18.442297
INFO:root:[Epoch 99] train=0.926282 val=0.869700 loss=0.204927 time: 18.084145
INFO:root:[Epoch 100] train=0.957252 val=0.909400 loss=0.128295 time: 19.331273
INFO:root:[Epoch 101] train=0.966306 val=0.915400 loss=0.099967 time: 17.819018
INFO:root:[Epoch 102] train=0.969591 val=0.913600 loss=0.089949 time: 19.088704
INFO:root:[Epoch 103] train=0.972837 val=0.914400 loss=0.081282 time: 18.771185
INFO:root:[Epoch 104] train=0.973417 val=0.916600 loss=0.080568 time: 19.113355
INFO:root:[Epoch 105] train=0.975761 val=0.914600 loss=0.072508 time: 18.757329
INFO:root:[Epoch 106] train=0.976382 val=0.916300 loss=0.072745 time: 17.152383
INFO:root:[Epoch 107] train=0.976522 val=0.915500 loss=0.068922 time: 18.009517
INFO:root:[Epoch 108] train=0.979006 val=0.915300 loss=0.064821 time: 18.666762
INFO:root:[Epoch 109] train=0.979607 val=0.914000 loss=0.061943 time: 18.238450
INFO:root:[Epoch 110] train=0.980088 val=0.916000 loss=0.060433 time: 17.767448
INFO:root:[Epoch 111] train=0.981110 val=0.915700 loss=0.057252 time: 16.291898
INFO:root:[Epoch 112] train=0.980929 val=0.917100 loss=0.056319 time: 17.048711
INFO:root:[Epoch 113] train=0.982332 val=0.916100 loss=0.055025 time: 19.561503
INFO:root:[Epoch 114] train=0.982412 val=0.916300 loss=0.052711 time: 20.832981
INFO:root:[Epoch 115] train=0.983133 val=0.914800 loss=0.052439 time: 20.095141
INFO:root:[Epoch 116] train=0.983634 val=0.916400 loss=0.049732 time: 19.809189
INFO:root:[Epoch 117] train=0.984495 val=0.916200 loss=0.046740 time: 22.097050
INFO:root:[Epoch 118] train=0.984595 val=0.916400 loss=0.047252 time: 22.124029
INFO:root:[Epoch 119] train=0.985116 val=0.915200 loss=0.045778 time: 23.375601
INFO:root:[Epoch 120] train=0.985357 val=0.915800 loss=0.044213 time: 23.975522
INFO:root:[Epoch 121] train=0.985677 val=0.915300 loss=0.043406 time: 23.187102
INFO:root:[Epoch 122] train=0.986599 val=0.914700 loss=0.040741 time: 24.446623
INFO:root:[Epoch 123] train=0.986679 val=0.917100 loss=0.041539 time: 22.561533
INFO:root:[Epoch 124] train=0.987099 val=0.917500 loss=0.039246 time: 23.185078
INFO:root:[Epoch 125] train=0.987039 val=0.915100 loss=0.039120 time: 22.393624
INFO:root:[Epoch 126] train=0.988161 val=0.913900 loss=0.037597 time: 24.056570
INFO:root:[Epoch 127] train=0.986859 val=0.915400 loss=0.038675 time: 22.435552
INFO:root:[Epoch 128] train=0.988642 val=0.914100 loss=0.036378 time: 22.815932
INFO:root:[Epoch 129] train=0.988862 val=0.914600 loss=0.034555 time: 25.663522
INFO:root:[Epoch 130] train=0.988822 val=0.913800 loss=0.035873 time: 25.495174
INFO:root:[Epoch 131] train=0.989203 val=0.913400 loss=0.033959 time: 25.049779
INFO:root:[Epoch 132] train=0.989002 val=0.914000 loss=0.034774 time: 25.799226
INFO:root:[Epoch 133] train=0.989223 val=0.914400 loss=0.034411 time: 25.849052
INFO:root:[Epoch 134] train=0.988562 val=0.915200 loss=0.034117 time: 24.155076
INFO:root:[Epoch 135] train=0.989543 val=0.915300 loss=0.032754 time: 20.811932
INFO:root:[Epoch 136] train=0.989563 val=0.914300 loss=0.031728 time: 21.029394
INFO:root:[Epoch 137] train=0.990425 val=0.915300 loss=0.031103 time: 20.857343
INFO:root:[Epoch 138] train=0.990485 val=0.912700 loss=0.030229 time: 20.503614
INFO:root:[Epoch 139] train=0.990104 val=0.914600 loss=0.031454 time: 20.630377
INFO:root:[Epoch 140] train=0.990445 val=0.913400 loss=0.030275 time: 21.245829
INFO:root:[Epoch 141] train=0.991226 val=0.914500 loss=0.028265 time: 21.042815
INFO:root:[Epoch 142] train=0.991286 val=0.914300 loss=0.028360 time: 20.934786
INFO:root:[Epoch 143] train=0.990625 val=0.914900 loss=0.029012 time: 20.993423
INFO:root:[Epoch 144] train=0.990865 val=0.914000 loss=0.028434 time: 20.372458
INFO:root:[Epoch 145] train=0.990865 val=0.911900 loss=0.028777 time: 21.355886
INFO:root:[Epoch 146] train=0.991567 val=0.914700 loss=0.027661 time: 16.308393
INFO:root:[Epoch 147] train=0.991466 val=0.915600 loss=0.026937 time: 15.864952
INFO:root:[Epoch 148] train=0.990485 val=0.913200 loss=0.029029 time: 16.949626
INFO:root:[Epoch 149] train=0.990805 val=0.915000 loss=0.027943 time: 15.280829
INFO:root:[Epoch 150] train=0.993189 val=0.915500 loss=0.023223 time: 15.970741
INFO:root:[Epoch 151] train=0.994191 val=0.914600 loss=0.020426 time: 16.228315
INFO:root:[Epoch 152] train=0.994732 val=0.915100 loss=0.019895 time: 16.091560
INFO:root:[Epoch 153] train=0.994231 val=0.916300 loss=0.019863 time: 15.146018
INFO:root:[Epoch 154] train=0.994371 val=0.915500 loss=0.019817 time: 15.493126
INFO:root:[Epoch 155] train=0.994551 val=0.915300 loss=0.019998 time: 15.272342
INFO:root:[Epoch 156] train=0.994551 val=0.916100 loss=0.018675 time: 15.711249
INFO:root:[Epoch 157] train=0.994732 val=0.915600 loss=0.018441 time: 17.357641
INFO:root:[Epoch 158] train=0.994671 val=0.915100 loss=0.018491 time: 16.266119
INFO:root:[Epoch 159] train=0.995032 val=0.916100 loss=0.018529 time: 15.736411
INFO:root:[Epoch 160] train=0.995172 val=0.916700 loss=0.017483 time: 15.536090
INFO:root:[Epoch 161] train=0.994471 val=0.916500 loss=0.019589 time: 16.027817
INFO:root:[Epoch 162] train=0.994752 val=0.916500 loss=0.018828 time: 17.113263
INFO:root:[Epoch 163] train=0.995493 val=0.916400 loss=0.017608 time: 16.556309
INFO:root:[Epoch 164] train=0.995613 val=0.916900 loss=0.017405 time: 15.170982
INFO:root:[Epoch 165] train=0.995232 val=0.916200 loss=0.017222 time: 16.253937
INFO:root:[Epoch 166] train=0.995413 val=0.916100 loss=0.017563 time: 16.253280
INFO:root:[Epoch 167] train=0.995893 val=0.916700 loss=0.016646 time: 17.520220
INFO:root:[Epoch 168] train=0.995333 val=0.917300 loss=0.016823 time: 15.768814
INFO:root:[Epoch 169] train=0.995032 val=0.916100 loss=0.017777 time: 15.358310
INFO:root:[Epoch 170] train=0.995172 val=0.916900 loss=0.017277 time: 16.260723
INFO:root:[Epoch 171] train=0.995413 val=0.916200 loss=0.017400 time: 17.264468
INFO:root:[Epoch 172] train=0.995252 val=0.916100 loss=0.017291 time: 16.347357
INFO:root:[Epoch 173] train=0.995413 val=0.916700 loss=0.016562 time: 16.156496
INFO:root:[Epoch 174] train=0.995713 val=0.917000 loss=0.016616 time: 15.437534
INFO:root:[Epoch 175] train=0.995793 val=0.915900 loss=0.016900 time: 17.020276
INFO:root:[Epoch 176] train=0.995353 val=0.916600 loss=0.016875 time: 19.011777
INFO:root:[Epoch 177] train=0.995813 val=0.916800 loss=0.016034 time: 17.930207
INFO:root:[Epoch 178] train=0.995573 val=0.918100 loss=0.016631 time: 16.367403
INFO:root:[Epoch 179] train=0.995994 val=0.916700 loss=0.015788 time: 15.643106
INFO:root:[Epoch 180] train=0.995633 val=0.917100 loss=0.016077 time: 15.955028
INFO:root:[Epoch 181] train=0.995573 val=0.916500 loss=0.016756 time: 16.379745
INFO:root:[Epoch 182] train=0.995413 val=0.917300 loss=0.016823 time: 15.964768
INFO:root:[Epoch 183] train=0.995553 val=0.917800 loss=0.016416 time: 16.472252
INFO:root:[Epoch 184] train=0.995954 val=0.917800 loss=0.015812 time: 16.691006
INFO:root:[Epoch 185] train=0.995593 val=0.917000 loss=0.016083 time: 16.970272
INFO:root:[Epoch 186] train=0.996114 val=0.917600 loss=0.015518 time: 17.092328
INFO:root:[Epoch 187] train=0.996074 val=0.917000 loss=0.015606 time: 16.216541
INFO:root:[Epoch 188] train=0.996214 val=0.917100 loss=0.015278 time: 16.959722
INFO:root:[Epoch 189] train=0.996114 val=0.917400 loss=0.015354 time: 17.518066
INFO:root:[Epoch 190] train=0.996214 val=0.916700 loss=0.015292 time: 18.176388
INFO:root:[Epoch 191] train=0.995473 val=0.916600 loss=0.016044 time: 17.679799
INFO:root:[Epoch 192] train=0.995933 val=0.916600 loss=0.015301 time: 16.972672
INFO:root:[Epoch 193] train=0.996214 val=0.917200 loss=0.015126 time: 17.079898
INFO:root:[Epoch 194] train=0.996074 val=0.916800 loss=0.015300 time: 16.543375
INFO:root:[Epoch 195] train=0.996254 val=0.917500 loss=0.015196 time: 17.102715
INFO:root:[Epoch 196] train=0.996474 val=0.917200 loss=0.014817 time: 17.249885
INFO:root:[Epoch 197] train=0.996655 val=0.917200 loss=0.015048 time: 17.123143
INFO:root:[Epoch 198] train=0.996314 val=0.917800 loss=0.015047 time: 16.396285
INFO:root:[Epoch 199] train=0.995833 val=0.916200 loss=0.015775 time: 17.454925
