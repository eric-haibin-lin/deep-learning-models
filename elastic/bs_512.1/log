INFO:root:Namespace(batch_size=128, drop_rate=0.0, gpus='0,1,2,3', last_gamma=False, lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512.1', save_period=10, save_plot_dir='bs_512.1', wd=0.0001)
[01:27:40] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.107583 val=0.120100 loss=2.430298 time: 16.981271
INFO:root:[Epoch 1] train=0.169781 val=0.186100 loss=2.147203 time: 15.041845
INFO:root:[Epoch 2] train=0.249356 val=0.238800 loss=1.876864 time: 14.534495
INFO:root:[Epoch 3] train=0.355288 val=0.407100 loss=1.654949 time: 14.924273
INFO:root:[Epoch 4] train=0.484838 val=0.509900 loss=1.388695 time: 14.630323
INFO:root:[Epoch 5] train=0.595300 val=0.578300 loss=1.138030 time: 14.498356
INFO:root:[Epoch 6] train=0.660559 val=0.609400 loss=0.958784 time: 14.748943
INFO:root:[Epoch 7] train=0.705179 val=0.641400 loss=0.838364 time: 15.146062
INFO:root:[Epoch 8] train=0.739429 val=0.670700 loss=0.744947 time: 15.206503
INFO:root:[Epoch 9] train=0.767739 val=0.768800 loss=0.669848 time: 14.764280
INFO:root:[Epoch 10] train=0.783485 val=0.727500 loss=0.624028 time: 15.099408
INFO:root:[Epoch 11] train=0.798929 val=0.732400 loss=0.582220 time: 14.710307
INFO:root:[Epoch 12] train=0.813104 val=0.709200 loss=0.548553 time: 14.693594
INFO:root:[Epoch 13] train=0.822004 val=0.764100 loss=0.518756 time: 15.736701
INFO:root:[Epoch 14] train=0.829675 val=0.780600 loss=0.493302 time: 15.109922
INFO:root:[Epoch 15] train=0.836199 val=0.782500 loss=0.475163 time: 15.272373
INFO:root:[Epoch 16] train=0.840931 val=0.768400 loss=0.461038 time: 14.972342
INFO:root:[Epoch 17] train=0.849589 val=0.790600 loss=0.440194 time: 14.931754
INFO:root:[Epoch 18] train=0.853596 val=0.785700 loss=0.429183 time: 14.602670
INFO:root:[Epoch 19] train=0.857382 val=0.794300 loss=0.415115 time: 15.340842
INFO:root:[Epoch 20] train=0.862355 val=0.789300 loss=0.401095 time: 14.539278
INFO:root:[Epoch 21] train=0.863523 val=0.822400 loss=0.393574 time: 14.656580
INFO:root:[Epoch 22] train=0.867469 val=0.797800 loss=0.381088 time: 14.633214
INFO:root:[Epoch 23] train=0.870308 val=0.804900 loss=0.372786 time: 15.076175
INFO:root:[Epoch 24] train=0.873852 val=0.807600 loss=0.364732 time: 14.889499
INFO:root:[Epoch 25] train=0.876148 val=0.814900 loss=0.355825 time: 15.240394
INFO:root:[Epoch 26] train=0.876450 val=0.811200 loss=0.355524 time: 14.558238
INFO:root:[Epoch 27] train=0.882651 val=0.826300 loss=0.337348 time: 14.938629
INFO:root:[Epoch 28] train=0.883860 val=0.797700 loss=0.333882 time: 14.849032
INFO:root:[Epoch 29] train=0.885068 val=0.813200 loss=0.328342 time: 14.919088
INFO:root:[Epoch 30] train=0.888551 val=0.795900 loss=0.325648 time: 15.118410
INFO:root:[Epoch 31] train=0.889659 val=0.790700 loss=0.318194 time: 14.794353
INFO:root:[Epoch 32] train=0.888773 val=0.842800 loss=0.315860 time: 14.884982
INFO:root:[Epoch 33] train=0.890142 val=0.821700 loss=0.315109 time: 14.773626
INFO:root:[Epoch 34] train=0.894108 val=0.839200 loss=0.306610 time: 14.853613
INFO:root:[Epoch 35] train=0.894773 val=0.758300 loss=0.302495 time: 14.745469
INFO:root:[Epoch 36] train=0.896947 val=0.809500 loss=0.296042 time: 14.497771
INFO:root:[Epoch 37] train=0.897572 val=0.809600 loss=0.294585 time: 14.915375
INFO:root:[Epoch 38] train=0.897088 val=0.857600 loss=0.293160 time: 15.188066
INFO:root:[Epoch 39] train=0.897833 val=0.845600 loss=0.294276 time: 14.709270
INFO:root:[Epoch 40] train=0.899122 val=0.824100 loss=0.287497 time: 15.141289
INFO:root:[Epoch 41] train=0.902767 val=0.835800 loss=0.281485 time: 15.052877
INFO:root:[Epoch 42] train=0.903471 val=0.839800 loss=0.278395 time: 15.124385
INFO:root:[Epoch 43] train=0.903914 val=0.837700 loss=0.275831 time: 14.678642
INFO:root:[Epoch 44] train=0.906008 val=0.845300 loss=0.275347 time: 15.518576
INFO:root:[Epoch 45] train=0.908022 val=0.848400 loss=0.266656 time: 15.125301
INFO:root:[Epoch 46] train=0.904116 val=0.839200 loss=0.273819 time: 15.069195
INFO:root:[Epoch 47] train=0.907116 val=0.855300 loss=0.264337 time: 14.833224
INFO:root:[Epoch 48] train=0.908082 val=0.842700 loss=0.263087 time: 15.555258
INFO:root:[Epoch 49] train=0.909673 val=0.854400 loss=0.258904 time: 14.573828
INFO:root:[Epoch 50] train=0.909693 val=0.832000 loss=0.262840 time: 14.646702
INFO:root:[Epoch 51] train=0.910458 val=0.837400 loss=0.257101 time: 14.763932
INFO:root:[Epoch 52] train=0.910861 val=0.849500 loss=0.254525 time: 15.388560
INFO:root:[Epoch 53] train=0.911385 val=0.833500 loss=0.254595 time: 15.077332
INFO:root:[Epoch 54] train=0.912492 val=0.841000 loss=0.248954 time: 14.620899
INFO:root:[Epoch 55] train=0.912895 val=0.847600 loss=0.248121 time: 15.230214
INFO:root:[Epoch 56] train=0.916902 val=0.854800 loss=0.241940 time: 15.344417
INFO:root:[Epoch 57] train=0.912834 val=0.801800 loss=0.248652 time: 14.888687
INFO:root:[Epoch 58] train=0.914727 val=0.849200 loss=0.243768 time: 14.728941
INFO:root:[Epoch 59] train=0.913861 val=0.864500 loss=0.243167 time: 15.403696
INFO:root:[Epoch 60] train=0.917284 val=0.845100 loss=0.238913 time: 15.053214
INFO:root:[Epoch 61] train=0.915593 val=0.854100 loss=0.241450 time: 15.059861
INFO:root:[Epoch 62] train=0.915794 val=0.820000 loss=0.239926 time: 15.335526
INFO:root:[Epoch 63] train=0.914203 val=0.849500 loss=0.243432 time: 14.897230
INFO:root:[Epoch 64] train=0.917103 val=0.836200 loss=0.235680 time: 15.232051
INFO:root:[Epoch 65] train=0.918593 val=0.857200 loss=0.235073 time: 14.905117
INFO:root:[Epoch 66] train=0.916056 val=0.858100 loss=0.237801 time: 15.015925
INFO:root:[Epoch 67] train=0.918814 val=0.806700 loss=0.232837 time: 15.144950
INFO:root:[Epoch 68] train=0.918976 val=0.853200 loss=0.230756 time: 14.643747
INFO:root:[Epoch 69] train=0.919418 val=0.848500 loss=0.232471 time: 15.511810
INFO:root:[Epoch 70] train=0.919539 val=0.834800 loss=0.231047 time: 15.073260
INFO:root:[Epoch 71] train=0.920264 val=0.853700 loss=0.227946 time: 15.485863
INFO:root:[Epoch 72] train=0.921150 val=0.839800 loss=0.226283 time: 15.091040
INFO:root:[Epoch 73] train=0.920949 val=0.860100 loss=0.224926 time: 14.822923
INFO:root:[Epoch 74] train=0.919801 val=0.845800 loss=0.225095 time: 15.190529
INFO:root:[Epoch 75] train=0.921311 val=0.765500 loss=0.227156 time: 14.672484
INFO:root:[Epoch 76] train=0.921573 val=0.848200 loss=0.224317 time: 15.041948
INFO:root:[Epoch 77] train=0.920828 val=0.835200 loss=0.226184 time: 15.459275
INFO:root:[Epoch 78] train=0.923224 val=0.855600 loss=0.219582 time: 14.817239
INFO:root:[Epoch 79] train=0.922036 val=0.829600 loss=0.222176 time: 15.468755
INFO:root:[Epoch 80] train=0.921573 val=0.830500 loss=0.220499 time: 15.042242
INFO:root:[Epoch 81] train=0.922640 val=0.848700 loss=0.221027 time: 14.903701
INFO:root:[Epoch 82] train=0.922439 val=0.842700 loss=0.219872 time: 14.561735
INFO:root:[Epoch 83] train=0.924191 val=0.817500 loss=0.217525 time: 15.419445
INFO:root:[Epoch 84] train=0.920466 val=0.816400 loss=0.222560 time: 14.852506
INFO:root:[Epoch 85] train=0.924956 val=0.853300 loss=0.215229 time: 14.691218
INFO:root:[Epoch 86] train=0.923083 val=0.825400 loss=0.217072 time: 14.780002
INFO:root:[Epoch 87] train=0.926687 val=0.849500 loss=0.211705 time: 14.708214
INFO:root:[Epoch 88] train=0.925600 val=0.827200 loss=0.214082 time: 14.723248
INFO:root:[Epoch 89] train=0.926023 val=0.823900 loss=0.211529 time: 15.123044
INFO:root:[Epoch 90] train=0.924110 val=0.853600 loss=0.217432 time: 14.824595
INFO:root:[Epoch 91] train=0.924493 val=0.836100 loss=0.213742 time: 14.987550
INFO:root:[Epoch 92] train=0.927312 val=0.865800 loss=0.212092 time: 14.932494
INFO:root:[Epoch 93] train=0.928157 val=0.850400 loss=0.204933 time: 14.834090
INFO:root:[Epoch 94] train=0.926003 val=0.844700 loss=0.212033 time: 15.075799
INFO:root:[Epoch 95] train=0.926305 val=0.844600 loss=0.209405 time: 15.081298
INFO:root:[Epoch 96] train=0.925238 val=0.838100 loss=0.210873 time: 14.853379
INFO:root:[Epoch 97] train=0.925137 val=0.855700 loss=0.211252 time: 14.860728
INFO:root:[Epoch 98] train=0.927070 val=0.873700 loss=0.208091 time: 15.224629
INFO:root:[Epoch 99] train=0.928137 val=0.871400 loss=0.205736 time: 14.655101
INFO:root:[Epoch 100] train=0.953890 val=0.910400 loss=0.134050 time: 14.981048
INFO:root:[Epoch 101] train=0.964058 val=0.912200 loss=0.105849 time: 15.051706
INFO:root:[Epoch 102] train=0.969213 val=0.913500 loss=0.092888 time: 14.762672
INFO:root:[Epoch 103] train=0.971247 val=0.911400 loss=0.087304 time: 14.841684
INFO:root:[Epoch 104] train=0.973260 val=0.914700 loss=0.080530 time: 14.854587
INFO:root:[Epoch 105] train=0.974630 val=0.914400 loss=0.075303 time: 15.545478
INFO:root:[Epoch 106] train=0.975173 val=0.915800 loss=0.074372 time: 14.431715
INFO:root:[Epoch 107] train=0.975294 val=0.913600 loss=0.072406 time: 14.756173
INFO:root:[Epoch 108] train=0.977328 val=0.914000 loss=0.068153 time: 14.902534
INFO:root:[Epoch 109] train=0.978657 val=0.916300 loss=0.064750 time: 15.182940
INFO:root:[Epoch 110] train=0.980046 val=0.915700 loss=0.061564 time: 14.962475
INFO:root:[Epoch 111] train=0.980006 val=0.910700 loss=0.058784 time: 14.990190
INFO:root:[Epoch 112] train=0.981033 val=0.915100 loss=0.058547 time: 14.769589
INFO:root:[Epoch 113] train=0.981496 val=0.914300 loss=0.055503 time: 14.797859
INFO:root:[Epoch 114] train=0.982019 val=0.915400 loss=0.054882 time: 14.951317
INFO:root:[Epoch 115] train=0.982986 val=0.914000 loss=0.050946 time: 14.797398
INFO:root:[Epoch 116] train=0.982704 val=0.913600 loss=0.050754 time: 15.457026
INFO:root:[Epoch 117] train=0.983227 val=0.911700 loss=0.050149 time: 14.817995
INFO:root:[Epoch 118] train=0.983066 val=0.916700 loss=0.050155 time: 14.598801
INFO:root:[Epoch 119] train=0.984999 val=0.915800 loss=0.045921 time: 15.439700
INFO:root:[Epoch 120] train=0.985362 val=0.915200 loss=0.044339 time: 14.893273
INFO:root:[Epoch 121] train=0.983227 val=0.916900 loss=0.048653 time: 14.958075
INFO:root:[Epoch 122] train=0.986167 val=0.915000 loss=0.042933 time: 15.122070
INFO:root:[Epoch 123] train=0.986147 val=0.912600 loss=0.041579 time: 15.046436
INFO:root:[Epoch 124] train=0.984979 val=0.913900 loss=0.044363 time: 14.977530
INFO:root:[Epoch 125] train=0.986429 val=0.911400 loss=0.041562 time: 14.833903
INFO:root:[Epoch 126] train=0.986872 val=0.916100 loss=0.040628 time: 15.137639
INFO:root:[Epoch 127] train=0.986308 val=0.915400 loss=0.040478 time: 15.093595
INFO:root:[Epoch 128] train=0.986650 val=0.914700 loss=0.039540 time: 15.242923
INFO:root:[Epoch 129] train=0.987234 val=0.914000 loss=0.038553 time: 14.982682
INFO:root:[Epoch 130] train=0.987758 val=0.913400 loss=0.037265 time: 14.810832
INFO:root:[Epoch 131] train=0.988019 val=0.912100 loss=0.035966 time: 15.117357
INFO:root:[Epoch 132] train=0.988503 val=0.912700 loss=0.035053 time: 15.196566
INFO:root:[Epoch 133] train=0.987436 val=0.910600 loss=0.037179 time: 14.994165
INFO:root:[Epoch 134] train=0.988543 val=0.912700 loss=0.034695 time: 14.419132
INFO:root:[Epoch 135] train=0.988724 val=0.914500 loss=0.034055 time: 15.200582
INFO:root:[Epoch 136] train=0.988322 val=0.913400 loss=0.034665 time: 15.129959
INFO:root:[Epoch 137] train=0.989207 val=0.913600 loss=0.033626 time: 15.094586
INFO:root:[Epoch 138] train=0.988986 val=0.912300 loss=0.033420 time: 14.999241
INFO:root:[Epoch 139] train=0.990093 val=0.910800 loss=0.031461 time: 14.728184
INFO:root:[Epoch 140] train=0.989771 val=0.915300 loss=0.030656 time: 14.622061
INFO:root:[Epoch 141] train=0.989127 val=0.913600 loss=0.032182 time: 14.925323
INFO:root:[Epoch 142] train=0.989671 val=0.911400 loss=0.031148 time: 15.061298
INFO:root:[Epoch 143] train=0.989852 val=0.914000 loss=0.030410 time: 15.368359
INFO:root:[Epoch 144] train=0.990295 val=0.911100 loss=0.029865 time: 14.906272
INFO:root:[Epoch 145] train=0.990073 val=0.911400 loss=0.030702 time: 15.319406
INFO:root:[Epoch 146] train=0.989912 val=0.913400 loss=0.030323 time: 15.504748
INFO:root:[Epoch 147] train=0.990617 val=0.910000 loss=0.029702 time: 15.044257
INFO:root:[Epoch 148] train=0.991181 val=0.912500 loss=0.027865 time: 14.947492
INFO:root:[Epoch 149] train=0.989650 val=0.909900 loss=0.031696 time: 15.090959
INFO:root:[Epoch 150] train=0.991946 val=0.915200 loss=0.025333 time: 14.860934
INFO:root:[Epoch 151] train=0.993939 val=0.914900 loss=0.021542 time: 14.977994
INFO:root:[Epoch 152] train=0.993818 val=0.915500 loss=0.021069 time: 15.391760
INFO:root:[Epoch 153] train=0.994120 val=0.916600 loss=0.020012 time: 14.822798
INFO:root:[Epoch 154] train=0.994745 val=0.917100 loss=0.019387 time: 14.964211
INFO:root:[Epoch 155] train=0.994161 val=0.916200 loss=0.020205 time: 14.928726
INFO:root:[Epoch 156] train=0.994161 val=0.916800 loss=0.019714 time: 15.187756
INFO:root:[Epoch 157] train=0.995027 val=0.916300 loss=0.018586 time: 14.961033
INFO:root:[Epoch 158] train=0.994604 val=0.916900 loss=0.019312 time: 14.963274
INFO:root:[Epoch 159] train=0.995288 val=0.916400 loss=0.018129 time: 14.699155
INFO:root:[Epoch 160] train=0.995228 val=0.917100 loss=0.018267 time: 14.890302
INFO:root:[Epoch 161] train=0.995409 val=0.916700 loss=0.017581 time: 15.449923
INFO:root:[Epoch 162] train=0.994644 val=0.916700 loss=0.019227 time: 15.401964
INFO:root:[Epoch 163] train=0.995308 val=0.916400 loss=0.018025 time: 15.443129
INFO:root:[Epoch 164] train=0.995027 val=0.917800 loss=0.017986 time: 15.155453
INFO:root:[Epoch 165] train=0.994966 val=0.917100 loss=0.018413 time: 14.895484
INFO:root:[Epoch 166] train=0.995490 val=0.916500 loss=0.016819 time: 15.381953
INFO:root:[Epoch 167] train=0.995027 val=0.918200 loss=0.018164 time: 15.121195
INFO:root:[Epoch 168] train=0.995208 val=0.917800 loss=0.017927 time: 14.954315
INFO:root:[Epoch 169] train=0.995550 val=0.917100 loss=0.016578 time: 15.947099
INFO:root:[Epoch 170] train=0.995611 val=0.918100 loss=0.016367 time: 14.528337
INFO:root:[Epoch 171] train=0.995792 val=0.917600 loss=0.015782 time: 14.899456
INFO:root:[Epoch 172] train=0.995852 val=0.917600 loss=0.016226 time: 15.375385
INFO:root:[Epoch 173] train=0.995550 val=0.917600 loss=0.016783 time: 14.884084
INFO:root:[Epoch 174] train=0.995711 val=0.917300 loss=0.016059 time: 15.474140
INFO:root:[Epoch 175] train=0.995812 val=0.917500 loss=0.015925 time: 15.175535
INFO:root:[Epoch 176] train=0.995510 val=0.916700 loss=0.016338 time: 15.012835
INFO:root:[Epoch 177] train=0.995651 val=0.916400 loss=0.015941 time: 15.090208
INFO:root:[Epoch 178] train=0.995409 val=0.917300 loss=0.016742 time: 15.102486
INFO:root:[Epoch 179] train=0.995691 val=0.917500 loss=0.016472 time: 15.930538
INFO:root:[Epoch 180] train=0.995731 val=0.916800 loss=0.016271 time: 15.127664
INFO:root:[Epoch 181] train=0.995973 val=0.916200 loss=0.015770 time: 15.249321
INFO:root:[Epoch 182] train=0.995993 val=0.916300 loss=0.015394 time: 14.962125
INFO:root:[Epoch 183] train=0.995570 val=0.916800 loss=0.016307 time: 14.938492
INFO:root:[Epoch 184] train=0.995711 val=0.917100 loss=0.016092 time: 15.025551
INFO:root:[Epoch 185] train=0.996013 val=0.916700 loss=0.015685 time: 15.013242
INFO:root:[Epoch 186] train=0.996013 val=0.917700 loss=0.015355 time: 15.541146
INFO:root:[Epoch 187] train=0.995590 val=0.916800 loss=0.015665 time: 14.926948
INFO:root:[Epoch 188] train=0.996053 val=0.916300 loss=0.015674 time: 15.258183
INFO:root:[Epoch 189] train=0.995973 val=0.916800 loss=0.015562 time: 15.469923
INFO:root:[Epoch 190] train=0.996235 val=0.915900 loss=0.015040 time: 14.786203
INFO:root:[Epoch 191] train=0.995590 val=0.916800 loss=0.015660 time: 14.917348
INFO:root:[Epoch 192] train=0.995671 val=0.916800 loss=0.015783 time: 14.731212
INFO:root:[Epoch 193] train=0.996275 val=0.916200 loss=0.015541 time: 15.459220
INFO:root:[Epoch 194] train=0.996235 val=0.917500 loss=0.014901 time: 15.537726
INFO:root:[Epoch 195] train=0.996275 val=0.917500 loss=0.014676 time: 15.902461
INFO:root:[Epoch 196] train=0.995792 val=0.918400 loss=0.015468 time: 16.134691
INFO:root:[Epoch 197] train=0.996436 val=0.916200 loss=0.014441 time: 15.571486
INFO:root:[Epoch 198] train=0.996194 val=0.916900 loss=0.015053 time: 16.428461
INFO:root:[Epoch 199] train=0.996295 val=0.917300 loss=0.014448 time: 16.250945
