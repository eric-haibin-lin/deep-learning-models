INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='2', lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1.0', save_period=10, save_plot_dir='bs_512_gpu_1.0', wd=0.0001)
[07:06:09] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.196098 val=0.225000 loss=2.217660 time: 17.200169
INFO:root:[Epoch 1] train=0.314453 val=0.349000 loss=1.764873 time: 16.259466
INFO:root:[Epoch 2] train=0.425761 val=0.401100 loss=1.528623 time: 16.227649
INFO:root:[Epoch 3] train=0.524021 val=0.459500 loss=1.305952 time: 15.985412
INFO:root:[Epoch 4] train=0.602207 val=0.512800 loss=1.110084 time: 16.015162
INFO:root:[Epoch 5] train=0.657659 val=0.644900 loss=0.963827 time: 15.985723
INFO:root:[Epoch 6] train=0.705682 val=0.666200 loss=0.833489 time: 16.370322
INFO:root:[Epoch 7] train=0.739469 val=0.683100 loss=0.741046 time: 16.626922
INFO:root:[Epoch 8] train=0.762907 val=0.741800 loss=0.680611 time: 16.762070
INFO:root:[Epoch 9] train=0.780102 val=0.682900 loss=0.631006 time: 16.895469
INFO:root:[Epoch 10] train=0.792123 val=0.730400 loss=0.592182 time: 16.515650
INFO:root:[Epoch 11] train=0.805372 val=0.777200 loss=0.559180 time: 16.950092
INFO:root:[Epoch 12] train=0.813869 val=0.772900 loss=0.532950 time: 16.447001
INFO:root:[Epoch 13] train=0.821158 val=0.769900 loss=0.513345 time: 16.924191
INFO:root:[Epoch 14] train=0.829253 val=0.786600 loss=0.493263 time: 17.017275
INFO:root:[Epoch 15] train=0.835253 val=0.791600 loss=0.470401 time: 17.070228
INFO:root:[Epoch 16] train=0.840468 val=0.759500 loss=0.457653 time: 17.253457
INFO:root:[Epoch 17] train=0.848562 val=0.791000 loss=0.438252 time: 16.967168
INFO:root:[Epoch 18] train=0.852227 val=0.789400 loss=0.426973 time: 17.095263
INFO:root:[Epoch 19] train=0.855529 val=0.822500 loss=0.414636 time: 17.074192
INFO:root:[Epoch 20] train=0.861026 val=0.783800 loss=0.402762 time: 17.237720
INFO:root:[Epoch 21] train=0.862536 val=0.780200 loss=0.396092 time: 16.741176
INFO:root:[Epoch 22] train=0.864932 val=0.794000 loss=0.389151 time: 16.798380
INFO:root:[Epoch 23] train=0.869443 val=0.828600 loss=0.377441 time: 17.069573
INFO:root:[Epoch 24] train=0.873852 val=0.825900 loss=0.366979 time: 16.917725
INFO:root:[Epoch 25] train=0.875604 val=0.773600 loss=0.360362 time: 17.009694
INFO:root:[Epoch 26] train=0.877275 val=0.783700 loss=0.354053 time: 16.787483
INFO:root:[Epoch 27] train=0.880175 val=0.779000 loss=0.345832 time: 16.754711
INFO:root:[Epoch 28] train=0.881947 val=0.804900 loss=0.338590 time: 16.974505
INFO:root:[Epoch 29] train=0.881745 val=0.833700 loss=0.337367 time: 16.685509
INFO:root:[Epoch 30] train=0.888289 val=0.804000 loss=0.322834 time: 17.003547
INFO:root:[Epoch 31] train=0.886296 val=0.816200 loss=0.324754 time: 17.389751
INFO:root:[Epoch 32] train=0.889397 val=0.795700 loss=0.316228 time: 16.811175
INFO:root:[Epoch 33] train=0.888007 val=0.764500 loss=0.318666 time: 16.915121
INFO:root:[Epoch 34] train=0.892236 val=0.776800 loss=0.310680 time: 16.794333
INFO:root:[Epoch 35] train=0.891934 val=0.825800 loss=0.308988 time: 17.144590
INFO:root:[Epoch 36] train=0.896746 val=0.823800 loss=0.299345 time: 17.118469
INFO:root:[Epoch 37] train=0.896947 val=0.844200 loss=0.296490 time: 16.948695
INFO:root:[Epoch 38] train=0.898216 val=0.818000 loss=0.290265 time: 16.954220
INFO:root:[Epoch 39] train=0.898417 val=0.837600 loss=0.289592 time: 17.140833
INFO:root:[Epoch 40] train=0.898880 val=0.828800 loss=0.287694 time: 16.856760
INFO:root:[Epoch 41] train=0.901377 val=0.825700 loss=0.283969 time: 16.709956
INFO:root:[Epoch 42] train=0.902565 val=0.828200 loss=0.275922 time: 15.642457
INFO:root:[Epoch 43] train=0.902746 val=0.839600 loss=0.281064 time: 15.955716
INFO:root:[Epoch 44] train=0.903512 val=0.856600 loss=0.275311 time: 16.218310
INFO:root:[Epoch 45] train=0.904599 val=0.812800 loss=0.268906 time: 15.999961
INFO:root:[Epoch 46] train=0.905324 val=0.845200 loss=0.268187 time: 16.140689
INFO:root:[Epoch 47] train=0.907941 val=0.802900 loss=0.265307 time: 15.902403
INFO:root:[Epoch 48] train=0.908183 val=0.851100 loss=0.264184 time: 16.151392
INFO:root:[Epoch 49] train=0.910760 val=0.849400 loss=0.258081 time: 16.339328
INFO:root:[Epoch 50] train=0.909290 val=0.760300 loss=0.259411 time: 15.955638
INFO:root:[Epoch 51] train=0.910418 val=0.860100 loss=0.257635 time: 15.739537
INFO:root:[Epoch 52] train=0.913237 val=0.817400 loss=0.249442 time: 15.340968
INFO:root:[Epoch 53] train=0.909572 val=0.849500 loss=0.253918 time: 15.099388
INFO:root:[Epoch 54] train=0.911485 val=0.839900 loss=0.250509 time: 16.045295
INFO:root:[Epoch 55] train=0.913680 val=0.861800 loss=0.245550 time: 15.298371
INFO:root:[Epoch 56] train=0.913076 val=0.799400 loss=0.248961 time: 15.236493
INFO:root:[Epoch 57] train=0.914908 val=0.850900 loss=0.245086 time: 15.009622
INFO:root:[Epoch 58] train=0.913982 val=0.836900 loss=0.246366 time: 14.962411
INFO:root:[Epoch 59] train=0.915955 val=0.847700 loss=0.242431 time: 15.177559
INFO:root:[Epoch 60] train=0.914646 val=0.854800 loss=0.240472 time: 15.406226
INFO:root:[Epoch 61] train=0.918492 val=0.858900 loss=0.233237 time: 14.897509
INFO:root:[Epoch 62] train=0.917606 val=0.851500 loss=0.236515 time: 15.004906
INFO:root:[Epoch 63] train=0.916157 val=0.843700 loss=0.235715 time: 15.363801
INFO:root:[Epoch 64] train=0.917163 val=0.819200 loss=0.235388 time: 14.692085
INFO:root:[Epoch 65] train=0.917848 val=0.844400 loss=0.235920 time: 15.625168
INFO:root:[Epoch 66] train=0.917405 val=0.821100 loss=0.234727 time: 14.738990
INFO:root:[Epoch 67] train=0.919841 val=0.849800 loss=0.228236 time: 15.004915
INFO:root:[Epoch 68] train=0.921533 val=0.875700 loss=0.227234 time: 15.189580
INFO:root:[Epoch 69] train=0.919257 val=0.851200 loss=0.227151 time: 14.864155
INFO:root:[Epoch 70] train=0.919378 val=0.827700 loss=0.229856 time: 14.937334
INFO:root:[Epoch 71] train=0.919358 val=0.854300 loss=0.227891 time: 15.445729
INFO:root:[Epoch 72] train=0.921593 val=0.834400 loss=0.224837 time: 15.021813
INFO:root:[Epoch 73] train=0.921130 val=0.799500 loss=0.221291 time: 16.035656
INFO:root:[Epoch 74] train=0.921754 val=0.842600 loss=0.224718 time: 14.852803
INFO:root:[Epoch 75] train=0.920586 val=0.862200 loss=0.225717 time: 15.243270
INFO:root:[Epoch 76] train=0.921875 val=0.844800 loss=0.222227 time: 15.133735
INFO:root:[Epoch 77] train=0.922459 val=0.861200 loss=0.220424 time: 15.125820
INFO:root:[Epoch 78] train=0.922882 val=0.841700 loss=0.220586 time: 15.200876
INFO:root:[Epoch 79] train=0.923083 val=0.842500 loss=0.217879 time: 14.924622
INFO:root:[Epoch 80] train=0.923768 val=0.855600 loss=0.215396 time: 14.365667
INFO:root:[Epoch 81] train=0.923043 val=0.860100 loss=0.216146 time: 14.952044
INFO:root:[Epoch 82] train=0.923506 val=0.806100 loss=0.216178 time: 15.349391
INFO:root:[Epoch 83] train=0.924513 val=0.832900 loss=0.213677 time: 15.151999
INFO:root:[Epoch 84] train=0.923929 val=0.844200 loss=0.216083 time: 15.700972
INFO:root:[Epoch 85] train=0.923123 val=0.839500 loss=0.215903 time: 15.416298
INFO:root:[Epoch 86] train=0.925379 val=0.835400 loss=0.210534 time: 14.764599
INFO:root:[Epoch 87] train=0.923868 val=0.854400 loss=0.214083 time: 14.879983
INFO:root:[Epoch 88] train=0.926567 val=0.851900 loss=0.209242 time: 15.305403
INFO:root:[Epoch 89] train=0.926889 val=0.841100 loss=0.209853 time: 14.797395
INFO:root:[Epoch 90] train=0.924110 val=0.844500 loss=0.213397 time: 14.785877
INFO:root:[Epoch 91] train=0.927070 val=0.818800 loss=0.209170 time: 15.257596
INFO:root:[Epoch 92] train=0.928338 val=0.864300 loss=0.205724 time: 14.859061
INFO:root:[Epoch 93] train=0.926687 val=0.820700 loss=0.208809 time: 16.029007
INFO:root:[Epoch 94] train=0.926204 val=0.866600 loss=0.206659 time: 15.521822
INFO:root:[Epoch 95] train=0.925379 val=0.837200 loss=0.211069 time: 15.767525
INFO:root:[Epoch 96] train=0.927312 val=0.859700 loss=0.205943 time: 15.486305
INFO:root:[Epoch 97] train=0.927412 val=0.838800 loss=0.206449 time: 15.113962
INFO:root:[Epoch 98] train=0.927795 val=0.865100 loss=0.203774 time: 15.244616
INFO:root:[Epoch 99] train=0.928882 val=0.826200 loss=0.202521 time: 16.573352
INFO:root:[Epoch 100] train=0.953266 val=0.904200 loss=0.135215 time: 16.072068
INFO:root:[Epoch 101] train=0.966314 val=0.907300 loss=0.101786 time: 16.151817
INFO:root:[Epoch 102] train=0.970401 val=0.910200 loss=0.089593 time: 15.598340
INFO:root:[Epoch 103] train=0.971911 val=0.909200 loss=0.084137 time: 16.515884
INFO:root:[Epoch 104] train=0.973401 val=0.912600 loss=0.079512 time: 15.812930
INFO:root:[Epoch 105] train=0.975878 val=0.911200 loss=0.073396 time: 16.007000
INFO:root:[Epoch 106] train=0.977066 val=0.911900 loss=0.069850 time: 15.792355
INFO:root:[Epoch 107] train=0.977750 val=0.910200 loss=0.068040 time: 16.277306
INFO:root:[Epoch 108] train=0.979341 val=0.911500 loss=0.063319 time: 16.280593
INFO:root:[Epoch 109] train=0.979623 val=0.910100 loss=0.061453 time: 15.787831
INFO:root:[Epoch 110] train=0.981415 val=0.911800 loss=0.059081 time: 16.176872
INFO:root:[Epoch 111] train=0.982080 val=0.912900 loss=0.055817 time: 17.085076
INFO:root:[Epoch 112] train=0.981898 val=0.909200 loss=0.055323 time: 17.115596
INFO:root:[Epoch 113] train=0.982241 val=0.913100 loss=0.053072 time: 17.536602
INFO:root:[Epoch 114] train=0.983288 val=0.912200 loss=0.053001 time: 17.336027
INFO:root:[Epoch 115] train=0.983368 val=0.908200 loss=0.051452 time: 16.863271
INFO:root:[Epoch 116] train=0.984959 val=0.912800 loss=0.046911 time: 17.037343
INFO:root:[Epoch 117] train=0.985402 val=0.912300 loss=0.045655 time: 16.690070
INFO:root:[Epoch 118] train=0.985261 val=0.909500 loss=0.045822 time: 16.423918
INFO:root:[Epoch 119] train=0.985724 val=0.911500 loss=0.044704 time: 17.047552
INFO:root:[Epoch 120] train=0.986489 val=0.911400 loss=0.042398 time: 16.923959
INFO:root:[Epoch 121] train=0.987113 val=0.913200 loss=0.041175 time: 16.794443
INFO:root:[Epoch 122] train=0.986791 val=0.911000 loss=0.040969 time: 17.268110
INFO:root:[Epoch 123] train=0.987113 val=0.910400 loss=0.039784 time: 17.117735
INFO:root:[Epoch 124] train=0.986691 val=0.910900 loss=0.039970 time: 16.847732
INFO:root:[Epoch 125] train=0.987778 val=0.912200 loss=0.038036 time: 16.964186
INFO:root:[Epoch 126] train=0.988845 val=0.913100 loss=0.035420 time: 17.082393
INFO:root:[Epoch 127] train=0.989026 val=0.912000 loss=0.035628 time: 17.157568
INFO:root:[Epoch 128] train=0.988624 val=0.911300 loss=0.035548 time: 17.180498
INFO:root:[Epoch 129] train=0.989147 val=0.910900 loss=0.034239 time: 17.329057
INFO:root:[Epoch 130] train=0.988483 val=0.912400 loss=0.035615 time: 17.072886
INFO:root:[Epoch 131] train=0.989348 val=0.911500 loss=0.034327 time: 17.065247
INFO:root:[Epoch 132] train=0.989046 val=0.911000 loss=0.033660 time: 17.188975
INFO:root:[Epoch 133] train=0.989268 val=0.912000 loss=0.033821 time: 15.890942
INFO:root:[Epoch 134] train=0.990013 val=0.908800 loss=0.031774 time: 16.598199
INFO:root:[Epoch 135] train=0.989751 val=0.909400 loss=0.031106 time: 16.784189
INFO:root:[Epoch 136] train=0.989892 val=0.911000 loss=0.031108 time: 16.019335
INFO:root:[Epoch 137] train=0.990053 val=0.910200 loss=0.030812 time: 16.638166
INFO:root:[Epoch 138] train=0.991040 val=0.911600 loss=0.029217 time: 16.133178
INFO:root:[Epoch 139] train=0.991281 val=0.913800 loss=0.029268 time: 16.267131
INFO:root:[Epoch 140] train=0.991201 val=0.908200 loss=0.028068 time: 16.058998
INFO:root:[Epoch 141] train=0.991120 val=0.909500 loss=0.029089 time: 15.683648
INFO:root:[Epoch 142] train=0.991583 val=0.910600 loss=0.027165 time: 15.702313
INFO:root:[Epoch 143] train=0.991382 val=0.912800 loss=0.028007 time: 16.782712
INFO:root:[Epoch 144] train=0.991020 val=0.909800 loss=0.028068 time: 16.367526
INFO:root:[Epoch 145] train=0.992630 val=0.909900 loss=0.025043 time: 16.016283
INFO:root:[Epoch 146] train=0.992369 val=0.909400 loss=0.025726 time: 16.263568
INFO:root:[Epoch 147] train=0.992268 val=0.911000 loss=0.026528 time: 16.345233
INFO:root:[Epoch 148] train=0.991664 val=0.910800 loss=0.026741 time: 16.422137
INFO:root:[Epoch 149] train=0.990859 val=0.908800 loss=0.027433 time: 15.908467
INFO:root:[Epoch 150] train=0.993879 val=0.913600 loss=0.021965 time: 16.313582
INFO:root:[Epoch 151] train=0.994463 val=0.913900 loss=0.019999 time: 16.301736
INFO:root:[Epoch 152] train=0.994926 val=0.913800 loss=0.018853 time: 16.510897
INFO:root:[Epoch 153] train=0.995168 val=0.912700 loss=0.018038 time: 16.285555
INFO:root:[Epoch 154] train=0.995832 val=0.912700 loss=0.017663 time: 16.028641
INFO:root:[Epoch 155] train=0.995147 val=0.913700 loss=0.018136 time: 16.061610
INFO:root:[Epoch 156] train=0.995429 val=0.913900 loss=0.017420 time: 17.129102
INFO:root:[Epoch 157] train=0.995933 val=0.914100 loss=0.016507 time: 15.883268
INFO:root:[Epoch 158] train=0.995711 val=0.913000 loss=0.016122 time: 16.017687
INFO:root:[Epoch 159] train=0.995812 val=0.913200 loss=0.016282 time: 16.205860
INFO:root:[Epoch 160] train=0.995953 val=0.912800 loss=0.016704 time: 16.613862
INFO:root:[Epoch 161] train=0.995953 val=0.913100 loss=0.016058 time: 15.880025
INFO:root:[Epoch 162] train=0.995751 val=0.913900 loss=0.015695 time: 16.053016
INFO:root:[Epoch 163] train=0.995651 val=0.914200 loss=0.016809 time: 15.889857
INFO:root:[Epoch 164] train=0.996074 val=0.913900 loss=0.015662 time: 15.772145
INFO:root:[Epoch 165] train=0.995731 val=0.913900 loss=0.016287 time: 16.172764
INFO:root:[Epoch 166] train=0.996235 val=0.913500 loss=0.015700 time: 15.829770
INFO:root:[Epoch 167] train=0.995973 val=0.912500 loss=0.015984 time: 16.071323
INFO:root:[Epoch 168] train=0.996577 val=0.914400 loss=0.015022 time: 16.735872
INFO:root:[Epoch 169] train=0.996919 val=0.915100 loss=0.013949 time: 16.586448
INFO:root:[Epoch 170] train=0.996315 val=0.915400 loss=0.015377 time: 16.147802
INFO:root:[Epoch 171] train=0.996658 val=0.913600 loss=0.014541 time: 16.079431
INFO:root:[Epoch 172] train=0.996396 val=0.914900 loss=0.014793 time: 16.308751
INFO:root:[Epoch 173] train=0.996074 val=0.914400 loss=0.015236 time: 16.305352
INFO:root:[Epoch 174] train=0.995913 val=0.913500 loss=0.015372 time: 16.158301
INFO:root:[Epoch 175] train=0.996275 val=0.915100 loss=0.015097 time: 16.130466
INFO:root:[Epoch 176] train=0.996356 val=0.915500 loss=0.014617 time: 16.887717
INFO:root:[Epoch 177] train=0.996315 val=0.914300 loss=0.014399 time: 16.284664
INFO:root:[Epoch 178] train=0.996879 val=0.913500 loss=0.014041 time: 16.651276
INFO:root:[Epoch 179] train=0.996738 val=0.913900 loss=0.014625 time: 16.491314
INFO:root:[Epoch 180] train=0.996416 val=0.913800 loss=0.014534 time: 16.328157
INFO:root:[Epoch 181] train=0.996557 val=0.913000 loss=0.014547 time: 16.220666
INFO:root:[Epoch 182] train=0.996718 val=0.913400 loss=0.013937 time: 16.296696
INFO:root:[Epoch 183] train=0.996537 val=0.913500 loss=0.014627 time: 16.429857
INFO:root:[Epoch 184] train=0.996597 val=0.913300 loss=0.014129 time: 16.390900
INFO:root:[Epoch 185] train=0.996879 val=0.914800 loss=0.013676 time: 16.470069
INFO:root:[Epoch 186] train=0.997000 val=0.914200 loss=0.013461 time: 16.113116
INFO:root:[Epoch 187] train=0.996597 val=0.914700 loss=0.013884 time: 16.484101
INFO:root:[Epoch 188] train=0.996879 val=0.913900 loss=0.013500 time: 15.849154
INFO:root:[Epoch 189] train=0.997121 val=0.913300 loss=0.013483 time: 16.398390
INFO:root:[Epoch 190] train=0.996919 val=0.913400 loss=0.013672 time: 16.323723
INFO:root:[Epoch 191] train=0.997121 val=0.913600 loss=0.013166 time: 16.161794
INFO:root:[Epoch 192] train=0.996839 val=0.913000 loss=0.014155 time: 16.013056
INFO:root:[Epoch 193] train=0.996839 val=0.914600 loss=0.013685 time: 16.193770
INFO:root:[Epoch 194] train=0.996899 val=0.913900 loss=0.013162 time: 16.185393
INFO:root:[Epoch 195] train=0.996758 val=0.914900 loss=0.013420 time: 16.493778
INFO:root:[Epoch 196] train=0.997020 val=0.914700 loss=0.013170 time: 16.288302
INFO:root:[Epoch 197] train=0.997543 val=0.914000 loss=0.012255 time: 16.416638
INFO:root:[Epoch 198] train=0.997322 val=0.914400 loss=0.013096 time: 16.736068
INFO:root:[Epoch 199] train=0.997302 val=0.914500 loss=0.012611 time: 16.742435
