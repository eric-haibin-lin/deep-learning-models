INFO:root:Namespace(batch_size=128, drop_rate=0.0, gpus='0,1', lr=0.2, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_256.0', save_period=10, save_plot_dir='bs_256.0', wd=0.0001)
[06:23:48] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.367688 val=0.498000 loss=1.721065 time: 18.325305
INFO:root:[Epoch 1] train=0.575160 val=0.542700 loss=1.176297 time: 17.107749
INFO:root:[Epoch 2] train=0.667588 val=0.590700 loss=0.933577 time: 17.095391
INFO:root:[Epoch 3] train=0.725200 val=0.697700 loss=0.780606 time: 16.740911
INFO:root:[Epoch 4] train=0.762099 val=0.736800 loss=0.683600 time: 16.263510
INFO:root:[Epoch 5] train=0.785437 val=0.715600 loss=0.618277 time: 16.771123
INFO:root:[Epoch 6] train=0.801643 val=0.739600 loss=0.572642 time: 16.210865
INFO:root:[Epoch 7] train=0.814203 val=0.760800 loss=0.536722 time: 16.490129
INFO:root:[Epoch 8] train=0.824519 val=0.760200 loss=0.508101 time: 17.112889
INFO:root:[Epoch 9] train=0.831811 val=0.800900 loss=0.485158 time: 16.612617
INFO:root:[Epoch 10] train=0.839042 val=0.811200 loss=0.463589 time: 17.002944
INFO:root:[Epoch 11] train=0.846134 val=0.823000 loss=0.443703 time: 16.456894
INFO:root:[Epoch 12] train=0.853546 val=0.810700 loss=0.427438 time: 17.017333
INFO:root:[Epoch 13] train=0.859235 val=0.811000 loss=0.408703 time: 17.007773
INFO:root:[Epoch 14] train=0.858874 val=0.832500 loss=0.406943 time: 16.545795
INFO:root:[Epoch 15] train=0.864002 val=0.811000 loss=0.389269 time: 16.538018
INFO:root:[Epoch 16] train=0.868209 val=0.788100 loss=0.379432 time: 16.253580
INFO:root:[Epoch 17] train=0.871414 val=0.831900 loss=0.371996 time: 16.415846
INFO:root:[Epoch 18] train=0.873197 val=0.786200 loss=0.360684 time: 16.678068
INFO:root:[Epoch 19] train=0.878065 val=0.826900 loss=0.349768 time: 16.491739
INFO:root:[Epoch 20] train=0.880208 val=0.853200 loss=0.346040 time: 17.297586
INFO:root:[Epoch 21] train=0.881490 val=0.846500 loss=0.338447 time: 16.954904
INFO:root:[Epoch 22] train=0.882752 val=0.810500 loss=0.334509 time: 17.277535
INFO:root:[Epoch 23] train=0.886018 val=0.832800 loss=0.327614 time: 15.985633
INFO:root:[Epoch 24] train=0.886959 val=0.811900 loss=0.323490 time: 16.721379
INFO:root:[Epoch 25] train=0.892448 val=0.807900 loss=0.311478 time: 16.311666
INFO:root:[Epoch 26] train=0.894371 val=0.816300 loss=0.306833 time: 15.857690
INFO:root:[Epoch 27] train=0.896595 val=0.820900 loss=0.300815 time: 16.033530
INFO:root:[Epoch 28] train=0.894531 val=0.827400 loss=0.299619 time: 16.700292
INFO:root:[Epoch 29] train=0.895072 val=0.860900 loss=0.300111 time: 16.704086
INFO:root:[Epoch 30] train=0.897155 val=0.823300 loss=0.291567 time: 17.436278
INFO:root:[Epoch 31] train=0.900601 val=0.859400 loss=0.286163 time: 16.549186
INFO:root:[Epoch 32] train=0.901182 val=0.869600 loss=0.285106 time: 16.155632
INFO:root:[Epoch 33] train=0.901002 val=0.859800 loss=0.281784 time: 16.337269
INFO:root:[Epoch 34] train=0.905349 val=0.843400 loss=0.274886 time: 16.726039
INFO:root:[Epoch 35] train=0.902845 val=0.845200 loss=0.276424 time: 16.489606
INFO:root:[Epoch 36] train=0.908794 val=0.851300 loss=0.265252 time: 16.570843
INFO:root:[Epoch 37] train=0.906711 val=0.856000 loss=0.266550 time: 16.666804
INFO:root:[Epoch 38] train=0.906871 val=0.857300 loss=0.266077 time: 17.514321
INFO:root:[Epoch 39] train=0.909615 val=0.854600 loss=0.259988 time: 16.804929
INFO:root:[Epoch 40] train=0.908614 val=0.864500 loss=0.261977 time: 17.197737
INFO:root:[Epoch 41] train=0.907031 val=0.841100 loss=0.262233 time: 16.539015
INFO:root:[Epoch 42] train=0.911218 val=0.860200 loss=0.255400 time: 16.846052
INFO:root:[Epoch 43] train=0.911018 val=0.868200 loss=0.254711 time: 16.557814
INFO:root:[Epoch 44] train=0.911979 val=0.856800 loss=0.252415 time: 16.601260
INFO:root:[Epoch 45] train=0.913462 val=0.856100 loss=0.243234 time: 16.692110
INFO:root:[Epoch 46] train=0.913582 val=0.854500 loss=0.248898 time: 16.611204
INFO:root:[Epoch 47] train=0.913862 val=0.860500 loss=0.245283 time: 16.097760
INFO:root:[Epoch 48] train=0.916707 val=0.851900 loss=0.236950 time: 16.983020
INFO:root:[Epoch 49] train=0.914243 val=0.860400 loss=0.246852 time: 15.927417
INFO:root:[Epoch 50] train=0.916326 val=0.841200 loss=0.238540 time: 15.887319
INFO:root:[Epoch 51] train=0.913602 val=0.847300 loss=0.243222 time: 16.575851
INFO:root:[Epoch 52] train=0.916106 val=0.872200 loss=0.239513 time: 16.649569
INFO:root:[Epoch 53] train=0.915425 val=0.854300 loss=0.240516 time: 16.921254
INFO:root:[Epoch 54] train=0.915645 val=0.848500 loss=0.236752 time: 16.838942
INFO:root:[Epoch 55] train=0.916787 val=0.855200 loss=0.236022 time: 16.980234
INFO:root:[Epoch 56] train=0.918109 val=0.860200 loss=0.232161 time: 16.967148
INFO:root:[Epoch 57] train=0.919271 val=0.857000 loss=0.233665 time: 17.239762
INFO:root:[Epoch 58] train=0.918289 val=0.880600 loss=0.231303 time: 17.620142
INFO:root:[Epoch 59] train=0.917929 val=0.842200 loss=0.230435 time: 16.647002
INFO:root:[Epoch 60] train=0.920593 val=0.866400 loss=0.227017 time: 16.679804
INFO:root:[Epoch 61] train=0.920353 val=0.844800 loss=0.223720 time: 16.753529
INFO:root:[Epoch 62] train=0.919231 val=0.830100 loss=0.226142 time: 15.712865
INFO:root:[Epoch 63] train=0.922817 val=0.854900 loss=0.220801 time: 16.252824
INFO:root:[Epoch 64] train=0.920513 val=0.794600 loss=0.224295 time: 16.130136
INFO:root:[Epoch 65] train=0.920833 val=0.844600 loss=0.223600 time: 16.825407
INFO:root:[Epoch 66] train=0.920513 val=0.855600 loss=0.224156 time: 16.374151
INFO:root:[Epoch 67] train=0.922055 val=0.852100 loss=0.222227 time: 16.488293
INFO:root:[Epoch 68] train=0.924319 val=0.843100 loss=0.219442 time: 16.765646
INFO:root:[Epoch 69] train=0.925180 val=0.863200 loss=0.215460 time: 16.421437
INFO:root:[Epoch 70] train=0.922596 val=0.847100 loss=0.220576 time: 16.687874
INFO:root:[Epoch 71] train=0.922756 val=0.857300 loss=0.219075 time: 16.580646
INFO:root:[Epoch 72] train=0.923377 val=0.870000 loss=0.217953 time: 16.554229
INFO:root:[Epoch 73] train=0.923998 val=0.852300 loss=0.214724 time: 16.955711
INFO:root:[Epoch 74] train=0.923598 val=0.840500 loss=0.218836 time: 16.547959
INFO:root:[Epoch 75] train=0.925581 val=0.872900 loss=0.211866 time: 17.106437
INFO:root:[Epoch 76] train=0.924519 val=0.853500 loss=0.214764 time: 16.726066
INFO:root:[Epoch 77] train=0.924379 val=0.850100 loss=0.211345 time: 16.897142
INFO:root:[Epoch 78] train=0.926202 val=0.858700 loss=0.214279 time: 17.441433
INFO:root:[Epoch 79] train=0.925721 val=0.868200 loss=0.212024 time: 16.848626
INFO:root:[Epoch 80] train=0.924139 val=0.819200 loss=0.214565 time: 16.759980
INFO:root:[Epoch 81] train=0.927905 val=0.873900 loss=0.206235 time: 16.149697
INFO:root:[Epoch 82] train=0.927524 val=0.859600 loss=0.207056 time: 15.897972
INFO:root:[Epoch 83] train=0.925521 val=0.836400 loss=0.210258 time: 16.866862
INFO:root:[Epoch 84] train=0.926442 val=0.864700 loss=0.210760 time: 16.647310
INFO:root:[Epoch 85] train=0.927364 val=0.853600 loss=0.204135 time: 16.017108
INFO:root:[Epoch 86] train=0.925641 val=0.836300 loss=0.208977 time: 17.151673
INFO:root:[Epoch 87] train=0.927003 val=0.840200 loss=0.207077 time: 16.193370
INFO:root:[Epoch 88] train=0.927464 val=0.877600 loss=0.206588 time: 16.539233
INFO:root:[Epoch 89] train=0.927784 val=0.857400 loss=0.206204 time: 15.834603
INFO:root:[Epoch 90] train=0.927584 val=0.840700 loss=0.207458 time: 16.501516
INFO:root:[Epoch 91] train=0.927143 val=0.862700 loss=0.206665 time: 16.481151
INFO:root:[Epoch 92] train=0.927424 val=0.874000 loss=0.206505 time: 16.288420
INFO:root:[Epoch 93] train=0.929688 val=0.821300 loss=0.197879 time: 17.120244
INFO:root:[Epoch 94] train=0.927464 val=0.882900 loss=0.207158 time: 17.693964
INFO:root:[Epoch 95] train=0.928686 val=0.844900 loss=0.201571 time: 16.564352
INFO:root:[Epoch 96] train=0.927464 val=0.846700 loss=0.207313 time: 16.784899
INFO:root:[Epoch 97] train=0.928085 val=0.879600 loss=0.205930 time: 16.696016
INFO:root:[Epoch 98] train=0.928546 val=0.871700 loss=0.203297 time: 16.164771
INFO:root:[Epoch 99] train=0.930048 val=0.874100 loss=0.198414 time: 16.399143
INFO:root:[Epoch 100] train=0.956190 val=0.913700 loss=0.128291 time: 16.698552
INFO:root:[Epoch 101] train=0.968169 val=0.914400 loss=0.096240 time: 16.947743
INFO:root:[Epoch 102] train=0.970994 val=0.918400 loss=0.088755 time: 16.623290
INFO:root:[Epoch 103] train=0.973357 val=0.916000 loss=0.079846 time: 17.518288
INFO:root:[Epoch 104] train=0.975461 val=0.917100 loss=0.075212 time: 16.584024
INFO:root:[Epoch 105] train=0.976723 val=0.919700 loss=0.070784 time: 16.431076
INFO:root:[Epoch 106] train=0.977865 val=0.916500 loss=0.067170 time: 16.936124
INFO:root:[Epoch 107] train=0.979688 val=0.918200 loss=0.063866 time: 16.186196
INFO:root:[Epoch 108] train=0.979547 val=0.918900 loss=0.061907 time: 17.334439
INFO:root:[Epoch 109] train=0.980869 val=0.916400 loss=0.056969 time: 16.852413
INFO:root:[Epoch 110] train=0.982312 val=0.918000 loss=0.054976 time: 16.833491
INFO:root:[Epoch 111] train=0.981891 val=0.917200 loss=0.053947 time: 16.741351
INFO:root:[Epoch 112] train=0.982332 val=0.916300 loss=0.051629 time: 16.724940
INFO:root:[Epoch 113] train=0.984736 val=0.920600 loss=0.047868 time: 17.122806
INFO:root:[Epoch 114] train=0.984455 val=0.917100 loss=0.048435 time: 16.067376
INFO:root:[Epoch 115] train=0.984375 val=0.918800 loss=0.048797 time: 17.048365
INFO:root:[Epoch 116] train=0.984936 val=0.919000 loss=0.046791 time: 16.410068
INFO:root:[Epoch 117] train=0.985677 val=0.918100 loss=0.043963 time: 15.957921
INFO:root:[Epoch 118] train=0.985837 val=0.917800 loss=0.043012 time: 17.259808
INFO:root:[Epoch 119] train=0.986258 val=0.914400 loss=0.043054 time: 17.119978
INFO:root:[Epoch 120] train=0.986458 val=0.917100 loss=0.040660 time: 17.432390
INFO:root:[Epoch 121] train=0.987400 val=0.916600 loss=0.040275 time: 16.645520
INFO:root:[Epoch 122] train=0.988241 val=0.915800 loss=0.037363 time: 17.062186
INFO:root:[Epoch 123] train=0.987961 val=0.915200 loss=0.038054 time: 16.459600
INFO:root:[Epoch 124] train=0.988221 val=0.916500 loss=0.036159 time: 16.540345
INFO:root:[Epoch 125] train=0.988281 val=0.912900 loss=0.036826 time: 16.178877
INFO:root:[Epoch 126] train=0.988742 val=0.917500 loss=0.035398 time: 16.527784
INFO:root:[Epoch 127] train=0.989263 val=0.915700 loss=0.033509 time: 16.907754
INFO:root:[Epoch 128] train=0.988662 val=0.914300 loss=0.035639 time: 17.063293
INFO:root:[Epoch 129] train=0.989543 val=0.917200 loss=0.033272 time: 16.322636
INFO:root:[Epoch 130] train=0.989062 val=0.915600 loss=0.033660 time: 15.948289
INFO:root:[Epoch 131] train=0.989583 val=0.916000 loss=0.032802 time: 16.299473
INFO:root:[Epoch 132] train=0.989804 val=0.916900 loss=0.031974 time: 16.585961
INFO:root:[Epoch 133] train=0.990084 val=0.917500 loss=0.031950 time: 16.149027
INFO:root:[Epoch 134] train=0.989163 val=0.916100 loss=0.032494 time: 17.302370
INFO:root:[Epoch 135] train=0.990385 val=0.915800 loss=0.030500 time: 16.848090
INFO:root:[Epoch 136] train=0.990625 val=0.917200 loss=0.029060 time: 16.508928
INFO:root:[Epoch 137] train=0.990765 val=0.916500 loss=0.029143 time: 16.353245
INFO:root:[Epoch 138] train=0.990946 val=0.915600 loss=0.028262 time: 16.563074
INFO:root:[Epoch 139] train=0.990184 val=0.912300 loss=0.029761 time: 16.595011
INFO:root:[Epoch 140] train=0.990865 val=0.915600 loss=0.028543 time: 16.910034
INFO:root:[Epoch 141] train=0.990745 val=0.917000 loss=0.028684 time: 16.735151
INFO:root:[Epoch 142] train=0.991546 val=0.914200 loss=0.026656 time: 17.237251
INFO:root:[Epoch 143] train=0.990585 val=0.916800 loss=0.028298 time: 17.534051
INFO:root:[Epoch 144] train=0.991366 val=0.912800 loss=0.027373 time: 16.506719
INFO:root:[Epoch 145] train=0.992388 val=0.916000 loss=0.025459 time: 17.056017
INFO:root:[Epoch 146] train=0.991426 val=0.916300 loss=0.026696 time: 16.403222
INFO:root:[Epoch 147] train=0.992308 val=0.913700 loss=0.025585 time: 17.013957
INFO:root:[Epoch 148] train=0.991386 val=0.913100 loss=0.026497 time: 16.744944
INFO:root:[Epoch 149] train=0.990905 val=0.914100 loss=0.027125 time: 16.861238
INFO:root:[Epoch 150] train=0.992728 val=0.916200 loss=0.023326 time: 15.778393
INFO:root:[Epoch 151] train=0.994050 val=0.916800 loss=0.020738 time: 17.005886
INFO:root:[Epoch 152] train=0.994591 val=0.918900 loss=0.019162 time: 16.982952
INFO:root:[Epoch 153] train=0.994531 val=0.918700 loss=0.018952 time: 17.881680
INFO:root:[Epoch 154] train=0.995313 val=0.919700 loss=0.017924 time: 17.140028
INFO:root:[Epoch 155] train=0.994972 val=0.918600 loss=0.018187 time: 17.051918
INFO:root:[Epoch 156] train=0.995413 val=0.918500 loss=0.017501 time: 17.608624
INFO:root:[Epoch 157] train=0.995513 val=0.918800 loss=0.017011 time: 17.863539
INFO:root:[Epoch 158] train=0.995653 val=0.918200 loss=0.016735 time: 17.912608
INFO:root:[Epoch 159] train=0.996054 val=0.918800 loss=0.016004 time: 18.373401
INFO:root:[Epoch 160] train=0.996194 val=0.918300 loss=0.015438 time: 18.409952
INFO:root:[Epoch 161] train=0.995853 val=0.918900 loss=0.016413 time: 17.536098
INFO:root:[Epoch 162] train=0.995252 val=0.918900 loss=0.017156 time: 18.246859
INFO:root:[Epoch 163] train=0.996374 val=0.918500 loss=0.015550 time: 18.802758
INFO:root:[Epoch 164] train=0.995833 val=0.918200 loss=0.016207 time: 18.531456
INFO:root:[Epoch 165] train=0.996074 val=0.918700 loss=0.015982 time: 18.408911
INFO:root:[Epoch 166] train=0.995954 val=0.918200 loss=0.015095 time: 18.575516
INFO:root:[Epoch 167] train=0.996514 val=0.919500 loss=0.015244 time: 18.346430
INFO:root:[Epoch 168] train=0.996054 val=0.919500 loss=0.015108 time: 18.280164
INFO:root:[Epoch 169] train=0.995913 val=0.919700 loss=0.015645 time: 17.818831
INFO:root:[Epoch 170] train=0.996334 val=0.918800 loss=0.015201 time: 18.096456
INFO:root:[Epoch 171] train=0.996434 val=0.918000 loss=0.014296 time: 18.226440
INFO:root:[Epoch 172] train=0.996294 val=0.917700 loss=0.015313 time: 19.298191
INFO:root:[Epoch 173] train=0.995573 val=0.918600 loss=0.016261 time: 18.140630
INFO:root:[Epoch 174] train=0.996214 val=0.918900 loss=0.015228 time: 18.305151
INFO:root:[Epoch 175] train=0.996234 val=0.918200 loss=0.015284 time: 18.037641
INFO:root:[Epoch 176] train=0.995613 val=0.917700 loss=0.015704 time: 17.573332
INFO:root:[Epoch 177] train=0.996174 val=0.918400 loss=0.014636 time: 18.645159
INFO:root:[Epoch 178] train=0.996394 val=0.919300 loss=0.014635 time: 17.928020
INFO:root:[Epoch 179] train=0.996695 val=0.918200 loss=0.013651 time: 18.599829
INFO:root:[Epoch 180] train=0.996434 val=0.918000 loss=0.014414 time: 18.169967
INFO:root:[Epoch 181] train=0.996114 val=0.918400 loss=0.014917 time: 18.317210
INFO:root:[Epoch 182] train=0.996955 val=0.918100 loss=0.013728 time: 18.600717
INFO:root:[Epoch 183] train=0.996474 val=0.920000 loss=0.014529 time: 18.203520
INFO:root:[Epoch 184] train=0.996294 val=0.919100 loss=0.014528 time: 17.916932
INFO:root:[Epoch 185] train=0.996374 val=0.919100 loss=0.014629 time: 18.015254
INFO:root:[Epoch 186] train=0.996915 val=0.918900 loss=0.013690 time: 18.259297
INFO:root:[Epoch 187] train=0.996554 val=0.917400 loss=0.014156 time: 18.915753
INFO:root:[Epoch 188] train=0.996354 val=0.918800 loss=0.014421 time: 18.541420
INFO:root:[Epoch 189] train=0.996094 val=0.919100 loss=0.014731 time: 18.064399
INFO:root:[Epoch 190] train=0.996494 val=0.918200 loss=0.014168 time: 18.307539
INFO:root:[Epoch 191] train=0.996434 val=0.918900 loss=0.014339 time: 17.990744
INFO:root:[Epoch 192] train=0.995954 val=0.920100 loss=0.015068 time: 17.121671
INFO:root:[Epoch 193] train=0.996474 val=0.918700 loss=0.013861 time: 17.789114
INFO:root:[Epoch 194] train=0.996935 val=0.918900 loss=0.013416 time: 17.458215
INFO:root:[Epoch 195] train=0.996074 val=0.918200 loss=0.014438 time: 17.896255
INFO:root:[Epoch 196] train=0.997256 val=0.919000 loss=0.012649 time: 17.416758
INFO:root:[Epoch 197] train=0.996575 val=0.919800 loss=0.013508 time: 17.692091
INFO:root:[Epoch 198] train=0.996815 val=0.919400 loss=0.013546 time: 17.823074
INFO:root:[Epoch 199] train=0.996474 val=0.919200 loss=0.014208 time: 17.562250
