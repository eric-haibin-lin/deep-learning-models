INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='0', last_gamma=False, lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1_warm_10.1', save_period=10, save_plot_dir='bs_512_gpu_1_warm_10.1', warmup_epochs=10, wd=0.0001)
[03:45:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.204091 val=0.279100 loss=2.156550 time: 14.767835 lr: 0.039588
INFO:root:[Epoch 1] train=0.346368 val=0.411700 loss=1.743082 time: 14.377696 lr: 0.079588
INFO:root:[Epoch 2] train=0.478576 val=0.500400 loss=1.416438 time: 14.508558 lr: 0.119588
INFO:root:[Epoch 3] train=0.599851 val=0.589200 loss=1.109774 time: 15.586281 lr: 0.159588
INFO:root:[Epoch 4] train=0.668814 val=0.635800 loss=0.931790 time: 14.513776 lr: 0.199588
INFO:root:[Epoch 5] train=0.710656 val=0.653200 loss=0.817543 time: 14.368426 lr: 0.239588
INFO:root:[Epoch 6] train=0.745772 val=0.663000 loss=0.725451 time: 14.204197 lr: 0.279588
INFO:root:[Epoch 7] train=0.772974 val=0.703500 loss=0.651350 time: 14.727767 lr: 0.319588
INFO:root:[Epoch 8] train=0.788861 val=0.689300 loss=0.605168 time: 14.577214 lr: 0.359588
INFO:root:[Epoch 9] train=0.804325 val=0.680500 loss=0.566238 time: 14.600116 lr: 0.399588
INFO:root:[Epoch 10] train=0.817393 val=0.726000 loss=0.526110 time: 14.923297 lr: 0.400000
INFO:root:[Epoch 11] train=0.830078 val=0.709400 loss=0.493100 time: 14.331714 lr: 0.400000
INFO:root:[Epoch 12] train=0.839401 val=0.764000 loss=0.464659 time: 14.709644 lr: 0.400000
INFO:root:[Epoch 13] train=0.846247 val=0.776700 loss=0.444050 time: 14.589152 lr: 0.400000
INFO:root:[Epoch 14] train=0.854019 val=0.709300 loss=0.422752 time: 14.332278 lr: 0.400000
INFO:root:[Epoch 15] train=0.857221 val=0.805000 loss=0.410795 time: 15.501651 lr: 0.400000
INFO:root:[Epoch 16] train=0.862899 val=0.738200 loss=0.395684 time: 16.173382 lr: 0.400000
INFO:root:[Epoch 17] train=0.867610 val=0.815500 loss=0.380667 time: 17.007156 lr: 0.400000
INFO:root:[Epoch 18] train=0.872946 val=0.819800 loss=0.364163 time: 16.742928 lr: 0.400000
INFO:root:[Epoch 19] train=0.876792 val=0.824000 loss=0.357349 time: 16.973127 lr: 0.400000
INFO:root:[Epoch 20] train=0.879792 val=0.826800 loss=0.346319 time: 16.480684 lr: 0.400000
INFO:root:[Epoch 21] train=0.881826 val=0.830300 loss=0.339107 time: 16.049536 lr: 0.400000
INFO:root:[Epoch 22] train=0.886678 val=0.818400 loss=0.330809 time: 16.213118 lr: 0.400000
INFO:root:[Epoch 23] train=0.887323 val=0.819400 loss=0.324571 time: 16.549147 lr: 0.400000
INFO:root:[Epoch 24] train=0.889356 val=0.826800 loss=0.317745 time: 16.435244 lr: 0.400000
INFO:root:[Epoch 25] train=0.891934 val=0.850700 loss=0.308127 time: 17.070029 lr: 0.400000
INFO:root:[Epoch 26] train=0.893504 val=0.747900 loss=0.305199 time: 16.559676 lr: 0.400000
INFO:root:[Epoch 27] train=0.894189 val=0.835700 loss=0.299977 time: 16.717262 lr: 0.400000
INFO:root:[Epoch 28] train=0.896867 val=0.771100 loss=0.293307 time: 16.590551 lr: 0.400000
INFO:root:[Epoch 29] train=0.899686 val=0.770000 loss=0.289563 time: 16.217173 lr: 0.400000
INFO:root:[Epoch 30] train=0.900270 val=0.827400 loss=0.286200 time: 16.356902 lr: 0.400000
INFO:root:[Epoch 31] train=0.904136 val=0.821400 loss=0.275640 time: 16.348413 lr: 0.400000
INFO:root:[Epoch 32] train=0.901236 val=0.826600 loss=0.278996 time: 16.977780 lr: 0.400000
INFO:root:[Epoch 33] train=0.904277 val=0.859000 loss=0.272179 time: 17.593154 lr: 0.400000
INFO:root:[Epoch 34] train=0.905565 val=0.823900 loss=0.271497 time: 18.340003 lr: 0.400000
INFO:root:[Epoch 35] train=0.906451 val=0.843900 loss=0.264954 time: 18.531949 lr: 0.400000
INFO:root:[Epoch 36] train=0.909915 val=0.781300 loss=0.262577 time: 18.245440 lr: 0.400000
INFO:root:[Epoch 37] train=0.908666 val=0.835500 loss=0.258593 time: 18.834316 lr: 0.400000
INFO:root:[Epoch 38] train=0.908102 val=0.799000 loss=0.261814 time: 18.043057 lr: 0.400000
INFO:root:[Epoch 39] train=0.909552 val=0.857500 loss=0.257903 time: 18.006268 lr: 0.400000
INFO:root:[Epoch 40] train=0.911385 val=0.824200 loss=0.255748 time: 18.340736 lr: 0.400000
INFO:root:[Epoch 41] train=0.911143 val=0.802200 loss=0.253541 time: 18.383883 lr: 0.400000
INFO:root:[Epoch 42] train=0.913620 val=0.819100 loss=0.243432 time: 18.018799 lr: 0.400000
INFO:root:[Epoch 43] train=0.913277 val=0.828300 loss=0.246098 time: 18.303036 lr: 0.400000
INFO:root:[Epoch 44] train=0.915311 val=0.814800 loss=0.242755 time: 18.134125 lr: 0.400000
INFO:root:[Epoch 45] train=0.914224 val=0.835300 loss=0.244368 time: 18.603873 lr: 0.400000
INFO:root:[Epoch 46] train=0.917022 val=0.771600 loss=0.236396 time: 18.005880 lr: 0.400000
INFO:root:[Epoch 47] train=0.914425 val=0.838500 loss=0.240651 time: 18.045223 lr: 0.400000
INFO:root:[Epoch 48] train=0.917163 val=0.832000 loss=0.236266 time: 18.108612 lr: 0.400000
INFO:root:[Epoch 49] train=0.917888 val=0.817700 loss=0.235316 time: 18.119467 lr: 0.400000
INFO:root:[Epoch 50] train=0.916056 val=0.784900 loss=0.238107 time: 18.224377 lr: 0.400000
INFO:root:[Epoch 51] train=0.918291 val=0.829500 loss=0.231516 time: 18.321149 lr: 0.400000
INFO:root:[Epoch 52] train=0.917989 val=0.826900 loss=0.234103 time: 18.068478 lr: 0.400000
INFO:root:[Epoch 53] train=0.921492 val=0.830700 loss=0.225826 time: 18.336276 lr: 0.400000
INFO:root:[Epoch 54] train=0.918170 val=0.835600 loss=0.232016 time: 18.110506 lr: 0.400000
INFO:root:[Epoch 55] train=0.920083 val=0.829100 loss=0.225628 time: 18.016650 lr: 0.400000
INFO:root:[Epoch 56] train=0.922298 val=0.841800 loss=0.221230 time: 18.243529 lr: 0.400000
INFO:root:[Epoch 57] train=0.921734 val=0.769100 loss=0.226393 time: 18.086353 lr: 0.400000
INFO:root:[Epoch 58] train=0.920667 val=0.825400 loss=0.223837 time: 18.089490 lr: 0.400000
INFO:root:[Epoch 59] train=0.922479 val=0.857600 loss=0.222529 time: 17.975352 lr: 0.400000
INFO:root:[Epoch 60] train=0.922076 val=0.830500 loss=0.220738 time: 18.085916 lr: 0.400000
INFO:root:[Epoch 61] train=0.925097 val=0.849900 loss=0.214932 time: 18.064625 lr: 0.400000
INFO:root:[Epoch 62] train=0.923969 val=0.840700 loss=0.215749 time: 18.216699 lr: 0.400000
INFO:root:[Epoch 63] train=0.920707 val=0.852800 loss=0.222019 time: 18.175227 lr: 0.400000
INFO:root:[Epoch 64] train=0.925399 val=0.847600 loss=0.209066 time: 17.649709 lr: 0.400000
INFO:root:[Epoch 65] train=0.922660 val=0.858800 loss=0.218271 time: 18.294628 lr: 0.400000
INFO:root:[Epoch 66] train=0.924694 val=0.845500 loss=0.214138 time: 18.196733 lr: 0.400000
INFO:root:[Epoch 67] train=0.923566 val=0.819300 loss=0.216374 time: 17.995711 lr: 0.400000
INFO:root:[Epoch 68] train=0.925580 val=0.871400 loss=0.212331 time: 18.828395 lr: 0.400000
INFO:root:[Epoch 69] train=0.926043 val=0.869100 loss=0.210150 time: 17.900229 lr: 0.400000
INFO:root:[Epoch 70] train=0.926687 val=0.792700 loss=0.205366 time: 17.988043 lr: 0.400000
INFO:root:[Epoch 71] train=0.925197 val=0.844200 loss=0.212654 time: 18.220653 lr: 0.400000
INFO:root:[Epoch 72] train=0.926285 val=0.848200 loss=0.207889 time: 17.828865 lr: 0.400000
INFO:root:[Epoch 73] train=0.927714 val=0.834000 loss=0.203212 time: 18.424576 lr: 0.400000
INFO:root:[Epoch 74] train=0.925379 val=0.866700 loss=0.208620 time: 18.362536 lr: 0.400000
INFO:root:[Epoch 75] train=0.928097 val=0.867300 loss=0.202758 time: 18.211769 lr: 0.400000
INFO:root:[Epoch 76] train=0.927533 val=0.862400 loss=0.207697 time: 18.574380 lr: 0.400000
INFO:root:[Epoch 77] train=0.927815 val=0.835500 loss=0.205531 time: 18.241552 lr: 0.400000
INFO:root:[Epoch 78] train=0.927211 val=0.844200 loss=0.202122 time: 18.531282 lr: 0.400000
INFO:root:[Epoch 79] train=0.928640 val=0.807800 loss=0.202772 time: 18.095511 lr: 0.400000
INFO:root:[Epoch 80] train=0.927694 val=0.832000 loss=0.203061 time: 17.996238 lr: 0.400000
INFO:root:[Epoch 81] train=0.929587 val=0.839500 loss=0.200541 time: 18.293978 lr: 0.400000
INFO:root:[Epoch 82] train=0.927291 val=0.852000 loss=0.204969 time: 18.301282 lr: 0.400000
INFO:root:[Epoch 83] train=0.929506 val=0.810100 loss=0.198604 time: 17.908547 lr: 0.400000
INFO:root:[Epoch 84] train=0.929446 val=0.867200 loss=0.199083 time: 18.142374 lr: 0.400000
INFO:root:[Epoch 85] train=0.931761 val=0.857900 loss=0.196659 time: 18.069373 lr: 0.400000
INFO:root:[Epoch 86] train=0.930996 val=0.873900 loss=0.195754 time: 18.569879 lr: 0.400000
INFO:root:[Epoch 87] train=0.932043 val=0.847200 loss=0.193709 time: 18.139043 lr: 0.400000
INFO:root:[Epoch 88] train=0.927996 val=0.809900 loss=0.200122 time: 18.191792 lr: 0.400000
INFO:root:[Epoch 89] train=0.930533 val=0.857700 loss=0.197301 time: 17.882348 lr: 0.400000
INFO:root:[Epoch 90] train=0.930392 val=0.859900 loss=0.197496 time: 18.357414 lr: 0.400000
INFO:root:[Epoch 91] train=0.930674 val=0.838100 loss=0.197399 time: 18.422530 lr: 0.400000
INFO:root:[Epoch 92] train=0.932023 val=0.874100 loss=0.190255 time: 18.437145 lr: 0.400000
INFO:root:[Epoch 93] train=0.930694 val=0.869900 loss=0.195263 time: 18.309335 lr: 0.400000
INFO:root:[Epoch 94] train=0.932688 val=0.836500 loss=0.190541 time: 18.223101 lr: 0.400000
INFO:root:[Epoch 95] train=0.931057 val=0.851600 loss=0.194258 time: 18.160975 lr: 0.400000
INFO:root:[Epoch 96] train=0.931037 val=0.842700 loss=0.193238 time: 18.188128 lr: 0.400000
INFO:root:[Epoch 97] train=0.933312 val=0.835000 loss=0.189274 time: 18.221124 lr: 0.400000
INFO:root:[Epoch 98] train=0.933151 val=0.824500 loss=0.190543 time: 18.516364 lr: 0.400000
INFO:root:[Epoch 99] train=0.931641 val=0.877500 loss=0.193186 time: 18.497627 lr: 0.400000
INFO:root:[Epoch 100] train=0.957253 val=0.912600 loss=0.125090 time: 18.095734 lr: 0.040000
INFO:root:[Epoch 101] train=0.969092 val=0.913000 loss=0.092513 time: 18.209146 lr: 0.040000
INFO:root:[Epoch 102] train=0.973160 val=0.914700 loss=0.081500 time: 18.327677 lr: 0.040000
INFO:root:[Epoch 103] train=0.975536 val=0.916900 loss=0.073477 time: 18.717517 lr: 0.040000
INFO:root:[Epoch 104] train=0.976079 val=0.916700 loss=0.070646 time: 18.245192 lr: 0.040000
INFO:root:[Epoch 105] train=0.978657 val=0.915900 loss=0.063720 time: 17.996352 lr: 0.040000
INFO:root:[Epoch 106] train=0.980610 val=0.917200 loss=0.059411 time: 19.057489 lr: 0.040000
INFO:root:[Epoch 107] train=0.981556 val=0.918100 loss=0.057051 time: 18.545549 lr: 0.040000
INFO:root:[Epoch 108] train=0.982080 val=0.917200 loss=0.054644 time: 17.972998 lr: 0.040000
INFO:root:[Epoch 109] train=0.982623 val=0.914100 loss=0.053746 time: 18.718164 lr: 0.040000
INFO:root:[Epoch 110] train=0.984778 val=0.918100 loss=0.048837 time: 18.240371 lr: 0.040000
INFO:root:[Epoch 111] train=0.984697 val=0.917000 loss=0.047738 time: 18.199281 lr: 0.040000
INFO:root:[Epoch 112] train=0.984093 val=0.919200 loss=0.047161 time: 18.302781 lr: 0.040000
INFO:root:[Epoch 113] train=0.984677 val=0.917600 loss=0.045753 time: 18.132612 lr: 0.040000
INFO:root:[Epoch 114] train=0.986409 val=0.918700 loss=0.043260 time: 18.602826 lr: 0.040000
INFO:root:[Epoch 115] train=0.986912 val=0.915400 loss=0.040789 time: 18.762488 lr: 0.040000
INFO:root:[Epoch 116] train=0.987033 val=0.916600 loss=0.039765 time: 18.582629 lr: 0.040000
INFO:root:[Epoch 117] train=0.988301 val=0.915900 loss=0.038399 time: 18.433074 lr: 0.040000
INFO:root:[Epoch 118] train=0.988040 val=0.917200 loss=0.037344 time: 18.318609 lr: 0.040000
INFO:root:[Epoch 119] train=0.988160 val=0.913500 loss=0.037237 time: 18.088347 lr: 0.040000
INFO:root:[Epoch 120] train=0.989147 val=0.917900 loss=0.033853 time: 18.129176 lr: 0.040000
INFO:root:[Epoch 121] train=0.989650 val=0.917000 loss=0.033386 time: 18.002653 lr: 0.040000
INFO:root:[Epoch 122] train=0.989812 val=0.916300 loss=0.032764 time: 18.553732 lr: 0.040000
INFO:root:[Epoch 123] train=0.989489 val=0.916800 loss=0.033156 time: 17.960509 lr: 0.040000
INFO:root:[Epoch 124] train=0.989932 val=0.917200 loss=0.032000 time: 18.342897 lr: 0.040000
INFO:root:[Epoch 125] train=0.990617 val=0.916700 loss=0.029693 time: 18.059972 lr: 0.040000
INFO:root:[Epoch 126] train=0.990255 val=0.914600 loss=0.029884 time: 18.679368 lr: 0.040000
INFO:root:[Epoch 127] train=0.990093 val=0.914500 loss=0.030605 time: 18.078583 lr: 0.040000
INFO:root:[Epoch 128] train=0.990778 val=0.915900 loss=0.028788 time: 18.122382 lr: 0.040000
INFO:root:[Epoch 129] train=0.991442 val=0.915600 loss=0.027707 time: 18.409013 lr: 0.040000
INFO:root:[Epoch 130] train=0.990456 val=0.915700 loss=0.028497 time: 18.259544 lr: 0.040000
INFO:root:[Epoch 131] train=0.991000 val=0.916300 loss=0.027615 time: 18.369096 lr: 0.040000
INFO:root:[Epoch 132] train=0.991845 val=0.915600 loss=0.025911 time: 18.346338 lr: 0.040000
INFO:root:[Epoch 133] train=0.992308 val=0.917000 loss=0.025527 time: 18.529488 lr: 0.040000
INFO:root:[Epoch 134] train=0.991523 val=0.914800 loss=0.026775 time: 18.240749 lr: 0.040000
INFO:root:[Epoch 135] train=0.991865 val=0.915700 loss=0.025674 time: 18.760129 lr: 0.040000
INFO:root:[Epoch 136] train=0.991966 val=0.917300 loss=0.025274 time: 18.475501 lr: 0.040000
INFO:root:[Epoch 137] train=0.992933 val=0.914200 loss=0.024521 time: 18.351261 lr: 0.040000
INFO:root:[Epoch 138] train=0.993094 val=0.915900 loss=0.023949 time: 18.034865 lr: 0.040000
INFO:root:[Epoch 139] train=0.993436 val=0.916000 loss=0.022495 time: 18.210724 lr: 0.040000
INFO:root:[Epoch 140] train=0.992953 val=0.913000 loss=0.022371 time: 18.121540 lr: 0.040000
INFO:root:[Epoch 141] train=0.993073 val=0.916000 loss=0.023312 time: 18.053375 lr: 0.040000
INFO:root:[Epoch 142] train=0.993416 val=0.917300 loss=0.022504 time: 18.225788 lr: 0.040000
INFO:root:[Epoch 143] train=0.993174 val=0.915600 loss=0.021960 time: 18.219486 lr: 0.040000
INFO:root:[Epoch 144] train=0.993194 val=0.917800 loss=0.022131 time: 18.139966 lr: 0.040000
INFO:root:[Epoch 145] train=0.993315 val=0.917400 loss=0.020867 time: 17.912988 lr: 0.040000
INFO:root:[Epoch 146] train=0.993818 val=0.916400 loss=0.020622 time: 18.122876 lr: 0.040000
INFO:root:[Epoch 147] train=0.993899 val=0.916100 loss=0.020626 time: 17.854290 lr: 0.040000
INFO:root:[Epoch 148] train=0.993919 val=0.915200 loss=0.020813 time: 18.386851 lr: 0.040000
INFO:root:[Epoch 149] train=0.993839 val=0.912600 loss=0.019898 time: 17.967163 lr: 0.040000
INFO:root:[Epoch 150] train=0.995067 val=0.917000 loss=0.017603 time: 18.046855 lr: 0.004000
INFO:root:[Epoch 151] train=0.995812 val=0.916700 loss=0.015696 time: 17.991918 lr: 0.004000
INFO:root:[Epoch 152] train=0.996174 val=0.918100 loss=0.014158 time: 18.338528 lr: 0.004000
INFO:root:[Epoch 153] train=0.996275 val=0.917400 loss=0.014255 time: 18.196948 lr: 0.004000
INFO:root:[Epoch 154] train=0.996396 val=0.917100 loss=0.014185 time: 18.768542 lr: 0.004000
INFO:root:[Epoch 155] train=0.996476 val=0.918100 loss=0.014174 time: 18.359074 lr: 0.004000
INFO:root:[Epoch 156] train=0.996778 val=0.918700 loss=0.013078 time: 18.454278 lr: 0.004000
INFO:root:[Epoch 157] train=0.996658 val=0.917900 loss=0.013376 time: 18.318054 lr: 0.004000
INFO:root:[Epoch 158] train=0.997000 val=0.917900 loss=0.012630 time: 18.692781 lr: 0.004000
INFO:root:[Epoch 159] train=0.996879 val=0.917400 loss=0.012206 time: 18.206425 lr: 0.004000
INFO:root:[Epoch 160] train=0.996899 val=0.918500 loss=0.012138 time: 18.345520 lr: 0.004000
INFO:root:[Epoch 161] train=0.997503 val=0.918000 loss=0.011786 time: 17.903807 lr: 0.004000
INFO:root:[Epoch 162] train=0.997382 val=0.918800 loss=0.011643 time: 18.295274 lr: 0.004000
INFO:root:[Epoch 163] train=0.996778 val=0.918500 loss=0.013022 time: 18.151468 lr: 0.004000
INFO:root:[Epoch 164] train=0.997060 val=0.918500 loss=0.011957 time: 18.120975 lr: 0.004000
INFO:root:[Epoch 165] train=0.996839 val=0.918800 loss=0.012773 time: 18.063637 lr: 0.004000
INFO:root:[Epoch 166] train=0.997020 val=0.917500 loss=0.012231 time: 18.125685 lr: 0.004000
INFO:root:[Epoch 167] train=0.997342 val=0.918100 loss=0.011758 time: 18.362521 lr: 0.004000
INFO:root:[Epoch 168] train=0.997705 val=0.918100 loss=0.011049 time: 18.256458 lr: 0.004000
INFO:root:[Epoch 169] train=0.996798 val=0.918400 loss=0.012427 time: 18.475386 lr: 0.004000
INFO:root:[Epoch 170] train=0.997362 val=0.918500 loss=0.011616 time: 18.182977 lr: 0.004000
INFO:root:[Epoch 171] train=0.997906 val=0.919800 loss=0.010579 time: 18.423136 lr: 0.004000
INFO:root:[Epoch 172] train=0.997664 val=0.918100 loss=0.010669 time: 18.243854 lr: 0.004000
INFO:root:[Epoch 173] train=0.997503 val=0.918600 loss=0.011370 time: 18.134705 lr: 0.004000
INFO:root:[Epoch 174] train=0.997604 val=0.919700 loss=0.011003 time: 18.046886 lr: 0.004000
INFO:root:[Epoch 175] train=0.997342 val=0.919900 loss=0.011720 time: 18.527987 lr: 0.004000
INFO:root:[Epoch 176] train=0.997443 val=0.919300 loss=0.011487 time: 18.153528 lr: 0.004000
INFO:root:[Epoch 177] train=0.997765 val=0.919100 loss=0.010549 time: 18.563163 lr: 0.004000
INFO:root:[Epoch 178] train=0.997322 val=0.918900 loss=0.011498 time: 18.671833 lr: 0.004000
INFO:root:[Epoch 179] train=0.997926 val=0.918200 loss=0.010430 time: 18.059994 lr: 0.004000
INFO:root:[Epoch 180] train=0.997805 val=0.918200 loss=0.010438 time: 18.512466 lr: 0.004000
INFO:root:[Epoch 181] train=0.997342 val=0.917700 loss=0.011412 time: 18.439221 lr: 0.004000
INFO:root:[Epoch 182] train=0.997785 val=0.918200 loss=0.010552 time: 18.757681 lr: 0.004000
INFO:root:[Epoch 183] train=0.997684 val=0.919000 loss=0.010576 time: 18.753239 lr: 0.004000
INFO:root:[Epoch 184] train=0.997745 val=0.918400 loss=0.010100 time: 18.472407 lr: 0.004000
INFO:root:[Epoch 185] train=0.997805 val=0.918600 loss=0.010355 time: 18.213674 lr: 0.004000
INFO:root:[Epoch 186] train=0.997382 val=0.919200 loss=0.010967 time: 18.180580 lr: 0.004000
INFO:root:[Epoch 187] train=0.997624 val=0.918200 loss=0.010835 time: 18.478784 lr: 0.004000
INFO:root:[Epoch 188] train=0.997604 val=0.919100 loss=0.010520 time: 18.194664 lr: 0.004000
INFO:root:[Epoch 189] train=0.998087 val=0.919200 loss=0.010040 time: 18.482933 lr: 0.004000
INFO:root:[Epoch 190] train=0.998148 val=0.917800 loss=0.009789 time: 18.242520 lr: 0.004000
INFO:root:[Epoch 191] train=0.997584 val=0.918300 loss=0.010533 time: 18.309101 lr: 0.004000
INFO:root:[Epoch 192] train=0.997644 val=0.918200 loss=0.010474 time: 18.380375 lr: 0.004000
INFO:root:[Epoch 193] train=0.998047 val=0.918200 loss=0.010142 time: 18.473303 lr: 0.004000
INFO:root:[Epoch 194] train=0.997946 val=0.918200 loss=0.009965 time: 18.742006 lr: 0.004000
INFO:root:[Epoch 195] train=0.997785 val=0.917500 loss=0.010568 time: 18.590371 lr: 0.004000
INFO:root:[Epoch 196] train=0.997825 val=0.919000 loss=0.010137 time: 18.999297 lr: 0.004000
INFO:root:[Epoch 197] train=0.997805 val=0.918900 loss=0.010099 time: 18.769082 lr: 0.004000
INFO:root:[Epoch 198] train=0.997725 val=0.918300 loss=0.010304 time: 18.316685 lr: 0.004000
INFO:root:[Epoch 199] train=0.997866 val=0.918100 loss=0.009934 time: 18.086136 lr: 0.004000
