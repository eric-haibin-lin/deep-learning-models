INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='1', lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1_warm_5.0', save_period=10, save_plot_dir='bs_512_gpu_1_warm_5.0', warmup_epochs=5, wd=0.0001)
[02:48:52] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.350375 val=0.321800 loss=1.776574 time: 17.051012 lr: 0.079175
INFO:root:[Epoch 1] train=0.571521 val=0.467900 loss=1.187393 time: 16.901675 lr: 0.159175
INFO:root:[Epoch 2] train=0.681117 val=0.445300 loss=0.895787 time: 16.521305 lr: 0.239175
INFO:root:[Epoch 3] train=0.739469 val=0.546400 loss=0.747040 time: 16.419577 lr: 0.319175
INFO:root:[Epoch 4] train=0.770558 val=0.701200 loss=0.659305 time: 16.831512 lr: 0.399175
INFO:root:[Epoch 5] train=0.794278 val=0.675700 loss=0.592649 time: 16.355062 lr: 0.400000
INFO:root:[Epoch 6] train=0.814413 val=0.766500 loss=0.536095 time: 16.356368 lr: 0.400000
INFO:root:[Epoch 7] train=0.828206 val=0.786800 loss=0.498116 time: 16.493938 lr: 0.400000
INFO:root:[Epoch 8] train=0.836662 val=0.813300 loss=0.468177 time: 16.658266 lr: 0.400000
INFO:root:[Epoch 9] train=0.850777 val=0.801300 loss=0.437291 time: 16.191146 lr: 0.400000
INFO:root:[Epoch 10] train=0.854563 val=0.809000 loss=0.419925 time: 16.351445 lr: 0.400000
INFO:root:[Epoch 11] train=0.862456 val=0.826100 loss=0.398332 time: 16.440908 lr: 0.400000
INFO:root:[Epoch 12] train=0.866422 val=0.832200 loss=0.386774 time: 16.936417 lr: 0.400000
INFO:root:[Epoch 13] train=0.873792 val=0.755000 loss=0.368308 time: 16.861885 lr: 0.400000
INFO:root:[Epoch 14] train=0.874376 val=0.802500 loss=0.362766 time: 16.691406 lr: 0.400000
INFO:root:[Epoch 15] train=0.875584 val=0.819600 loss=0.354764 time: 16.995112 lr: 0.400000
INFO:root:[Epoch 16] train=0.881101 val=0.785500 loss=0.340662 time: 16.893050 lr: 0.400000
INFO:root:[Epoch 17] train=0.884907 val=0.828200 loss=0.333271 time: 16.541761 lr: 0.400000
INFO:root:[Epoch 18] train=0.887887 val=0.823900 loss=0.321807 time: 16.807140 lr: 0.400000
INFO:root:[Epoch 19] train=0.888531 val=0.828500 loss=0.322623 time: 16.546997 lr: 0.400000
INFO:root:[Epoch 20] train=0.890665 val=0.849200 loss=0.314762 time: 16.440659 lr: 0.400000
INFO:root:[Epoch 21] train=0.892034 val=0.848000 loss=0.308616 time: 16.609384 lr: 0.400000
INFO:root:[Epoch 22] train=0.894310 val=0.832600 loss=0.303778 time: 16.456722 lr: 0.400000
INFO:root:[Epoch 23] train=0.896645 val=0.831400 loss=0.296076 time: 16.490128 lr: 0.400000
INFO:root:[Epoch 24] train=0.898377 val=0.832200 loss=0.290968 time: 16.512204 lr: 0.400000
INFO:root:[Epoch 25] train=0.898256 val=0.830300 loss=0.291265 time: 16.586243 lr: 0.400000
INFO:root:[Epoch 26] train=0.902928 val=0.843400 loss=0.281468 time: 16.609434 lr: 0.400000
INFO:root:[Epoch 27] train=0.903834 val=0.811800 loss=0.274607 time: 16.557313 lr: 0.400000
INFO:root:[Epoch 28] train=0.903934 val=0.843300 loss=0.278106 time: 16.919107 lr: 0.400000
INFO:root:[Epoch 29] train=0.904599 val=0.846300 loss=0.271033 time: 16.619849 lr: 0.400000
INFO:root:[Epoch 30] train=0.905122 val=0.837400 loss=0.268006 time: 16.490549 lr: 0.400000
INFO:root:[Epoch 31] train=0.908686 val=0.830200 loss=0.262367 time: 16.392782 lr: 0.400000
INFO:root:[Epoch 32] train=0.908062 val=0.842800 loss=0.264393 time: 16.579354 lr: 0.400000
INFO:root:[Epoch 33] train=0.908928 val=0.835600 loss=0.261561 time: 16.480364 lr: 0.400000
INFO:root:[Epoch 34] train=0.909995 val=0.831800 loss=0.256219 time: 16.880866 lr: 0.400000
INFO:root:[Epoch 35] train=0.912854 val=0.816200 loss=0.253550 time: 16.793012 lr: 0.400000
INFO:root:[Epoch 36] train=0.912734 val=0.870500 loss=0.248941 time: 16.974234 lr: 0.400000
INFO:root:[Epoch 37] train=0.911203 val=0.804700 loss=0.248694 time: 16.370125 lr: 0.400000
INFO:root:[Epoch 38] train=0.913177 val=0.851100 loss=0.245079 time: 16.691613 lr: 0.400000
INFO:root:[Epoch 39] train=0.914767 val=0.840500 loss=0.243565 time: 16.454268 lr: 0.400000
INFO:root:[Epoch 40] train=0.915794 val=0.829300 loss=0.243238 time: 16.400767 lr: 0.400000
INFO:root:[Epoch 41] train=0.915452 val=0.842900 loss=0.240347 time: 16.706403 lr: 0.400000
INFO:root:[Epoch 42] train=0.913861 val=0.836700 loss=0.244427 time: 16.268301 lr: 0.400000
INFO:root:[Epoch 43] train=0.918814 val=0.854100 loss=0.235147 time: 16.849516 lr: 0.400000
INFO:root:[Epoch 44] train=0.918130 val=0.842000 loss=0.232128 time: 16.494538 lr: 0.400000
INFO:root:[Epoch 45] train=0.917304 val=0.856600 loss=0.234881 time: 16.847470 lr: 0.400000
INFO:root:[Epoch 46] train=0.920063 val=0.836700 loss=0.229263 time: 16.752280 lr: 0.400000
INFO:root:[Epoch 47] train=0.920848 val=0.752800 loss=0.227762 time: 16.586390 lr: 0.400000
INFO:root:[Epoch 48] train=0.921935 val=0.839300 loss=0.224511 time: 16.780825 lr: 0.400000
INFO:root:[Epoch 49] train=0.917888 val=0.855200 loss=0.230988 time: 16.260494 lr: 0.400000
INFO:root:[Epoch 50] train=0.923003 val=0.823100 loss=0.219043 time: 16.870923 lr: 0.400000
INFO:root:[Epoch 51] train=0.920788 val=0.831400 loss=0.224055 time: 16.750538 lr: 0.400000
INFO:root:[Epoch 52] train=0.919298 val=0.850300 loss=0.228663 time: 16.984677 lr: 0.400000
INFO:root:[Epoch 53] train=0.923305 val=0.838100 loss=0.218161 time: 16.736335 lr: 0.400000
INFO:root:[Epoch 54] train=0.921452 val=0.864300 loss=0.224882 time: 16.593993 lr: 0.400000
INFO:root:[Epoch 55] train=0.924251 val=0.829400 loss=0.219007 time: 16.542389 lr: 0.400000
INFO:root:[Epoch 56] train=0.922036 val=0.864600 loss=0.219047 time: 16.584353 lr: 0.400000
INFO:root:[Epoch 57] train=0.922358 val=0.822000 loss=0.217867 time: 16.686321 lr: 0.400000
INFO:root:[Epoch 58] train=0.922902 val=0.797500 loss=0.219313 time: 16.295837 lr: 0.400000
INFO:root:[Epoch 59] train=0.924332 val=0.833000 loss=0.213976 time: 16.999598 lr: 0.400000
INFO:root:[Epoch 60] train=0.925278 val=0.836100 loss=0.213561 time: 16.549788 lr: 0.400000
INFO:root:[Epoch 61] train=0.925358 val=0.836000 loss=0.214466 time: 16.755853 lr: 0.400000
INFO:root:[Epoch 62] train=0.925379 val=0.855800 loss=0.215908 time: 16.830440 lr: 0.400000
INFO:root:[Epoch 63] train=0.926647 val=0.836900 loss=0.209492 time: 16.749878 lr: 0.400000
INFO:root:[Epoch 64] train=0.925660 val=0.841900 loss=0.210565 time: 16.716682 lr: 0.400000
INFO:root:[Epoch 65] train=0.927130 val=0.832600 loss=0.208644 time: 16.742907 lr: 0.400000
INFO:root:[Epoch 66] train=0.924513 val=0.839600 loss=0.212564 time: 16.701603 lr: 0.400000
INFO:root:[Epoch 67] train=0.927150 val=0.847200 loss=0.205982 time: 16.550057 lr: 0.400000
INFO:root:[Epoch 68] train=0.926889 val=0.860600 loss=0.207587 time: 16.167926 lr: 0.400000
INFO:root:[Epoch 69] train=0.928016 val=0.846300 loss=0.207445 time: 16.685362 lr: 0.400000
INFO:root:[Epoch 70] train=0.926889 val=0.851200 loss=0.209405 time: 16.477620 lr: 0.400000
INFO:root:[Epoch 71] train=0.930030 val=0.826800 loss=0.201357 time: 16.585053 lr: 0.400000
INFO:root:[Epoch 72] train=0.925902 val=0.853800 loss=0.206300 time: 16.579985 lr: 0.400000
INFO:root:[Epoch 73] train=0.926164 val=0.853000 loss=0.208233 time: 16.853625 lr: 0.400000
INFO:root:[Epoch 74] train=0.927795 val=0.837200 loss=0.203272 time: 16.923496 lr: 0.400000
INFO:root:[Epoch 75] train=0.928862 val=0.833100 loss=0.202033 time: 16.925364 lr: 0.400000
INFO:root:[Epoch 76] train=0.929023 val=0.867000 loss=0.200134 time: 16.902561 lr: 0.400000
INFO:root:[Epoch 77] train=0.931077 val=0.836600 loss=0.198554 time: 16.405562 lr: 0.400000
INFO:root:[Epoch 78] train=0.929768 val=0.848400 loss=0.198320 time: 16.502788 lr: 0.400000
INFO:root:[Epoch 79] train=0.928661 val=0.858800 loss=0.201981 time: 16.765420 lr: 0.400000
INFO:root:[Epoch 80] train=0.930795 val=0.846900 loss=0.197422 time: 16.847677 lr: 0.400000
INFO:root:[Epoch 81] train=0.928942 val=0.856500 loss=0.200690 time: 16.611259 lr: 0.400000
INFO:root:[Epoch 82] train=0.930171 val=0.846200 loss=0.197969 time: 16.642226 lr: 0.400000
INFO:root:[Epoch 83] train=0.930775 val=0.822700 loss=0.197826 time: 16.753955 lr: 0.400000
INFO:root:[Epoch 84] train=0.930473 val=0.825400 loss=0.197385 time: 16.571859 lr: 0.400000
INFO:root:[Epoch 85] train=0.930835 val=0.805700 loss=0.196580 time: 16.244865 lr: 0.400000
INFO:root:[Epoch 86] train=0.931480 val=0.855300 loss=0.196072 time: 16.390987 lr: 0.400000
INFO:root:[Epoch 87] train=0.930735 val=0.859100 loss=0.197038 time: 16.730748 lr: 0.400000
INFO:root:[Epoch 88] train=0.929969 val=0.851300 loss=0.199132 time: 16.985951 lr: 0.400000
INFO:root:[Epoch 89] train=0.930835 val=0.871600 loss=0.193559 time: 16.952907 lr: 0.400000
INFO:root:[Epoch 90] train=0.931057 val=0.860400 loss=0.194355 time: 16.818652 lr: 0.400000
INFO:root:[Epoch 91] train=0.932949 val=0.856800 loss=0.191774 time: 16.771305 lr: 0.400000
INFO:root:[Epoch 92] train=0.932829 val=0.855300 loss=0.190503 time: 16.797082 lr: 0.400000
INFO:root:[Epoch 93] train=0.931298 val=0.811800 loss=0.193373 time: 16.673107 lr: 0.400000
INFO:root:[Epoch 94] train=0.931077 val=0.863100 loss=0.194231 time: 17.110060 lr: 0.400000
INFO:root:[Epoch 95] train=0.931157 val=0.853800 loss=0.192375 time: 16.844575 lr: 0.400000
INFO:root:[Epoch 96] train=0.930916 val=0.860300 loss=0.195020 time: 16.788509 lr: 0.400000
INFO:root:[Epoch 97] train=0.934178 val=0.861200 loss=0.186103 time: 16.888212 lr: 0.400000
INFO:root:[Epoch 98] train=0.932225 val=0.870800 loss=0.191511 time: 16.973608 lr: 0.400000
INFO:root:[Epoch 99] train=0.933775 val=0.856900 loss=0.188179 time: 16.710775 lr: 0.400000
INFO:root:[Epoch 100] train=0.959206 val=0.911400 loss=0.121568 time: 16.527751 lr: 0.040000
INFO:root:[Epoch 101] train=0.969878 val=0.913300 loss=0.089939 time: 16.701867 lr: 0.040000
INFO:root:[Epoch 102] train=0.974388 val=0.915900 loss=0.079621 time: 16.718617 lr: 0.040000
INFO:root:[Epoch 103] train=0.975354 val=0.914300 loss=0.073710 time: 16.514035 lr: 0.040000
INFO:root:[Epoch 104] train=0.976865 val=0.915800 loss=0.068715 time: 16.566648 lr: 0.040000
INFO:root:[Epoch 105] train=0.980227 val=0.917000 loss=0.061055 time: 16.600242 lr: 0.040000
INFO:root:[Epoch 106] train=0.980489 val=0.914900 loss=0.060661 time: 16.405083 lr: 0.040000
INFO:root:[Epoch 107] train=0.982603 val=0.916400 loss=0.055336 time: 16.222697 lr: 0.040000
INFO:root:[Epoch 108] train=0.983026 val=0.914800 loss=0.053048 time: 16.703929 lr: 0.040000
INFO:root:[Epoch 109] train=0.982120 val=0.915800 loss=0.053438 time: 16.622641 lr: 0.040000
INFO:root:[Epoch 110] train=0.984536 val=0.918100 loss=0.048002 time: 16.799222 lr: 0.040000
INFO:root:[Epoch 111] train=0.985684 val=0.916000 loss=0.045837 time: 16.477756 lr: 0.040000
INFO:root:[Epoch 112] train=0.985764 val=0.918800 loss=0.043970 time: 16.914892 lr: 0.040000
INFO:root:[Epoch 113] train=0.986610 val=0.916100 loss=0.042682 time: 16.893607 lr: 0.040000
INFO:root:[Epoch 114] train=0.986912 val=0.917300 loss=0.041425 time: 16.970385 lr: 0.040000
INFO:root:[Epoch 115] train=0.987778 val=0.914700 loss=0.039954 time: 16.442635 lr: 0.040000
INFO:root:[Epoch 116] train=0.987315 val=0.916300 loss=0.039689 time: 16.450090 lr: 0.040000
INFO:root:[Epoch 117] train=0.988342 val=0.917400 loss=0.037047 time: 16.912241 lr: 0.040000
INFO:root:[Epoch 118] train=0.988241 val=0.916700 loss=0.036008 time: 17.063737 lr: 0.040000
INFO:root:[Epoch 119] train=0.987838 val=0.916500 loss=0.036728 time: 16.722765 lr: 0.040000
INFO:root:[Epoch 120] train=0.989026 val=0.915900 loss=0.034156 time: 16.758572 lr: 0.040000
INFO:root:[Epoch 121] train=0.989228 val=0.914100 loss=0.033484 time: 16.530081 lr: 0.040000
INFO:root:[Epoch 122] train=0.989389 val=0.914100 loss=0.033019 time: 16.757767 lr: 0.040000
INFO:root:[Epoch 123] train=0.989167 val=0.914500 loss=0.032859 time: 16.364243 lr: 0.040000
INFO:root:[Epoch 124] train=0.990597 val=0.915500 loss=0.031340 time: 16.867097 lr: 0.040000
INFO:root:[Epoch 125] train=0.990315 val=0.914100 loss=0.030098 time: 16.545208 lr: 0.040000
INFO:root:[Epoch 126] train=0.990939 val=0.916100 loss=0.029884 time: 16.774028 lr: 0.040000
INFO:root:[Epoch 127] train=0.991382 val=0.916000 loss=0.028013 time: 16.729825 lr: 0.040000
INFO:root:[Epoch 128] train=0.990637 val=0.916500 loss=0.028710 time: 17.511151 lr: 0.040000
INFO:root:[Epoch 129] train=0.991281 val=0.915100 loss=0.027395 time: 16.782267 lr: 0.040000
INFO:root:[Epoch 130] train=0.991885 val=0.916200 loss=0.026875 time: 16.863970 lr: 0.040000
INFO:root:[Epoch 131] train=0.992087 val=0.914700 loss=0.025716 time: 16.676456 lr: 0.040000
INFO:root:[Epoch 132] train=0.992630 val=0.914700 loss=0.024165 time: 16.541110 lr: 0.040000
INFO:root:[Epoch 133] train=0.993073 val=0.914200 loss=0.024212 time: 16.845088 lr: 0.040000
INFO:root:[Epoch 134] train=0.992711 val=0.915600 loss=0.024253 time: 16.783712 lr: 0.040000
INFO:root:[Epoch 135] train=0.992671 val=0.914000 loss=0.024004 time: 16.689706 lr: 0.040000
INFO:root:[Epoch 136] train=0.993718 val=0.915700 loss=0.022168 time: 16.956837 lr: 0.040000
INFO:root:[Epoch 137] train=0.992691 val=0.915100 loss=0.023111 time: 16.740990 lr: 0.040000
INFO:root:[Epoch 138] train=0.992832 val=0.914400 loss=0.023704 time: 16.893198 lr: 0.040000
INFO:root:[Epoch 139] train=0.993516 val=0.914300 loss=0.021898 time: 16.681014 lr: 0.040000
INFO:root:[Epoch 140] train=0.993476 val=0.916000 loss=0.021900 time: 16.885212 lr: 0.040000
INFO:root:[Epoch 141] train=0.992933 val=0.917100 loss=0.022708 time: 16.744925 lr: 0.040000
INFO:root:[Epoch 142] train=0.993214 val=0.916400 loss=0.021833 time: 16.832138 lr: 0.040000
INFO:root:[Epoch 143] train=0.992792 val=0.914900 loss=0.022368 time: 16.375377 lr: 0.040000
INFO:root:[Epoch 144] train=0.993255 val=0.914900 loss=0.021507 time: 16.892105 lr: 0.040000
INFO:root:[Epoch 145] train=0.993436 val=0.914200 loss=0.020915 time: 16.637293 lr: 0.040000
INFO:root:[Epoch 146] train=0.993778 val=0.914300 loss=0.020569 time: 16.776059 lr: 0.040000
INFO:root:[Epoch 147] train=0.993577 val=0.917600 loss=0.020128 time: 16.717881 lr: 0.040000
INFO:root:[Epoch 148] train=0.993899 val=0.914100 loss=0.020408 time: 16.542076 lr: 0.040000
INFO:root:[Epoch 149] train=0.994100 val=0.912900 loss=0.019288 time: 16.649081 lr: 0.040000
INFO:root:[Epoch 150] train=0.995772 val=0.916400 loss=0.016165 time: 16.569490 lr: 0.004000
INFO:root:[Epoch 151] train=0.996376 val=0.916400 loss=0.014119 time: 17.052736 lr: 0.004000
INFO:root:[Epoch 152] train=0.995993 val=0.917300 loss=0.013768 time: 16.607631 lr: 0.004000
INFO:root:[Epoch 153] train=0.996496 val=0.917100 loss=0.013568 time: 17.165717 lr: 0.004000
INFO:root:[Epoch 154] train=0.996053 val=0.917000 loss=0.014209 time: 16.398953 lr: 0.004000
INFO:root:[Epoch 155] train=0.997282 val=0.918200 loss=0.012639 time: 16.909806 lr: 0.004000
INFO:root:[Epoch 156] train=0.996879 val=0.917600 loss=0.012662 time: 17.150821 lr: 0.004000
INFO:root:[Epoch 157] train=0.996557 val=0.917100 loss=0.013648 time: 17.415981 lr: 0.004000
INFO:root:[Epoch 158] train=0.997020 val=0.916000 loss=0.013162 time: 16.662905 lr: 0.004000
INFO:root:[Epoch 159] train=0.996658 val=0.918000 loss=0.012819 time: 17.190568 lr: 0.004000
INFO:root:[Epoch 160] train=0.996879 val=0.917200 loss=0.013125 time: 16.700206 lr: 0.004000
INFO:root:[Epoch 161] train=0.997161 val=0.917700 loss=0.011769 time: 16.842987 lr: 0.004000
INFO:root:[Epoch 162] train=0.997483 val=0.917700 loss=0.011707 time: 16.861773 lr: 0.004000
INFO:root:[Epoch 163] train=0.996960 val=0.917700 loss=0.012349 time: 16.586303 lr: 0.004000
INFO:root:[Epoch 164] train=0.996859 val=0.917300 loss=0.012238 time: 16.563898 lr: 0.004000
INFO:root:[Epoch 165] train=0.997141 val=0.916900 loss=0.011538 time: 16.354078 lr: 0.004000
INFO:root:[Epoch 166] train=0.997282 val=0.917200 loss=0.011829 time: 16.700812 lr: 0.004000
INFO:root:[Epoch 167] train=0.997040 val=0.917200 loss=0.011836 time: 16.839622 lr: 0.004000
INFO:root:[Epoch 168] train=0.997483 val=0.917100 loss=0.010984 time: 16.578817 lr: 0.004000
INFO:root:[Epoch 169] train=0.997342 val=0.918000 loss=0.011302 time: 15.760149 lr: 0.004000
INFO:root:[Epoch 170] train=0.997443 val=0.917800 loss=0.011358 time: 15.548243 lr: 0.004000
INFO:root:[Epoch 171] train=0.997382 val=0.918800 loss=0.011845 time: 15.734335 lr: 0.004000
INFO:root:[Epoch 172] train=0.997060 val=0.917400 loss=0.012146 time: 16.357114 lr: 0.004000
INFO:root:[Epoch 173] train=0.997282 val=0.918200 loss=0.011254 time: 16.365289 lr: 0.004000
INFO:root:[Epoch 174] train=0.997403 val=0.917600 loss=0.011198 time: 16.536800 lr: 0.004000
INFO:root:[Epoch 175] train=0.997584 val=0.918200 loss=0.010822 time: 16.886772 lr: 0.004000
INFO:root:[Epoch 176] train=0.997342 val=0.917700 loss=0.011420 time: 15.984230 lr: 0.004000
INFO:root:[Epoch 177] train=0.997564 val=0.918100 loss=0.011462 time: 15.787500 lr: 0.004000
INFO:root:[Epoch 178] train=0.997322 val=0.917000 loss=0.010763 time: 16.064209 lr: 0.004000
INFO:root:[Epoch 179] train=0.998168 val=0.918300 loss=0.010100 time: 16.563684 lr: 0.004000
INFO:root:[Epoch 180] train=0.997362 val=0.917700 loss=0.010838 time: 15.734120 lr: 0.004000
INFO:root:[Epoch 181] train=0.997946 val=0.918300 loss=0.009826 time: 14.952836 lr: 0.004000
INFO:root:[Epoch 182] train=0.997785 val=0.916800 loss=0.010220 time: 14.508425 lr: 0.004000
INFO:root:[Epoch 183] train=0.997866 val=0.917400 loss=0.010592 time: 14.837027 lr: 0.004000
INFO:root:[Epoch 184] train=0.997584 val=0.916800 loss=0.010816 time: 14.815878 lr: 0.004000
INFO:root:[Epoch 185] train=0.997644 val=0.917500 loss=0.010590 time: 15.136557 lr: 0.004000
INFO:root:[Epoch 186] train=0.997684 val=0.918100 loss=0.010332 time: 15.917859 lr: 0.004000
INFO:root:[Epoch 187] train=0.997866 val=0.918200 loss=0.010276 time: 15.976632 lr: 0.004000
INFO:root:[Epoch 188] train=0.997483 val=0.918500 loss=0.010859 time: 15.328958 lr: 0.004000
INFO:root:[Epoch 189] train=0.998007 val=0.918000 loss=0.010554 time: 14.879326 lr: 0.004000
INFO:root:[Epoch 190] train=0.997221 val=0.917800 loss=0.010791 time: 15.021518 lr: 0.004000
INFO:root:[Epoch 191] train=0.997624 val=0.917600 loss=0.010468 time: 14.983440 lr: 0.004000
INFO:root:[Epoch 192] train=0.997423 val=0.917100 loss=0.010785 time: 14.946421 lr: 0.004000
INFO:root:[Epoch 193] train=0.997745 val=0.918500 loss=0.010537 time: 14.976990 lr: 0.004000
INFO:root:[Epoch 194] train=0.997866 val=0.917500 loss=0.010274 time: 15.260477 lr: 0.004000
INFO:root:[Epoch 195] train=0.997705 val=0.917700 loss=0.010272 time: 14.846923 lr: 0.004000
INFO:root:[Epoch 196] train=0.997846 val=0.918200 loss=0.010457 time: 14.581564 lr: 0.004000
INFO:root:[Epoch 197] train=0.997825 val=0.917700 loss=0.009982 time: 14.942209 lr: 0.004000
INFO:root:[Epoch 198] train=0.998047 val=0.917800 loss=0.009472 time: 14.900003 lr: 0.004000
INFO:root:[Epoch 199] train=0.997644 val=0.917800 loss=0.010237 time: 14.886454 lr: 0.004000
