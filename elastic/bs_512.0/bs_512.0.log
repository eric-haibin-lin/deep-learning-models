INFO:root:Namespace(batch_size=128, drop_rate=0.0, gpus='0,1,2,3', lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512.0', save_period=10, save_plot_dir='bs_512.0', wd=0.0001)
[06:23:49] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.218327 val=0.299300 loss=2.143466 time: 18.411004
INFO:root:[Epoch 1] train=0.364530 val=0.431900 loss=1.683909 time: 16.210377
INFO:root:[Epoch 2] train=0.478314 val=0.475700 loss=1.420999 time: 16.041110
INFO:root:[Epoch 3] train=0.580038 val=0.584300 loss=1.169826 time: 15.494821
INFO:root:[Epoch 4] train=0.649303 val=0.615300 loss=0.982946 time: 15.228517
INFO:root:[Epoch 5] train=0.697266 val=0.637800 loss=0.858741 time: 15.919254
INFO:root:[Epoch 6] train=0.732804 val=0.700900 loss=0.760478 time: 15.574405
INFO:root:[Epoch 7] train=0.761598 val=0.721000 loss=0.682159 time: 15.378592
INFO:root:[Epoch 8] train=0.784915 val=0.722900 loss=0.622462 time: 15.545900
INFO:root:[Epoch 9] train=0.799593 val=0.678700 loss=0.577465 time: 15.075855
INFO:root:[Epoch 10] train=0.810869 val=0.720500 loss=0.542861 time: 15.688838
INFO:root:[Epoch 11] train=0.820957 val=0.788200 loss=0.514491 time: 15.630156
INFO:root:[Epoch 12] train=0.830058 val=0.808300 loss=0.487002 time: 15.873417
INFO:root:[Epoch 13] train=0.836985 val=0.816200 loss=0.473073 time: 15.611833
INFO:root:[Epoch 14] train=0.843327 val=0.799100 loss=0.451091 time: 16.234323
INFO:root:[Epoch 15] train=0.848039 val=0.681700 loss=0.439088 time: 16.754487
INFO:root:[Epoch 16] train=0.850395 val=0.754200 loss=0.426977 time: 15.992865
INFO:root:[Epoch 17] train=0.857321 val=0.804000 loss=0.411885 time: 15.546862
INFO:root:[Epoch 18] train=0.863301 val=0.806600 loss=0.395178 time: 15.865047
INFO:root:[Epoch 19] train=0.863402 val=0.815300 loss=0.389016 time: 15.548335
INFO:root:[Epoch 20] train=0.870329 val=0.824400 loss=0.377502 time: 16.122004
INFO:root:[Epoch 21] train=0.872886 val=0.806900 loss=0.369168 time: 15.488481
INFO:root:[Epoch 22] train=0.874456 val=0.817800 loss=0.361595 time: 15.761443
INFO:root:[Epoch 23] train=0.877698 val=0.776200 loss=0.354836 time: 16.243349
INFO:root:[Epoch 24] train=0.877597 val=0.801800 loss=0.348339 time: 16.211739
INFO:root:[Epoch 25] train=0.881403 val=0.809700 loss=0.341588 time: 15.984514
INFO:root:[Epoch 26] train=0.885007 val=0.820400 loss=0.330941 time: 16.118285
INFO:root:[Epoch 27] train=0.884927 val=0.815700 loss=0.329168 time: 16.008197
INFO:root:[Epoch 28] train=0.887786 val=0.816200 loss=0.323935 time: 15.980907
INFO:root:[Epoch 29] train=0.891934 val=0.816900 loss=0.313941 time: 15.891366
INFO:root:[Epoch 30] train=0.892598 val=0.852100 loss=0.311958 time: 15.867465
INFO:root:[Epoch 31] train=0.891189 val=0.807200 loss=0.312545 time: 16.065555
INFO:root:[Epoch 32] train=0.893283 val=0.798500 loss=0.304873 time: 15.941228
INFO:root:[Epoch 33] train=0.895639 val=0.836900 loss=0.300480 time: 15.732348
INFO:root:[Epoch 34] train=0.898135 val=0.822200 loss=0.292644 time: 15.990637
INFO:root:[Epoch 35] train=0.898800 val=0.833100 loss=0.291812 time: 15.617448
INFO:root:[Epoch 36] train=0.899142 val=0.804600 loss=0.288753 time: 15.634308
INFO:root:[Epoch 37] train=0.900350 val=0.820700 loss=0.283034 time: 15.509939
INFO:root:[Epoch 38] train=0.900652 val=0.830500 loss=0.282215 time: 16.109483
INFO:root:[Epoch 39] train=0.903934 val=0.826000 loss=0.277561 time: 15.720976
INFO:root:[Epoch 40] train=0.903089 val=0.791800 loss=0.278371 time: 16.340950
INFO:root:[Epoch 41] train=0.906169 val=0.820700 loss=0.271651 time: 15.915778
INFO:root:[Epoch 42] train=0.903975 val=0.827100 loss=0.273661 time: 15.628501
INFO:root:[Epoch 43] train=0.908626 val=0.836300 loss=0.263218 time: 16.064894
INFO:root:[Epoch 44] train=0.907196 val=0.822400 loss=0.264109 time: 16.470512
INFO:root:[Epoch 45] train=0.907720 val=0.831500 loss=0.265001 time: 16.077551
INFO:root:[Epoch 46] train=0.910499 val=0.852100 loss=0.257705 time: 15.486556
INFO:root:[Epoch 47] train=0.909069 val=0.844600 loss=0.257611 time: 15.587187
INFO:root:[Epoch 48] train=0.908908 val=0.857300 loss=0.256987 time: 15.515666
INFO:root:[Epoch 49] train=0.911546 val=0.836800 loss=0.252417 time: 15.441618
INFO:root:[Epoch 50] train=0.913982 val=0.854300 loss=0.250955 time: 16.235317
INFO:root:[Epoch 51] train=0.911485 val=0.839200 loss=0.249448 time: 16.747400
INFO:root:[Epoch 52] train=0.914062 val=0.834200 loss=0.248278 time: 15.937204
INFO:root:[Epoch 53] train=0.913861 val=0.849300 loss=0.244133 time: 15.564755
INFO:root:[Epoch 54] train=0.913740 val=0.849300 loss=0.246119 time: 15.956724
INFO:root:[Epoch 55] train=0.915170 val=0.716100 loss=0.242451 time: 15.848164
INFO:root:[Epoch 56] train=0.915412 val=0.867700 loss=0.242511 time: 15.699371
INFO:root:[Epoch 57] train=0.917224 val=0.816800 loss=0.238298 time: 15.448755
INFO:root:[Epoch 58] train=0.917083 val=0.854600 loss=0.235884 time: 15.695587
INFO:root:[Epoch 59] train=0.916861 val=0.792800 loss=0.237274 time: 16.179130
INFO:root:[Epoch 60] train=0.916398 val=0.869300 loss=0.235875 time: 16.014837
INFO:root:[Epoch 61] train=0.918774 val=0.859100 loss=0.234468 time: 15.872536
INFO:root:[Epoch 62] train=0.919278 val=0.860600 loss=0.230330 time: 16.157320
INFO:root:[Epoch 63] train=0.920949 val=0.855100 loss=0.226530 time: 15.240677
INFO:root:[Epoch 64] train=0.917244 val=0.855900 loss=0.234332 time: 15.514657
INFO:root:[Epoch 65] train=0.921070 val=0.843600 loss=0.226753 time: 16.028665
INFO:root:[Epoch 66] train=0.922882 val=0.860300 loss=0.220416 time: 16.272712
INFO:root:[Epoch 67] train=0.919479 val=0.815200 loss=0.228504 time: 16.248440
INFO:root:[Epoch 68] train=0.920486 val=0.846200 loss=0.224434 time: 15.325477
INFO:root:[Epoch 69] train=0.921472 val=0.852900 loss=0.224123 time: 15.670065
INFO:root:[Epoch 70] train=0.921049 val=0.843400 loss=0.222488 time: 15.609539
INFO:root:[Epoch 71] train=0.920224 val=0.852700 loss=0.224474 time: 15.731227
INFO:root:[Epoch 72] train=0.923184 val=0.804000 loss=0.218203 time: 15.841018
INFO:root:[Epoch 73] train=0.922781 val=0.837000 loss=0.218431 time: 15.925448
INFO:root:[Epoch 74] train=0.923425 val=0.821000 loss=0.218483 time: 16.150912
INFO:root:[Epoch 75] train=0.921976 val=0.862600 loss=0.219969 time: 16.122496
INFO:root:[Epoch 76] train=0.922962 val=0.832900 loss=0.218736 time: 15.664685
INFO:root:[Epoch 77] train=0.924110 val=0.825300 loss=0.214562 time: 15.720093
INFO:root:[Epoch 78] train=0.924110 val=0.865400 loss=0.218226 time: 15.842508
INFO:root:[Epoch 79] train=0.925177 val=0.817900 loss=0.213684 time: 15.674059
INFO:root:[Epoch 80] train=0.925439 val=0.848800 loss=0.213515 time: 15.552514
INFO:root:[Epoch 81] train=0.925902 val=0.849600 loss=0.212721 time: 15.839149
INFO:root:[Epoch 82] train=0.925842 val=0.848100 loss=0.211582 time: 16.217892
INFO:root:[Epoch 83] train=0.924634 val=0.859100 loss=0.214871 time: 16.125630
INFO:root:[Epoch 84] train=0.927070 val=0.871400 loss=0.208227 time: 16.166358
INFO:root:[Epoch 85] train=0.925741 val=0.847700 loss=0.214355 time: 15.619054
INFO:root:[Epoch 86] train=0.926083 val=0.831300 loss=0.209072 time: 15.881085
INFO:root:[Epoch 87] train=0.926124 val=0.862000 loss=0.213876 time: 15.747060
INFO:root:[Epoch 88] train=0.928318 val=0.844900 loss=0.203317 time: 16.013742
INFO:root:[Epoch 89] train=0.926244 val=0.847900 loss=0.209475 time: 15.592314
INFO:root:[Epoch 90] train=0.925318 val=0.844400 loss=0.210011 time: 15.760249
INFO:root:[Epoch 91] train=0.926325 val=0.846900 loss=0.206954 time: 15.871782
INFO:root:[Epoch 92] train=0.927895 val=0.851000 loss=0.205766 time: 16.167154
INFO:root:[Epoch 93] train=0.929285 val=0.858200 loss=0.203301 time: 16.089025
INFO:root:[Epoch 94] train=0.927654 val=0.845700 loss=0.206247 time: 16.210274
INFO:root:[Epoch 95] train=0.928681 val=0.861100 loss=0.203688 time: 15.678677
INFO:root:[Epoch 96] train=0.927473 val=0.823700 loss=0.205939 time: 16.029056
INFO:root:[Epoch 97] train=0.928258 val=0.867200 loss=0.201535 time: 15.100049
INFO:root:[Epoch 98] train=0.928318 val=0.838900 loss=0.203061 time: 16.014125
INFO:root:[Epoch 99] train=0.929607 val=0.817500 loss=0.202108 time: 15.537553
INFO:root:[Epoch 100] train=0.953850 val=0.908500 loss=0.137415 time: 16.410937
INFO:root:[Epoch 101] train=0.965367 val=0.910900 loss=0.102863 time: 15.957677
INFO:root:[Epoch 102] train=0.970401 val=0.913400 loss=0.091476 time: 15.654262
INFO:root:[Epoch 103] train=0.971831 val=0.912800 loss=0.084714 time: 15.963120
INFO:root:[Epoch 104] train=0.973683 val=0.914000 loss=0.078821 time: 16.367517
INFO:root:[Epoch 105] train=0.975495 val=0.915000 loss=0.074754 time: 15.721887
INFO:root:[Epoch 106] train=0.975858 val=0.915800 loss=0.071370 time: 16.026977
INFO:root:[Epoch 107] train=0.977247 val=0.915100 loss=0.069207 time: 15.679347
INFO:root:[Epoch 108] train=0.978536 val=0.914700 loss=0.066305 time: 15.775960
INFO:root:[Epoch 109] train=0.978757 val=0.913000 loss=0.063590 time: 16.525316
INFO:root:[Epoch 110] train=0.979100 val=0.913900 loss=0.062880 time: 16.258913
INFO:root:[Epoch 111] train=0.980489 val=0.915800 loss=0.058050 time: 15.706489
INFO:root:[Epoch 112] train=0.981918 val=0.912900 loss=0.056607 time: 16.158408
INFO:root:[Epoch 113] train=0.983388 val=0.914200 loss=0.053243 time: 15.672399
INFO:root:[Epoch 114] train=0.982523 val=0.914800 loss=0.052731 time: 15.738094
INFO:root:[Epoch 115] train=0.982643 val=0.914300 loss=0.052315 time: 16.038465
INFO:root:[Epoch 116] train=0.983187 val=0.913900 loss=0.051133 time: 15.738013
INFO:root:[Epoch 117] train=0.983771 val=0.914400 loss=0.048752 time: 15.658206
INFO:root:[Epoch 118] train=0.984637 val=0.914700 loss=0.048270 time: 16.069345
INFO:root:[Epoch 119] train=0.984959 val=0.913400 loss=0.046970 time: 15.919823
INFO:root:[Epoch 120] train=0.985100 val=0.915100 loss=0.045207 time: 16.216028
INFO:root:[Epoch 121] train=0.986449 val=0.912000 loss=0.042548 time: 15.599306
INFO:root:[Epoch 122] train=0.986147 val=0.913400 loss=0.042314 time: 15.773142
INFO:root:[Epoch 123] train=0.986368 val=0.913300 loss=0.042019 time: 15.928221
INFO:root:[Epoch 124] train=0.987093 val=0.914600 loss=0.041003 time: 16.263853
INFO:root:[Epoch 125] train=0.987194 val=0.914800 loss=0.039013 time: 15.832371
INFO:root:[Epoch 126] train=0.988181 val=0.913300 loss=0.037742 time: 16.148750
INFO:root:[Epoch 127] train=0.988462 val=0.915900 loss=0.037297 time: 16.260267
INFO:root:[Epoch 128] train=0.988201 val=0.917200 loss=0.037500 time: 15.816718
INFO:root:[Epoch 129] train=0.987134 val=0.915000 loss=0.037759 time: 16.282962
INFO:root:[Epoch 130] train=0.988664 val=0.918500 loss=0.036148 time: 15.776900
INFO:root:[Epoch 131] train=0.988744 val=0.915600 loss=0.035200 time: 15.673299
INFO:root:[Epoch 132] train=0.988483 val=0.915200 loss=0.034994 time: 15.460981
INFO:root:[Epoch 133] train=0.988905 val=0.915100 loss=0.033393 time: 16.079023
INFO:root:[Epoch 134] train=0.989751 val=0.916200 loss=0.033104 time: 15.586394
INFO:root:[Epoch 135] train=0.989328 val=0.914500 loss=0.033303 time: 15.892451
INFO:root:[Epoch 136] train=0.989409 val=0.911900 loss=0.034246 time: 16.156307
INFO:root:[Epoch 137] train=0.989429 val=0.914400 loss=0.033127 time: 16.256433
INFO:root:[Epoch 138] train=0.989671 val=0.913800 loss=0.032070 time: 16.233535
INFO:root:[Epoch 139] train=0.989892 val=0.910700 loss=0.031434 time: 15.870032
INFO:root:[Epoch 140] train=0.989510 val=0.913300 loss=0.032583 time: 15.594171
INFO:root:[Epoch 141] train=0.989771 val=0.912900 loss=0.030857 time: 16.000265
INFO:root:[Epoch 142] train=0.990416 val=0.915900 loss=0.030996 time: 15.939045
INFO:root:[Epoch 143] train=0.989590 val=0.911800 loss=0.030753 time: 15.990362
INFO:root:[Epoch 144] train=0.990295 val=0.913300 loss=0.029978 time: 15.647065
INFO:root:[Epoch 145] train=0.990234 val=0.914200 loss=0.030568 time: 16.529193
INFO:root:[Epoch 146] train=0.991442 val=0.914000 loss=0.028692 time: 15.736599
INFO:root:[Epoch 147] train=0.991201 val=0.911600 loss=0.027904 time: 16.216623
INFO:root:[Epoch 148] train=0.990919 val=0.911900 loss=0.028043 time: 15.321761
INFO:root:[Epoch 149] train=0.991040 val=0.915000 loss=0.028849 time: 16.017642
INFO:root:[Epoch 150] train=0.992188 val=0.917700 loss=0.025179 time: 16.725384
INFO:root:[Epoch 151] train=0.994161 val=0.918500 loss=0.020843 time: 15.984004
INFO:root:[Epoch 152] train=0.994080 val=0.918100 loss=0.021083 time: 16.456374
INFO:root:[Epoch 153] train=0.994423 val=0.917000 loss=0.019987 time: 16.013857
INFO:root:[Epoch 154] train=0.994161 val=0.917600 loss=0.020400 time: 16.105921
INFO:root:[Epoch 155] train=0.994423 val=0.917300 loss=0.020151 time: 16.042169
INFO:root:[Epoch 156] train=0.994825 val=0.916600 loss=0.019362 time: 15.553046
INFO:root:[Epoch 157] train=0.994100 val=0.917500 loss=0.020357 time: 15.756529
INFO:root:[Epoch 158] train=0.995107 val=0.917800 loss=0.017933 time: 15.576025
INFO:root:[Epoch 159] train=0.995087 val=0.917800 loss=0.018707 time: 16.158830
INFO:root:[Epoch 160] train=0.994543 val=0.917500 loss=0.018502 time: 16.707565
INFO:root:[Epoch 161] train=0.994604 val=0.917300 loss=0.018566 time: 16.906332
INFO:root:[Epoch 162] train=0.995107 val=0.917100 loss=0.018170 time: 16.743349
INFO:root:[Epoch 163] train=0.995208 val=0.917100 loss=0.018620 time: 16.637722
INFO:root:[Epoch 164] train=0.994906 val=0.917600 loss=0.018627 time: 17.000275
INFO:root:[Epoch 165] train=0.995067 val=0.916800 loss=0.018143 time: 17.035579
INFO:root:[Epoch 166] train=0.995087 val=0.917400 loss=0.018461 time: 17.355647
INFO:root:[Epoch 167] train=0.994986 val=0.916400 loss=0.018569 time: 17.482179
INFO:root:[Epoch 168] train=0.995349 val=0.916300 loss=0.017124 time: 17.416339
INFO:root:[Epoch 169] train=0.995631 val=0.916300 loss=0.017414 time: 17.540210
INFO:root:[Epoch 170] train=0.995308 val=0.916500 loss=0.017356 time: 17.386089
INFO:root:[Epoch 171] train=0.995490 val=0.917100 loss=0.017398 time: 17.418515
INFO:root:[Epoch 172] train=0.995651 val=0.917800 loss=0.017117 time: 17.891381
INFO:root:[Epoch 173] train=0.995248 val=0.916100 loss=0.017498 time: 17.817808
INFO:root:[Epoch 174] train=0.995872 val=0.915800 loss=0.016588 time: 17.468714
INFO:root:[Epoch 175] train=0.995510 val=0.916600 loss=0.016810 time: 17.548859
INFO:root:[Epoch 176] train=0.995147 val=0.917500 loss=0.017991 time: 17.255481
INFO:root:[Epoch 177] train=0.996013 val=0.918200 loss=0.015830 time: 17.522762
INFO:root:[Epoch 178] train=0.995731 val=0.916600 loss=0.016351 time: 17.848607
INFO:root:[Epoch 179] train=0.995470 val=0.915900 loss=0.017188 time: 17.775643
INFO:root:[Epoch 180] train=0.996094 val=0.917200 loss=0.015943 time: 17.318871
INFO:root:[Epoch 181] train=0.996174 val=0.918200 loss=0.015700 time: 17.777076
INFO:root:[Epoch 182] train=0.995711 val=0.918600 loss=0.016186 time: 17.767962
INFO:root:[Epoch 183] train=0.995510 val=0.917300 loss=0.016356 time: 17.644785
INFO:root:[Epoch 184] train=0.996074 val=0.917100 loss=0.015393 time: 17.736751
INFO:root:[Epoch 185] train=0.996215 val=0.916800 loss=0.015877 time: 17.669598
INFO:root:[Epoch 186] train=0.995590 val=0.917600 loss=0.016519 time: 17.605034
INFO:root:[Epoch 187] train=0.995872 val=0.918400 loss=0.016030 time: 17.387738
INFO:root:[Epoch 188] train=0.996013 val=0.917400 loss=0.015387 time: 17.875023
INFO:root:[Epoch 189] train=0.995510 val=0.918900 loss=0.016148 time: 17.186692
INFO:root:[Epoch 190] train=0.995953 val=0.918000 loss=0.015875 time: 17.323987
INFO:root:[Epoch 191] train=0.996235 val=0.917700 loss=0.015488 time: 17.544377
INFO:root:[Epoch 192] train=0.996134 val=0.917900 loss=0.015408 time: 17.233792
INFO:root:[Epoch 193] train=0.995751 val=0.918600 loss=0.015818 time: 17.694462
INFO:root:[Epoch 194] train=0.996235 val=0.917400 loss=0.015484 time: 17.446262
INFO:root:[Epoch 195] train=0.996315 val=0.918300 loss=0.015622 time: 17.259948
INFO:root:[Epoch 196] train=0.995812 val=0.919000 loss=0.015651 time: 17.424871
INFO:root:[Epoch 197] train=0.996154 val=0.916500 loss=0.015068 time: 17.370619
INFO:root:[Epoch 198] train=0.996557 val=0.918600 loss=0.015027 time: 17.814320
INFO:root:[Epoch 199] train=0.996255 val=0.917900 loss=0.014856 time: 18.012696
