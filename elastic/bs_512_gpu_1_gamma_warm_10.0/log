INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='2', last_gamma=True, lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1_gamma_warm_10.0', save_period=10, save_plot_dir='bs_512_gpu_1_gamma_warm_10.0', warmup_epochs=10, wd=0.0001)
[03:55:06] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.324561 val=0.456000 loss=1.847587 time: 19.106079 lr: 0.039588
INFO:root:[Epoch 1] train=0.541338 val=0.508100 loss=1.257360 time: 18.539340 lr: 0.079588
INFO:root:[Epoch 2] train=0.649565 val=0.559400 loss=0.983349 time: 18.430144 lr: 0.119588
INFO:root:[Epoch 3] train=0.708642 val=0.643600 loss=0.820737 time: 18.053096 lr: 0.159588
INFO:root:[Epoch 4] train=0.753524 val=0.703800 loss=0.703715 time: 17.887725 lr: 0.199588
INFO:root:[Epoch 5] train=0.778491 val=0.701500 loss=0.635807 time: 17.545106 lr: 0.239588
INFO:root:[Epoch 6] train=0.799533 val=0.666800 loss=0.579163 time: 17.394045 lr: 0.279588
INFO:root:[Epoch 7] train=0.810728 val=0.757900 loss=0.544650 time: 17.657179 lr: 0.319588
INFO:root:[Epoch 8] train=0.823172 val=0.792100 loss=0.509361 time: 18.418976 lr: 0.359588
INFO:root:[Epoch 9] train=0.830300 val=0.766600 loss=0.492049 time: 17.505075 lr: 0.399588
INFO:root:[Epoch 10] train=0.840971 val=0.810100 loss=0.462195 time: 18.187647 lr: 0.400000
INFO:root:[Epoch 11] train=0.849388 val=0.778300 loss=0.435552 time: 17.859662 lr: 0.400000
INFO:root:[Epoch 12] train=0.855066 val=0.816600 loss=0.417431 time: 18.464101 lr: 0.400000
INFO:root:[Epoch 13] train=0.864067 val=0.793600 loss=0.393910 time: 17.999671 lr: 0.400000
INFO:root:[Epoch 14] train=0.867691 val=0.824900 loss=0.384472 time: 17.891673 lr: 0.400000
INFO:root:[Epoch 15] train=0.869382 val=0.774800 loss=0.374364 time: 18.051930 lr: 0.400000
INFO:root:[Epoch 16] train=0.875242 val=0.838900 loss=0.357884 time: 18.158208 lr: 0.400000
INFO:root:[Epoch 17] train=0.880517 val=0.757900 loss=0.345983 time: 18.117047 lr: 0.400000
INFO:root:[Epoch 18] train=0.881806 val=0.844300 loss=0.340554 time: 18.339464 lr: 0.400000
INFO:root:[Epoch 19] train=0.886316 val=0.848600 loss=0.329474 time: 18.044823 lr: 0.400000
INFO:root:[Epoch 20] train=0.886900 val=0.838100 loss=0.325046 time: 17.865542 lr: 0.400000
INFO:root:[Epoch 21] train=0.891149 val=0.848000 loss=0.315674 time: 17.864149 lr: 0.400000
INFO:root:[Epoch 22] train=0.894028 val=0.796100 loss=0.308468 time: 17.869366 lr: 0.400000
INFO:root:[Epoch 23] train=0.892759 val=0.838500 loss=0.307813 time: 17.888957 lr: 0.400000
INFO:root:[Epoch 24] train=0.894712 val=0.856200 loss=0.303021 time: 18.539340 lr: 0.400000
INFO:root:[Epoch 25] train=0.896847 val=0.835500 loss=0.295025 time: 18.092825 lr: 0.400000
INFO:root:[Epoch 26] train=0.898256 val=0.857700 loss=0.292932 time: 17.972165 lr: 0.400000
INFO:root:[Epoch 27] train=0.901277 val=0.829800 loss=0.283453 time: 17.883946 lr: 0.400000
INFO:root:[Epoch 28] train=0.900934 val=0.834900 loss=0.281559 time: 17.619796 lr: 0.400000
INFO:root:[Epoch 29] train=0.904015 val=0.844400 loss=0.275635 time: 17.919109 lr: 0.400000
INFO:root:[Epoch 30] train=0.903391 val=0.829600 loss=0.275060 time: 17.627500 lr: 0.400000
INFO:root:[Epoch 31] train=0.904820 val=0.844200 loss=0.271306 time: 17.965269 lr: 0.400000
INFO:root:[Epoch 32] train=0.907559 val=0.817100 loss=0.263458 time: 18.084450 lr: 0.400000
INFO:root:[Epoch 33] train=0.905988 val=0.833900 loss=0.268016 time: 17.963662 lr: 0.400000
INFO:root:[Epoch 34] train=0.909452 val=0.795700 loss=0.260431 time: 17.663438 lr: 0.400000
INFO:root:[Epoch 35] train=0.909754 val=0.802900 loss=0.259061 time: 17.910333 lr: 0.400000
INFO:root:[Epoch 36] train=0.910720 val=0.846500 loss=0.255135 time: 17.861791 lr: 0.400000
INFO:root:[Epoch 37] train=0.911968 val=0.818800 loss=0.254643 time: 18.456874 lr: 0.400000
INFO:root:[Epoch 38] train=0.912130 val=0.855900 loss=0.251374 time: 17.998718 lr: 0.400000
INFO:root:[Epoch 39] train=0.913781 val=0.846400 loss=0.246177 time: 17.797510 lr: 0.400000
INFO:root:[Epoch 40] train=0.913720 val=0.848600 loss=0.246612 time: 17.712269 lr: 0.400000
INFO:root:[Epoch 41] train=0.916700 val=0.813200 loss=0.241834 time: 17.537854 lr: 0.400000
INFO:root:[Epoch 42] train=0.916519 val=0.828700 loss=0.240123 time: 17.646310 lr: 0.400000
INFO:root:[Epoch 43] train=0.915190 val=0.835000 loss=0.242037 time: 17.968117 lr: 0.400000
INFO:root:[Epoch 44] train=0.916902 val=0.810100 loss=0.233681 time: 17.772785 lr: 0.400000
INFO:root:[Epoch 45] train=0.917888 val=0.852100 loss=0.238912 time: 17.776037 lr: 0.400000
INFO:root:[Epoch 46] train=0.916982 val=0.818200 loss=0.234101 time: 17.943949 lr: 0.400000
INFO:root:[Epoch 47] train=0.916378 val=0.839700 loss=0.237256 time: 17.365207 lr: 0.400000
INFO:root:[Epoch 48] train=0.919882 val=0.836300 loss=0.228207 time: 17.923564 lr: 0.400000
INFO:root:[Epoch 49] train=0.920687 val=0.860800 loss=0.225581 time: 17.801863 lr: 0.400000
INFO:root:[Epoch 50] train=0.919398 val=0.854200 loss=0.226069 time: 17.969343 lr: 0.400000
INFO:root:[Epoch 51] train=0.919781 val=0.825000 loss=0.229523 time: 17.964127 lr: 0.400000
INFO:root:[Epoch 52] train=0.920627 val=0.840300 loss=0.224911 time: 18.136128 lr: 0.400000
INFO:root:[Epoch 53] train=0.920888 val=0.832900 loss=0.225117 time: 17.386615 lr: 0.400000
INFO:root:[Epoch 54] train=0.920647 val=0.841000 loss=0.228173 time: 17.831999 lr: 0.400000
INFO:root:[Epoch 55] train=0.922237 val=0.834000 loss=0.221430 time: 17.787777 lr: 0.400000
INFO:root:[Epoch 56] train=0.924432 val=0.805700 loss=0.217810 time: 17.704288 lr: 0.400000
INFO:root:[Epoch 57] train=0.923043 val=0.855700 loss=0.217831 time: 17.914636 lr: 0.400000
INFO:root:[Epoch 58] train=0.923365 val=0.839300 loss=0.218709 time: 17.606351 lr: 0.400000
INFO:root:[Epoch 59] train=0.923486 val=0.868700 loss=0.218645 time: 17.323475 lr: 0.400000
INFO:root:[Epoch 60] train=0.921271 val=0.829200 loss=0.220799 time: 18.250108 lr: 0.400000
INFO:root:[Epoch 61] train=0.924513 val=0.850800 loss=0.216003 time: 17.577880 lr: 0.400000
INFO:root:[Epoch 62] train=0.924956 val=0.853300 loss=0.213373 time: 17.677173 lr: 0.400000
INFO:root:[Epoch 63] train=0.925298 val=0.825800 loss=0.216047 time: 17.760923 lr: 0.400000
INFO:root:[Epoch 64] train=0.925479 val=0.837700 loss=0.213986 time: 17.660865 lr: 0.400000
INFO:root:[Epoch 65] train=0.923989 val=0.844400 loss=0.216803 time: 17.685611 lr: 0.400000
INFO:root:[Epoch 66] train=0.925419 val=0.819700 loss=0.211127 time: 17.911240 lr: 0.400000
INFO:root:[Epoch 67] train=0.925318 val=0.854900 loss=0.210764 time: 18.035849 lr: 0.400000
INFO:root:[Epoch 68] train=0.927130 val=0.788000 loss=0.210449 time: 18.395377 lr: 0.400000
INFO:root:[Epoch 69] train=0.927976 val=0.804700 loss=0.207413 time: 17.999648 lr: 0.400000
INFO:root:[Epoch 70] train=0.927010 val=0.839700 loss=0.210888 time: 17.619986 lr: 0.400000
INFO:root:[Epoch 71] train=0.928097 val=0.837500 loss=0.204890 time: 18.059265 lr: 0.400000
INFO:root:[Epoch 72] train=0.927553 val=0.839200 loss=0.202799 time: 17.732193 lr: 0.400000
INFO:root:[Epoch 73] train=0.927312 val=0.826600 loss=0.207673 time: 18.294968 lr: 0.400000
INFO:root:[Epoch 74] train=0.927593 val=0.839900 loss=0.205387 time: 18.035204 lr: 0.400000
INFO:root:[Epoch 75] train=0.928278 val=0.848500 loss=0.201709 time: 18.292206 lr: 0.400000
INFO:root:[Epoch 76] train=0.929466 val=0.833400 loss=0.199974 time: 17.630173 lr: 0.400000
INFO:root:[Epoch 77] train=0.929929 val=0.804000 loss=0.204950 time: 17.674309 lr: 0.400000
INFO:root:[Epoch 78] train=0.929224 val=0.862200 loss=0.203029 time: 18.008512 lr: 0.400000
INFO:root:[Epoch 79] train=0.927936 val=0.860000 loss=0.201994 time: 17.863763 lr: 0.400000
INFO:root:[Epoch 80] train=0.929426 val=0.859900 loss=0.200569 time: 17.919630 lr: 0.400000
INFO:root:[Epoch 81] train=0.927855 val=0.822100 loss=0.203384 time: 17.830726 lr: 0.400000
INFO:root:[Epoch 82] train=0.930050 val=0.855500 loss=0.199140 time: 17.677011 lr: 0.400000
INFO:root:[Epoch 83] train=0.930292 val=0.813300 loss=0.195611 time: 17.628801 lr: 0.400000
INFO:root:[Epoch 84] train=0.931480 val=0.875600 loss=0.196778 time: 18.358189 lr: 0.400000
INFO:root:[Epoch 85] train=0.930795 val=0.841300 loss=0.195112 time: 17.959679 lr: 0.400000
INFO:root:[Epoch 86] train=0.931218 val=0.838800 loss=0.200343 time: 18.286975 lr: 0.400000
INFO:root:[Epoch 87] train=0.930674 val=0.838600 loss=0.194987 time: 17.575483 lr: 0.400000
INFO:root:[Epoch 88] train=0.931459 val=0.862600 loss=0.194857 time: 17.901578 lr: 0.400000
INFO:root:[Epoch 89] train=0.933956 val=0.844800 loss=0.190870 time: 17.906683 lr: 0.400000
INFO:root:[Epoch 90] train=0.930412 val=0.863500 loss=0.196239 time: 18.189464 lr: 0.400000
INFO:root:[Epoch 91] train=0.930513 val=0.868500 loss=0.198340 time: 18.036408 lr: 0.400000
INFO:root:[Epoch 92] train=0.932225 val=0.838700 loss=0.191706 time: 18.184615 lr: 0.400000
INFO:root:[Epoch 93] train=0.931741 val=0.828600 loss=0.195760 time: 17.812411 lr: 0.400000
INFO:root:[Epoch 94] train=0.934178 val=0.850600 loss=0.187062 time: 17.989879 lr: 0.400000
INFO:root:[Epoch 95] train=0.931923 val=0.817000 loss=0.193496 time: 18.146233 lr: 0.400000
INFO:root:[Epoch 96] train=0.934661 val=0.851400 loss=0.187402 time: 18.127119 lr: 0.400000
INFO:root:[Epoch 97] train=0.931258 val=0.879900 loss=0.195291 time: 18.005446 lr: 0.400000
INFO:root:[Epoch 98] train=0.929446 val=0.853300 loss=0.198490 time: 18.039609 lr: 0.400000
INFO:root:[Epoch 99] train=0.932043 val=0.837100 loss=0.192536 time: 18.059707 lr: 0.400000
INFO:root:[Epoch 100] train=0.958058 val=0.910200 loss=0.125881 time: 17.875043 lr: 0.040000
INFO:root:[Epoch 101] train=0.969052 val=0.911700 loss=0.091925 time: 17.843278 lr: 0.040000
INFO:root:[Epoch 102] train=0.973180 val=0.915100 loss=0.080472 time: 18.163575 lr: 0.040000
INFO:root:[Epoch 103] train=0.975717 val=0.915300 loss=0.073790 time: 18.040112 lr: 0.040000
INFO:root:[Epoch 104] train=0.977227 val=0.915900 loss=0.067537 time: 18.157253 lr: 0.040000
INFO:root:[Epoch 105] train=0.979482 val=0.918100 loss=0.063360 time: 17.943662 lr: 0.040000
INFO:root:[Epoch 106] train=0.979945 val=0.916300 loss=0.060789 time: 18.319858 lr: 0.040000
INFO:root:[Epoch 107] train=0.980106 val=0.915400 loss=0.058298 time: 17.740725 lr: 0.040000
INFO:root:[Epoch 108] train=0.981979 val=0.915200 loss=0.055045 time: 18.067272 lr: 0.040000
INFO:root:[Epoch 109] train=0.982543 val=0.919200 loss=0.052485 time: 17.850428 lr: 0.040000
INFO:root:[Epoch 110] train=0.984717 val=0.916500 loss=0.048111 time: 17.838058 lr: 0.040000
INFO:root:[Epoch 111] train=0.984899 val=0.916400 loss=0.046166 time: 18.343204 lr: 0.040000
INFO:root:[Epoch 112] train=0.985201 val=0.916700 loss=0.045737 time: 17.871879 lr: 0.040000
INFO:root:[Epoch 113] train=0.985341 val=0.916900 loss=0.044015 time: 18.248547 lr: 0.040000
INFO:root:[Epoch 114] train=0.987174 val=0.917000 loss=0.041660 time: 17.750925 lr: 0.040000
INFO:root:[Epoch 115] train=0.986751 val=0.917300 loss=0.040805 time: 17.944149 lr: 0.040000
INFO:root:[Epoch 116] train=0.986630 val=0.917300 loss=0.041346 time: 17.995343 lr: 0.040000
INFO:root:[Epoch 117] train=0.987355 val=0.915000 loss=0.039208 time: 17.923751 lr: 0.040000
INFO:root:[Epoch 118] train=0.988301 val=0.919000 loss=0.037018 time: 17.905710 lr: 0.040000
INFO:root:[Epoch 119] train=0.988040 val=0.917600 loss=0.036631 time: 17.770968 lr: 0.040000
INFO:root:[Epoch 120] train=0.988785 val=0.915500 loss=0.035693 time: 17.700992 lr: 0.040000
INFO:root:[Epoch 121] train=0.989228 val=0.917900 loss=0.033828 time: 18.066590 lr: 0.040000
INFO:root:[Epoch 122] train=0.989550 val=0.915700 loss=0.033158 time: 17.767520 lr: 0.040000
INFO:root:[Epoch 123] train=0.989832 val=0.915200 loss=0.031738 time: 17.721323 lr: 0.040000
INFO:root:[Epoch 124] train=0.989489 val=0.915100 loss=0.032565 time: 17.670366 lr: 0.040000
INFO:root:[Epoch 125] train=0.989570 val=0.916400 loss=0.031959 time: 17.471932 lr: 0.040000
INFO:root:[Epoch 126] train=0.990879 val=0.916800 loss=0.030282 time: 18.083357 lr: 0.040000
INFO:root:[Epoch 127] train=0.990134 val=0.916500 loss=0.029907 time: 17.476422 lr: 0.040000
INFO:root:[Epoch 128] train=0.990154 val=0.915700 loss=0.029645 time: 17.768282 lr: 0.040000
INFO:root:[Epoch 129] train=0.991241 val=0.914600 loss=0.028434 time: 17.741242 lr: 0.040000
INFO:root:[Epoch 130] train=0.991241 val=0.916200 loss=0.027989 time: 18.033237 lr: 0.040000
INFO:root:[Epoch 131] train=0.991624 val=0.915000 loss=0.026813 time: 17.825766 lr: 0.040000
INFO:root:[Epoch 132] train=0.992248 val=0.913100 loss=0.026622 time: 18.194285 lr: 0.040000
INFO:root:[Epoch 133] train=0.992107 val=0.917500 loss=0.026007 time: 17.880390 lr: 0.040000
INFO:root:[Epoch 134] train=0.991604 val=0.916700 loss=0.026601 time: 18.308748 lr: 0.040000
INFO:root:[Epoch 135] train=0.992006 val=0.916000 loss=0.026046 time: 18.022108 lr: 0.040000
INFO:root:[Epoch 136] train=0.992630 val=0.914600 loss=0.024257 time: 18.023692 lr: 0.040000
INFO:root:[Epoch 137] train=0.992912 val=0.915900 loss=0.023378 time: 18.079248 lr: 0.040000
INFO:root:[Epoch 138] train=0.992550 val=0.915500 loss=0.023772 time: 18.051090 lr: 0.040000
INFO:root:[Epoch 139] train=0.992671 val=0.913600 loss=0.023436 time: 18.092921 lr: 0.040000
INFO:root:[Epoch 140] train=0.992812 val=0.915700 loss=0.023519 time: 17.902933 lr: 0.040000
INFO:root:[Epoch 141] train=0.992610 val=0.914000 loss=0.023961 time: 17.735223 lr: 0.040000
INFO:root:[Epoch 142] train=0.992892 val=0.916200 loss=0.022533 time: 17.598108 lr: 0.040000
INFO:root:[Epoch 143] train=0.993617 val=0.914000 loss=0.021190 time: 17.766332 lr: 0.040000
INFO:root:[Epoch 144] train=0.992550 val=0.913400 loss=0.022524 time: 17.977101 lr: 0.040000
INFO:root:[Epoch 145] train=0.993315 val=0.915200 loss=0.021132 time: 17.947363 lr: 0.040000
INFO:root:[Epoch 146] train=0.992953 val=0.915400 loss=0.022683 time: 18.154183 lr: 0.040000
INFO:root:[Epoch 147] train=0.993416 val=0.914900 loss=0.021268 time: 17.931706 lr: 0.040000
INFO:root:[Epoch 148] train=0.993114 val=0.915100 loss=0.021001 time: 17.936503 lr: 0.040000
INFO:root:[Epoch 149] train=0.992953 val=0.913500 loss=0.021700 time: 17.910322 lr: 0.040000
INFO:root:[Epoch 150] train=0.994624 val=0.915800 loss=0.018159 time: 17.939094 lr: 0.004000
INFO:root:[Epoch 151] train=0.995067 val=0.917000 loss=0.016752 time: 18.186512 lr: 0.004000
INFO:root:[Epoch 152] train=0.995913 val=0.916600 loss=0.015175 time: 17.557147 lr: 0.004000
INFO:root:[Epoch 153] train=0.995731 val=0.917200 loss=0.015540 time: 17.973050 lr: 0.004000
INFO:root:[Epoch 154] train=0.996376 val=0.916300 loss=0.013980 time: 18.020634 lr: 0.004000
INFO:root:[Epoch 155] train=0.996557 val=0.918900 loss=0.013751 time: 17.945442 lr: 0.004000
INFO:root:[Epoch 156] train=0.996658 val=0.918100 loss=0.013610 time: 18.318088 lr: 0.004000
INFO:root:[Epoch 157] train=0.996295 val=0.917800 loss=0.013730 time: 18.070338 lr: 0.004000
INFO:root:[Epoch 158] train=0.996295 val=0.918800 loss=0.013821 time: 18.154376 lr: 0.004000
INFO:root:[Epoch 159] train=0.996617 val=0.918300 loss=0.013286 time: 17.954319 lr: 0.004000
INFO:root:[Epoch 160] train=0.996960 val=0.917200 loss=0.012684 time: 17.886882 lr: 0.004000
INFO:root:[Epoch 161] train=0.997221 val=0.917700 loss=0.012446 time: 17.980941 lr: 0.004000
INFO:root:[Epoch 162] train=0.996738 val=0.916900 loss=0.012833 time: 18.293337 lr: 0.004000
INFO:root:[Epoch 163] train=0.996919 val=0.917200 loss=0.012504 time: 17.964282 lr: 0.004000
INFO:root:[Epoch 164] train=0.996557 val=0.916700 loss=0.012737 time: 17.473977 lr: 0.004000
INFO:root:[Epoch 165] train=0.996819 val=0.917700 loss=0.012385 time: 17.862693 lr: 0.004000
INFO:root:[Epoch 166] train=0.997221 val=0.917900 loss=0.012235 time: 17.768701 lr: 0.004000
INFO:root:[Epoch 167] train=0.996859 val=0.918200 loss=0.012446 time: 17.764030 lr: 0.004000
INFO:root:[Epoch 168] train=0.996960 val=0.917400 loss=0.012315 time: 17.901313 lr: 0.004000
INFO:root:[Epoch 169] train=0.997282 val=0.917400 loss=0.011631 time: 16.911191 lr: 0.004000
INFO:root:[Epoch 170] train=0.997664 val=0.917100 loss=0.011289 time: 17.403909 lr: 0.004000
INFO:root:[Epoch 171] train=0.997282 val=0.917800 loss=0.012102 time: 16.999658 lr: 0.004000
INFO:root:[Epoch 172] train=0.997080 val=0.917200 loss=0.012322 time: 17.288241 lr: 0.004000
INFO:root:[Epoch 173] train=0.997201 val=0.917400 loss=0.011814 time: 16.296625 lr: 0.004000
INFO:root:[Epoch 174] train=0.997201 val=0.917200 loss=0.011708 time: 16.509090 lr: 0.004000
INFO:root:[Epoch 175] train=0.997564 val=0.917700 loss=0.011291 time: 16.424226 lr: 0.004000
INFO:root:[Epoch 176] train=0.997543 val=0.917900 loss=0.011368 time: 16.732490 lr: 0.004000
INFO:root:[Epoch 177] train=0.997241 val=0.917600 loss=0.011324 time: 16.778760 lr: 0.004000
INFO:root:[Epoch 178] train=0.997483 val=0.916500 loss=0.011125 time: 16.257115 lr: 0.004000
INFO:root:[Epoch 179] train=0.997080 val=0.916800 loss=0.012033 time: 16.183721 lr: 0.004000
INFO:root:[Epoch 180] train=0.997483 val=0.916600 loss=0.011059 time: 16.652208 lr: 0.004000
INFO:root:[Epoch 181] train=0.997684 val=0.916500 loss=0.010508 time: 16.315253 lr: 0.004000
INFO:root:[Epoch 182] train=0.997564 val=0.917000 loss=0.011348 time: 16.253481 lr: 0.004000
INFO:root:[Epoch 183] train=0.997624 val=0.917100 loss=0.010860 time: 15.557605 lr: 0.004000
INFO:root:[Epoch 184] train=0.997322 val=0.917800 loss=0.011320 time: 15.356551 lr: 0.004000
INFO:root:[Epoch 185] train=0.997241 val=0.917700 loss=0.011352 time: 15.225529 lr: 0.004000
INFO:root:[Epoch 186] train=0.997241 val=0.917200 loss=0.011442 time: 14.818568 lr: 0.004000
INFO:root:[Epoch 187] train=0.997564 val=0.917300 loss=0.011017 time: 14.388176 lr: 0.004000
INFO:root:[Epoch 188] train=0.997846 val=0.916600 loss=0.010301 time: 15.242997 lr: 0.004000
INFO:root:[Epoch 189] train=0.997322 val=0.917100 loss=0.010989 time: 15.313411 lr: 0.004000
INFO:root:[Epoch 190] train=0.997302 val=0.918000 loss=0.011168 time: 15.298952 lr: 0.004000
INFO:root:[Epoch 191] train=0.997221 val=0.917300 loss=0.011112 time: 14.902265 lr: 0.004000
INFO:root:[Epoch 192] train=0.997201 val=0.917700 loss=0.011534 time: 14.576981 lr: 0.004000
INFO:root:[Epoch 193] train=0.997543 val=0.916500 loss=0.010425 time: 15.359047 lr: 0.004000
INFO:root:[Epoch 194] train=0.997483 val=0.917000 loss=0.011260 time: 14.912120 lr: 0.004000
INFO:root:[Epoch 195] train=0.997745 val=0.917400 loss=0.010418 time: 14.445858 lr: 0.004000
INFO:root:[Epoch 196] train=0.997564 val=0.917400 loss=0.010747 time: 14.975821 lr: 0.004000
INFO:root:[Epoch 197] train=0.997805 val=0.917400 loss=0.010900 time: 15.073434 lr: 0.004000
INFO:root:[Epoch 198] train=0.997564 val=0.917200 loss=0.010542 time: 16.413110 lr: 0.004000
INFO:root:[Epoch 199] train=0.997684 val=0.917700 loss=0.010178 time: 16.546844 lr: 0.004000
