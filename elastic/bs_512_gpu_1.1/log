INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='2', last_gamma=False, lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1.1', save_period=10, save_plot_dir='bs_512_gpu_1.1', warmup_epochs=0, wd=0.0001)
[03:49:43] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.352670 val=0.439200 loss=1.721437 time: 15.708330 lr: 0.400000
INFO:root:[Epoch 1] train=0.572628 val=0.541300 loss=1.180672 time: 15.720191 lr: 0.400000
INFO:root:[Epoch 2] train=0.682063 val=0.679800 loss=0.889835 time: 16.287119 lr: 0.400000
INFO:root:[Epoch 3] train=0.743033 val=0.623000 loss=0.736649 time: 16.294099 lr: 0.400000
INFO:root:[Epoch 4] train=0.776478 val=0.692200 loss=0.638892 time: 16.072169 lr: 0.400000
INFO:root:[Epoch 5] train=0.801989 val=0.744000 loss=0.570615 time: 16.955746 lr: 0.400000
INFO:root:[Epoch 6] train=0.817453 val=0.779700 loss=0.523808 time: 16.724659 lr: 0.400000
INFO:root:[Epoch 7] train=0.831447 val=0.771800 loss=0.487740 time: 16.437146 lr: 0.400000
INFO:root:[Epoch 8] train=0.836884 val=0.774400 loss=0.469441 time: 16.483552 lr: 0.400000
INFO:root:[Epoch 9] train=0.848079 val=0.780600 loss=0.436937 time: 16.598085 lr: 0.400000
INFO:root:[Epoch 10] train=0.855046 val=0.779700 loss=0.417664 time: 15.981474 lr: 0.400000
INFO:root:[Epoch 11] train=0.861993 val=0.760400 loss=0.399309 time: 16.637011 lr: 0.400000
INFO:root:[Epoch 12] train=0.867107 val=0.821500 loss=0.386320 time: 16.346075 lr: 0.400000
INFO:root:[Epoch 13] train=0.872846 val=0.817800 loss=0.367865 time: 15.986214 lr: 0.400000
INFO:root:[Epoch 14] train=0.873872 val=0.822100 loss=0.361127 time: 16.202380 lr: 0.400000
INFO:root:[Epoch 15] train=0.877920 val=0.789600 loss=0.350130 time: 16.258382 lr: 0.400000
INFO:root:[Epoch 16] train=0.880759 val=0.823200 loss=0.339640 time: 16.061735 lr: 0.400000
INFO:root:[Epoch 17] train=0.884826 val=0.808000 loss=0.331001 time: 17.131590 lr: 0.400000
INFO:root:[Epoch 18] train=0.888048 val=0.815400 loss=0.324577 time: 17.125582 lr: 0.400000
INFO:root:[Epoch 19] train=0.889598 val=0.815600 loss=0.317876 time: 18.581837 lr: 0.400000
INFO:root:[Epoch 20] train=0.893384 val=0.828600 loss=0.308141 time: 18.270838 lr: 0.400000
INFO:root:[Epoch 21] train=0.896162 val=0.848700 loss=0.301717 time: 18.327688 lr: 0.400000
INFO:root:[Epoch 22] train=0.896565 val=0.693500 loss=0.296089 time: 18.158070 lr: 0.400000
INFO:root:[Epoch 23] train=0.897773 val=0.822900 loss=0.291277 time: 18.339501 lr: 0.400000
INFO:root:[Epoch 24] train=0.897793 val=0.811700 loss=0.287849 time: 17.773726 lr: 0.400000
INFO:root:[Epoch 25] train=0.902344 val=0.844500 loss=0.280533 time: 17.597392 lr: 0.400000
INFO:root:[Epoch 26] train=0.905082 val=0.836900 loss=0.273931 time: 18.018354 lr: 0.400000
INFO:root:[Epoch 27] train=0.905747 val=0.802500 loss=0.271271 time: 17.666631 lr: 0.400000
INFO:root:[Epoch 28] train=0.904639 val=0.848700 loss=0.271090 time: 17.858057 lr: 0.400000
INFO:root:[Epoch 29] train=0.906935 val=0.818900 loss=0.266071 time: 18.136258 lr: 0.400000
INFO:root:[Epoch 30] train=0.907277 val=0.855400 loss=0.264258 time: 18.273633 lr: 0.400000
INFO:root:[Epoch 31] train=0.910297 val=0.803800 loss=0.254678 time: 17.749434 lr: 0.400000
INFO:root:[Epoch 32] train=0.910921 val=0.855400 loss=0.257095 time: 17.905887 lr: 0.400000
INFO:root:[Epoch 33] train=0.909572 val=0.863400 loss=0.257714 time: 18.635298 lr: 0.400000
INFO:root:[Epoch 34] train=0.915573 val=0.855200 loss=0.244065 time: 18.038223 lr: 0.400000
INFO:root:[Epoch 35] train=0.911868 val=0.806000 loss=0.250575 time: 17.910928 lr: 0.400000
INFO:root:[Epoch 36] train=0.913378 val=0.823300 loss=0.246778 time: 18.350968 lr: 0.400000
INFO:root:[Epoch 37] train=0.916479 val=0.855000 loss=0.236366 time: 18.406850 lr: 0.400000
INFO:root:[Epoch 38] train=0.915714 val=0.788900 loss=0.239870 time: 18.480053 lr: 0.400000
INFO:root:[Epoch 39] train=0.914848 val=0.837200 loss=0.240585 time: 17.857798 lr: 0.400000
INFO:root:[Epoch 40] train=0.916499 val=0.851500 loss=0.235230 time: 18.030069 lr: 0.400000
INFO:root:[Epoch 41] train=0.918150 val=0.859500 loss=0.237447 time: 17.888771 lr: 0.400000
INFO:root:[Epoch 42] train=0.917928 val=0.832300 loss=0.230757 time: 18.134282 lr: 0.400000
INFO:root:[Epoch 43] train=0.917586 val=0.839400 loss=0.232954 time: 18.039128 lr: 0.400000
INFO:root:[Epoch 44] train=0.920969 val=0.836500 loss=0.227381 time: 18.205388 lr: 0.400000
INFO:root:[Epoch 45] train=0.919942 val=0.830900 loss=0.226608 time: 17.933631 lr: 0.400000
INFO:root:[Epoch 46] train=0.920405 val=0.853100 loss=0.226193 time: 17.973865 lr: 0.400000
INFO:root:[Epoch 47] train=0.920184 val=0.801200 loss=0.224472 time: 18.236348 lr: 0.400000
INFO:root:[Epoch 48] train=0.921190 val=0.831100 loss=0.222004 time: 18.138472 lr: 0.400000
INFO:root:[Epoch 49] train=0.922137 val=0.844100 loss=0.222637 time: 18.287643 lr: 0.400000
INFO:root:[Epoch 50] train=0.921935 val=0.850700 loss=0.224170 time: 17.948620 lr: 0.400000
INFO:root:[Epoch 51] train=0.923063 val=0.844400 loss=0.216630 time: 17.986880 lr: 0.400000
INFO:root:[Epoch 52] train=0.922862 val=0.779800 loss=0.218317 time: 17.631916 lr: 0.400000
INFO:root:[Epoch 53] train=0.924593 val=0.840200 loss=0.216091 time: 17.722765 lr: 0.400000
INFO:root:[Epoch 54] train=0.922177 val=0.852600 loss=0.217057 time: 18.089816 lr: 0.400000
INFO:root:[Epoch 55] train=0.924714 val=0.840500 loss=0.213528 time: 18.191411 lr: 0.400000
INFO:root:[Epoch 56] train=0.923506 val=0.849700 loss=0.216246 time: 18.432312 lr: 0.400000
INFO:root:[Epoch 57] train=0.926405 val=0.860800 loss=0.208547 time: 17.961438 lr: 0.400000
INFO:root:[Epoch 58] train=0.927110 val=0.849600 loss=0.210648 time: 17.664709 lr: 0.400000
INFO:root:[Epoch 59] train=0.925781 val=0.846300 loss=0.210022 time: 17.824886 lr: 0.400000
INFO:root:[Epoch 60] train=0.928097 val=0.828300 loss=0.205745 time: 18.366024 lr: 0.400000
INFO:root:[Epoch 61] train=0.927473 val=0.814100 loss=0.206358 time: 17.870882 lr: 0.400000
INFO:root:[Epoch 62] train=0.926506 val=0.870800 loss=0.208061 time: 18.146872 lr: 0.400000
INFO:root:[Epoch 63] train=0.928359 val=0.851300 loss=0.206346 time: 18.104184 lr: 0.400000
INFO:root:[Epoch 64] train=0.927130 val=0.860400 loss=0.203708 time: 18.083845 lr: 0.400000
INFO:root:[Epoch 65] train=0.925962 val=0.870600 loss=0.207518 time: 18.002896 lr: 0.400000
INFO:root:[Epoch 66] train=0.927815 val=0.866900 loss=0.204230 time: 17.670282 lr: 0.400000
INFO:root:[Epoch 67] train=0.927513 val=0.849400 loss=0.204443 time: 18.121724 lr: 0.400000
INFO:root:[Epoch 68] train=0.926808 val=0.825900 loss=0.205264 time: 17.973602 lr: 0.400000
INFO:root:[Epoch 69] train=0.928701 val=0.848900 loss=0.202885 time: 18.085692 lr: 0.400000
INFO:root:[Epoch 70] train=0.930674 val=0.840300 loss=0.197748 time: 17.913350 lr: 0.400000
INFO:root:[Epoch 71] train=0.930130 val=0.866900 loss=0.197689 time: 18.122922 lr: 0.400000
INFO:root:[Epoch 72] train=0.931339 val=0.862600 loss=0.193937 time: 18.215197 lr: 0.400000
INFO:root:[Epoch 73] train=0.928560 val=0.853800 loss=0.200118 time: 18.401343 lr: 0.400000
INFO:root:[Epoch 74] train=0.932768 val=0.846500 loss=0.195978 time: 18.333867 lr: 0.400000
INFO:root:[Epoch 75] train=0.929285 val=0.845900 loss=0.199957 time: 18.221965 lr: 0.400000
INFO:root:[Epoch 76] train=0.929426 val=0.873700 loss=0.197971 time: 18.107238 lr: 0.400000
INFO:root:[Epoch 77] train=0.929385 val=0.842800 loss=0.196658 time: 18.402161 lr: 0.400000
INFO:root:[Epoch 78] train=0.932365 val=0.854000 loss=0.194644 time: 18.043844 lr: 0.400000
INFO:root:[Epoch 79] train=0.930493 val=0.847700 loss=0.194016 time: 18.275010 lr: 0.400000
INFO:root:[Epoch 80] train=0.930694 val=0.827500 loss=0.192792 time: 18.245552 lr: 0.400000
INFO:root:[Epoch 81] train=0.932345 val=0.833700 loss=0.191724 time: 18.200617 lr: 0.400000
INFO:root:[Epoch 82] train=0.931641 val=0.845300 loss=0.193858 time: 17.898474 lr: 0.400000
INFO:root:[Epoch 83] train=0.933553 val=0.872800 loss=0.191508 time: 18.596235 lr: 0.400000
INFO:root:[Epoch 84] train=0.932023 val=0.858100 loss=0.191418 time: 17.959102 lr: 0.400000
INFO:root:[Epoch 85] train=0.932990 val=0.827000 loss=0.191982 time: 18.268488 lr: 0.400000
INFO:root:[Epoch 86] train=0.930352 val=0.854700 loss=0.197026 time: 18.046034 lr: 0.400000
INFO:root:[Epoch 87] train=0.934681 val=0.854400 loss=0.187721 time: 18.038841 lr: 0.400000
INFO:root:[Epoch 88] train=0.932486 val=0.841500 loss=0.194052 time: 18.070412 lr: 0.400000
INFO:root:[Epoch 89] train=0.933654 val=0.845800 loss=0.188158 time: 18.059988 lr: 0.400000
INFO:root:[Epoch 90] train=0.932929 val=0.847600 loss=0.187718 time: 18.495578 lr: 0.400000
INFO:root:[Epoch 91] train=0.931681 val=0.862100 loss=0.189949 time: 18.539456 lr: 0.400000
INFO:root:[Epoch 92] train=0.932104 val=0.849600 loss=0.189683 time: 18.148731 lr: 0.400000
INFO:root:[Epoch 93] train=0.933976 val=0.837200 loss=0.187971 time: 18.264300 lr: 0.400000
INFO:root:[Epoch 94] train=0.932245 val=0.813900 loss=0.192645 time: 18.302393 lr: 0.400000
INFO:root:[Epoch 95] train=0.933131 val=0.857600 loss=0.188414 time: 18.649366 lr: 0.400000
INFO:root:[Epoch 96] train=0.934238 val=0.839900 loss=0.185071 time: 18.283747 lr: 0.400000
INFO:root:[Epoch 97] train=0.933694 val=0.837500 loss=0.189865 time: 18.212659 lr: 0.400000
INFO:root:[Epoch 98] train=0.936070 val=0.854700 loss=0.181548 time: 17.685297 lr: 0.400000
INFO:root:[Epoch 99] train=0.935889 val=0.842500 loss=0.181941 time: 18.262858 lr: 0.400000
INFO:root:[Epoch 100] train=0.957132 val=0.906000 loss=0.122720 time: 18.249493 lr: 0.040000
INFO:root:[Epoch 101] train=0.970280 val=0.909800 loss=0.088818 time: 18.757455 lr: 0.040000
INFO:root:[Epoch 102] train=0.974428 val=0.909600 loss=0.077875 time: 18.073370 lr: 0.040000
INFO:root:[Epoch 103] train=0.976301 val=0.909100 loss=0.071543 time: 17.752925 lr: 0.040000
INFO:root:[Epoch 104] train=0.977408 val=0.912300 loss=0.066335 time: 18.857270 lr: 0.040000
INFO:root:[Epoch 105] train=0.980811 val=0.914000 loss=0.059935 time: 18.385751 lr: 0.040000
INFO:root:[Epoch 106] train=0.981516 val=0.910700 loss=0.057478 time: 17.803197 lr: 0.040000
INFO:root:[Epoch 107] train=0.982724 val=0.913000 loss=0.053000 time: 17.762303 lr: 0.040000
INFO:root:[Epoch 108] train=0.983247 val=0.911400 loss=0.052139 time: 17.531234 lr: 0.040000
INFO:root:[Epoch 109] train=0.983127 val=0.914600 loss=0.050582 time: 18.682490 lr: 0.040000
INFO:root:[Epoch 110] train=0.983509 val=0.913800 loss=0.049138 time: 18.046089 lr: 0.040000
INFO:root:[Epoch 111] train=0.985261 val=0.913800 loss=0.046292 time: 18.683866 lr: 0.040000
INFO:root:[Epoch 112] train=0.987134 val=0.913200 loss=0.041827 time: 17.836137 lr: 0.040000
INFO:root:[Epoch 113] train=0.986248 val=0.912600 loss=0.042806 time: 18.322651 lr: 0.040000
INFO:root:[Epoch 114] train=0.986650 val=0.913700 loss=0.042138 time: 18.062828 lr: 0.040000
INFO:root:[Epoch 115] train=0.987415 val=0.911500 loss=0.038670 time: 18.385917 lr: 0.040000
INFO:root:[Epoch 116] train=0.988181 val=0.914000 loss=0.037518 time: 18.164434 lr: 0.040000
INFO:root:[Epoch 117] train=0.987959 val=0.913600 loss=0.037138 time: 18.098089 lr: 0.040000
INFO:root:[Epoch 118] train=0.988744 val=0.914200 loss=0.035599 time: 17.786833 lr: 0.040000
INFO:root:[Epoch 119] train=0.989268 val=0.911400 loss=0.033898 time: 17.981407 lr: 0.040000
INFO:root:[Epoch 120] train=0.989550 val=0.914000 loss=0.033234 time: 17.766346 lr: 0.040000
INFO:root:[Epoch 121] train=0.989812 val=0.913900 loss=0.032893 time: 17.831821 lr: 0.040000
INFO:root:[Epoch 122] train=0.989932 val=0.914100 loss=0.031279 time: 18.084274 lr: 0.040000
INFO:root:[Epoch 123] train=0.990436 val=0.910300 loss=0.030316 time: 18.170929 lr: 0.040000
INFO:root:[Epoch 124] train=0.990275 val=0.912400 loss=0.031332 time: 18.103705 lr: 0.040000
INFO:root:[Epoch 125] train=0.990919 val=0.913000 loss=0.029640 time: 18.304778 lr: 0.040000
INFO:root:[Epoch 126] train=0.991060 val=0.912700 loss=0.029343 time: 17.919120 lr: 0.040000
INFO:root:[Epoch 127] train=0.990778 val=0.911900 loss=0.029443 time: 18.647017 lr: 0.040000
INFO:root:[Epoch 128] train=0.992087 val=0.912600 loss=0.026524 time: 18.084396 lr: 0.040000
INFO:root:[Epoch 129] train=0.991926 val=0.911300 loss=0.027307 time: 18.133479 lr: 0.040000
INFO:root:[Epoch 130] train=0.991322 val=0.912600 loss=0.026338 time: 18.850890 lr: 0.040000
INFO:root:[Epoch 131] train=0.991503 val=0.914600 loss=0.026791 time: 18.373838 lr: 0.040000
INFO:root:[Epoch 132] train=0.992248 val=0.912800 loss=0.025151 time: 18.032469 lr: 0.040000
INFO:root:[Epoch 133] train=0.992510 val=0.913200 loss=0.025265 time: 18.300500 lr: 0.040000
INFO:root:[Epoch 134] train=0.992469 val=0.911400 loss=0.025000 time: 18.291137 lr: 0.040000
INFO:root:[Epoch 135] train=0.993033 val=0.913000 loss=0.023414 time: 18.514830 lr: 0.040000
INFO:root:[Epoch 136] train=0.992751 val=0.912300 loss=0.023797 time: 18.019302 lr: 0.040000
INFO:root:[Epoch 137] train=0.993114 val=0.912500 loss=0.023062 time: 18.012285 lr: 0.040000
INFO:root:[Epoch 138] train=0.993194 val=0.910400 loss=0.022169 time: 18.208519 lr: 0.040000
INFO:root:[Epoch 139] train=0.994060 val=0.912100 loss=0.020813 time: 17.997592 lr: 0.040000
INFO:root:[Epoch 140] train=0.993154 val=0.913900 loss=0.022559 time: 18.007865 lr: 0.040000
INFO:root:[Epoch 141] train=0.993355 val=0.909900 loss=0.021967 time: 17.791216 lr: 0.040000
INFO:root:[Epoch 142] train=0.992892 val=0.913100 loss=0.022048 time: 18.304077 lr: 0.040000
INFO:root:[Epoch 143] train=0.993758 val=0.913700 loss=0.020967 time: 18.158328 lr: 0.040000
INFO:root:[Epoch 144] train=0.993939 val=0.912500 loss=0.020339 time: 18.955930 lr: 0.040000
INFO:root:[Epoch 145] train=0.993255 val=0.911800 loss=0.021481 time: 18.557004 lr: 0.040000
INFO:root:[Epoch 146] train=0.993436 val=0.910400 loss=0.020740 time: 17.790461 lr: 0.040000
INFO:root:[Epoch 147] train=0.994382 val=0.909300 loss=0.019092 time: 18.156004 lr: 0.040000
INFO:root:[Epoch 148] train=0.994282 val=0.911400 loss=0.018697 time: 17.746068 lr: 0.040000
INFO:root:[Epoch 149] train=0.993678 val=0.912600 loss=0.019667 time: 18.135383 lr: 0.040000
INFO:root:[Epoch 150] train=0.995409 val=0.915100 loss=0.016194 time: 18.332334 lr: 0.004000
INFO:root:[Epoch 151] train=0.995892 val=0.914200 loss=0.015408 time: 18.243915 lr: 0.004000
INFO:root:[Epoch 152] train=0.996839 val=0.915900 loss=0.013206 time: 18.246969 lr: 0.004000
INFO:root:[Epoch 153] train=0.996436 val=0.915300 loss=0.013717 time: 18.258001 lr: 0.004000
INFO:root:[Epoch 154] train=0.996939 val=0.915000 loss=0.013299 time: 18.125990 lr: 0.004000
INFO:root:[Epoch 155] train=0.996597 val=0.915600 loss=0.013431 time: 18.251843 lr: 0.004000
INFO:root:[Epoch 156] train=0.996758 val=0.915200 loss=0.012976 time: 17.684380 lr: 0.004000
INFO:root:[Epoch 157] train=0.996496 val=0.915700 loss=0.013475 time: 18.603325 lr: 0.004000
INFO:root:[Epoch 158] train=0.997141 val=0.915100 loss=0.012032 time: 18.231997 lr: 0.004000
INFO:root:[Epoch 159] train=0.996960 val=0.915200 loss=0.012319 time: 18.205887 lr: 0.004000
INFO:root:[Epoch 160] train=0.997181 val=0.915500 loss=0.012020 time: 18.114860 lr: 0.004000
INFO:root:[Epoch 161] train=0.997443 val=0.916100 loss=0.011732 time: 18.836265 lr: 0.004000
INFO:root:[Epoch 162] train=0.997463 val=0.915800 loss=0.011386 time: 18.563277 lr: 0.004000
INFO:root:[Epoch 163] train=0.997141 val=0.916100 loss=0.012125 time: 18.462658 lr: 0.004000
INFO:root:[Epoch 164] train=0.997604 val=0.915300 loss=0.010902 time: 18.443504 lr: 0.004000
INFO:root:[Epoch 165] train=0.997483 val=0.915400 loss=0.011343 time: 18.112971 lr: 0.004000
INFO:root:[Epoch 166] train=0.997624 val=0.916000 loss=0.011264 time: 17.991632 lr: 0.004000
INFO:root:[Epoch 167] train=0.997523 val=0.916200 loss=0.011476 time: 18.400697 lr: 0.004000
INFO:root:[Epoch 168] train=0.997342 val=0.916100 loss=0.011715 time: 18.688374 lr: 0.004000
INFO:root:[Epoch 169] train=0.997523 val=0.914900 loss=0.010663 time: 18.085696 lr: 0.004000
INFO:root:[Epoch 170] train=0.997282 val=0.915100 loss=0.011432 time: 18.477245 lr: 0.004000
INFO:root:[Epoch 171] train=0.997302 val=0.916100 loss=0.011435 time: 17.944027 lr: 0.004000
INFO:root:[Epoch 172] train=0.997503 val=0.915400 loss=0.011262 time: 17.982039 lr: 0.004000
INFO:root:[Epoch 173] train=0.997241 val=0.915500 loss=0.011502 time: 18.108756 lr: 0.004000
INFO:root:[Epoch 174] train=0.998047 val=0.915200 loss=0.011044 time: 18.287800 lr: 0.004000
INFO:root:[Epoch 175] train=0.997241 val=0.915600 loss=0.011044 time: 17.931032 lr: 0.004000
INFO:root:[Epoch 176] train=0.997725 val=0.916400 loss=0.010480 time: 18.263005 lr: 0.004000
INFO:root:[Epoch 177] train=0.997403 val=0.915600 loss=0.010789 time: 18.303059 lr: 0.004000
INFO:root:[Epoch 178] train=0.997906 val=0.916800 loss=0.010445 time: 18.870065 lr: 0.004000
INFO:root:[Epoch 179] train=0.997805 val=0.916500 loss=0.010789 time: 18.374199 lr: 0.004000
INFO:root:[Epoch 180] train=0.997825 val=0.916100 loss=0.010259 time: 18.330724 lr: 0.004000
INFO:root:[Epoch 181] train=0.997644 val=0.915200 loss=0.010839 time: 18.353193 lr: 0.004000
INFO:root:[Epoch 182] train=0.997604 val=0.915700 loss=0.010934 time: 17.954930 lr: 0.004000
INFO:root:[Epoch 183] train=0.997523 val=0.916000 loss=0.010564 time: 18.259110 lr: 0.004000
INFO:root:[Epoch 184] train=0.997584 val=0.915900 loss=0.010665 time: 18.059813 lr: 0.004000
INFO:root:[Epoch 185] train=0.997986 val=0.917100 loss=0.009996 time: 18.626373 lr: 0.004000
INFO:root:[Epoch 186] train=0.998107 val=0.914800 loss=0.010501 time: 16.959333 lr: 0.004000
INFO:root:[Epoch 187] train=0.997241 val=0.914800 loss=0.011203 time: 17.514198 lr: 0.004000
INFO:root:[Epoch 188] train=0.997846 val=0.915300 loss=0.010048 time: 17.610953 lr: 0.004000
INFO:root:[Epoch 189] train=0.997886 val=0.915700 loss=0.010183 time: 17.465113 lr: 0.004000
INFO:root:[Epoch 190] train=0.997765 val=0.915600 loss=0.010270 time: 17.241943 lr: 0.004000
INFO:root:[Epoch 191] train=0.997846 val=0.914900 loss=0.010088 time: 16.377370 lr: 0.004000
INFO:root:[Epoch 192] train=0.997644 val=0.916100 loss=0.010267 time: 16.667643 lr: 0.004000
INFO:root:[Epoch 193] train=0.997926 val=0.915000 loss=0.010133 time: 16.948022 lr: 0.004000
INFO:root:[Epoch 194] train=0.998168 val=0.916100 loss=0.009886 time: 16.528760 lr: 0.004000
INFO:root:[Epoch 195] train=0.997705 val=0.915400 loss=0.010297 time: 16.710535 lr: 0.004000
INFO:root:[Epoch 196] train=0.997745 val=0.915600 loss=0.010327 time: 16.911081 lr: 0.004000
INFO:root:[Epoch 197] train=0.998228 val=0.916100 loss=0.009221 time: 16.450233 lr: 0.004000
INFO:root:[Epoch 198] train=0.998268 val=0.915900 loss=0.009661 time: 16.550959 lr: 0.004000
INFO:root:[Epoch 199] train=0.997825 val=0.915100 loss=0.009685 time: 16.215141 lr: 0.004000
