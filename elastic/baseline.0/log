INFO:root:Namespace(batch_size=128, drop_rate=0.0, gpu=3, lr=0.1, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='baseline-params', save_period=10, save_plot_dir='.', wd=0.0001)
[04:29:31] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.462059 val=0.547300 loss=1.470389 time: 16.541695
INFO:root:[Epoch 1] train=0.662680 val=0.677800 loss=0.949427 time: 16.648256
INFO:root:[Epoch 2] train=0.737660 val=0.746500 loss=0.753686 time: 16.096014
INFO:root:[Epoch 3] train=0.773498 val=0.765200 loss=0.652936 time: 16.822540
INFO:root:[Epoch 4] train=0.796474 val=0.803100 loss=0.590905 time: 15.399702
INFO:root:[Epoch 5] train=0.812360 val=0.795700 loss=0.545703 time: 17.330060
INFO:root:[Epoch 6] train=0.822877 val=0.812700 loss=0.508586 time: 16.571784
INFO:root:[Epoch 7] train=0.832632 val=0.819300 loss=0.480562 time: 16.959252
INFO:root:[Epoch 8] train=0.842488 val=0.824200 loss=0.459064 time: 18.639833
INFO:root:[Epoch 9] train=0.848818 val=0.787800 loss=0.436453 time: 16.608686
INFO:root:[Epoch 10] train=0.855148 val=0.819900 loss=0.419067 time: 16.872575
INFO:root:[Epoch 11] train=0.858934 val=0.808300 loss=0.407388 time: 16.443742
INFO:root:[Epoch 12] train=0.863702 val=0.848400 loss=0.394670 time: 16.516401
INFO:root:[Epoch 13] train=0.869291 val=0.818700 loss=0.377978 time: 16.018150
INFO:root:[Epoch 14] train=0.870453 val=0.846400 loss=0.375615 time: 16.854315
INFO:root:[Epoch 15] train=0.873237 val=0.827700 loss=0.365312 time: 17.008180
INFO:root:[Epoch 16] train=0.877183 val=0.842500 loss=0.353452 time: 16.832600
INFO:root:[Epoch 17] train=0.879227 val=0.845400 loss=0.347119 time: 15.197174
INFO:root:[Epoch 18] train=0.883674 val=0.836900 loss=0.337361 time: 16.564544
INFO:root:[Epoch 19] train=0.883894 val=0.837400 loss=0.333778 time: 16.189377
INFO:root:[Epoch 20] train=0.887861 val=0.827100 loss=0.322876 time: 16.700302
INFO:root:[Epoch 21] train=0.890365 val=0.854700 loss=0.317382 time: 16.323226
INFO:root:[Epoch 22] train=0.890064 val=0.797400 loss=0.314929 time: 16.721747
INFO:root:[Epoch 23] train=0.892548 val=0.852000 loss=0.306892 time: 16.788006
INFO:root:[Epoch 24] train=0.895252 val=0.857900 loss=0.303537 time: 17.089573
INFO:root:[Epoch 25] train=0.896995 val=0.833100 loss=0.298094 time: 16.521063
INFO:root:[Epoch 26] train=0.896174 val=0.841700 loss=0.296390 time: 16.072730
INFO:root:[Epoch 27] train=0.899920 val=0.840400 loss=0.291741 time: 15.905909
INFO:root:[Epoch 28] train=0.900220 val=0.857500 loss=0.286446 time: 16.004821
INFO:root:[Epoch 29] train=0.900942 val=0.857100 loss=0.284791 time: 15.910821
INFO:root:[Epoch 30] train=0.900501 val=0.861700 loss=0.283097 time: 17.746291
INFO:root:[Epoch 31] train=0.903746 val=0.865700 loss=0.272252 time: 16.057694
INFO:root:[Epoch 32] train=0.905389 val=0.856600 loss=0.271870 time: 17.128833
INFO:root:[Epoch 33] train=0.905709 val=0.833300 loss=0.269791 time: 16.705365
INFO:root:[Epoch 34] train=0.905068 val=0.854800 loss=0.269008 time: 15.960639
INFO:root:[Epoch 35] train=0.906871 val=0.853300 loss=0.265078 time: 16.911490
INFO:root:[Epoch 36] train=0.908113 val=0.834600 loss=0.260778 time: 16.600565
INFO:root:[Epoch 37] train=0.909776 val=0.845400 loss=0.259382 time: 17.220274
INFO:root:[Epoch 38] train=0.910877 val=0.858600 loss=0.257131 time: 15.955858
INFO:root:[Epoch 39] train=0.912400 val=0.863400 loss=0.254489 time: 16.849537
INFO:root:[Epoch 40] train=0.910737 val=0.857000 loss=0.254442 time: 16.597261
INFO:root:[Epoch 41] train=0.912360 val=0.824200 loss=0.249759 time: 15.737017
INFO:root:[Epoch 42] train=0.911378 val=0.856900 loss=0.252182 time: 16.163252
INFO:root:[Epoch 43] train=0.912139 val=0.840300 loss=0.253142 time: 17.767581
INFO:root:[Epoch 44] train=0.914062 val=0.873500 loss=0.245374 time: 15.847533
INFO:root:[Epoch 45] train=0.913602 val=0.836200 loss=0.246401 time: 17.815337
INFO:root:[Epoch 46] train=0.913982 val=0.857100 loss=0.245607 time: 16.296766
INFO:root:[Epoch 47] train=0.914583 val=0.877100 loss=0.240976 time: 15.699422
INFO:root:[Epoch 48] train=0.914904 val=0.823600 loss=0.241878 time: 16.515700
INFO:root:[Epoch 49] train=0.914904 val=0.870300 loss=0.241871 time: 17.053195
INFO:root:[Epoch 50] train=0.915104 val=0.867500 loss=0.244536 time: 17.423785
INFO:root:[Epoch 51] train=0.918890 val=0.861900 loss=0.232754 time: 18.168855
INFO:root:[Epoch 52] train=0.916386 val=0.868800 loss=0.236430 time: 17.565592
INFO:root:[Epoch 53] train=0.916767 val=0.848900 loss=0.236500 time: 16.870520
INFO:root:[Epoch 54] train=0.919431 val=0.868500 loss=0.230030 time: 18.394942
INFO:root:[Epoch 55] train=0.918610 val=0.879800 loss=0.231852 time: 16.879714
INFO:root:[Epoch 56] train=0.919972 val=0.856500 loss=0.230073 time: 16.318623
INFO:root:[Epoch 57] train=0.918610 val=0.831500 loss=0.229081 time: 16.679404
INFO:root:[Epoch 58] train=0.919411 val=0.856600 loss=0.229609 time: 16.621166
INFO:root:[Epoch 59] train=0.917829 val=0.875100 loss=0.233893 time: 16.052498
INFO:root:[Epoch 60] train=0.921595 val=0.858000 loss=0.220565 time: 16.231593
INFO:root:[Epoch 61] train=0.920933 val=0.869000 loss=0.226378 time: 16.530562
INFO:root:[Epoch 62] train=0.923838 val=0.881800 loss=0.220570 time: 16.679264
INFO:root:[Epoch 63] train=0.923357 val=0.866600 loss=0.218838 time: 15.820325
INFO:root:[Epoch 64] train=0.919832 val=0.837300 loss=0.226508 time: 16.132646
INFO:root:[Epoch 65] train=0.921474 val=0.866200 loss=0.222062 time: 17.121760
INFO:root:[Epoch 66] train=0.920032 val=0.868900 loss=0.228203 time: 15.933089
INFO:root:[Epoch 67] train=0.922476 val=0.851100 loss=0.219953 time: 16.888557
INFO:root:[Epoch 68] train=0.923678 val=0.870400 loss=0.217667 time: 16.988869
INFO:root:[Epoch 69] train=0.923758 val=0.867600 loss=0.218294 time: 16.466070
INFO:root:[Epoch 70] train=0.922236 val=0.864400 loss=0.220553 time: 16.397814
INFO:root:[Epoch 71] train=0.922796 val=0.868600 loss=0.218035 time: 16.228863
INFO:root:[Epoch 72] train=0.923177 val=0.848300 loss=0.220051 time: 16.491576
INFO:root:[Epoch 73] train=0.924880 val=0.867800 loss=0.214906 time: 16.458555
INFO:root:[Epoch 74] train=0.926502 val=0.873700 loss=0.213878 time: 17.922243
INFO:root:[Epoch 75] train=0.924239 val=0.863500 loss=0.216511 time: 17.106219
INFO:root:[Epoch 76] train=0.923077 val=0.855500 loss=0.215420 time: 16.830667
INFO:root:[Epoch 77] train=0.923838 val=0.869300 loss=0.217604 time: 17.150109
INFO:root:[Epoch 78] train=0.926482 val=0.854900 loss=0.211384 time: 17.563264
INFO:root:[Epoch 79] train=0.923438 val=0.865300 loss=0.215984 time: 16.570110
INFO:root:[Epoch 80] train=0.925421 val=0.802400 loss=0.211635 time: 17.389368
INFO:root:[Epoch 81] train=0.926703 val=0.873000 loss=0.210013 time: 17.520553
INFO:root:[Epoch 82] train=0.925441 val=0.846600 loss=0.211957 time: 17.543533
INFO:root:[Epoch 83] train=0.926142 val=0.879000 loss=0.211108 time: 17.445151
INFO:root:[Epoch 84] train=0.927204 val=0.855000 loss=0.206355 time: 16.299704
INFO:root:[Epoch 85] train=0.926823 val=0.859100 loss=0.208495 time: 17.943156
INFO:root:[Epoch 86] train=0.925020 val=0.872100 loss=0.213673 time: 17.970301
INFO:root:[Epoch 87] train=0.926783 val=0.870800 loss=0.209368 time: 16.562612
INFO:root:[Epoch 88] train=0.927804 val=0.885700 loss=0.203775 time: 17.767574
INFO:root:[Epoch 89] train=0.927804 val=0.869500 loss=0.207460 time: 18.540712
INFO:root:[Epoch 90] train=0.926382 val=0.855800 loss=0.209110 time: 16.507163
INFO:root:[Epoch 91] train=0.926643 val=0.869400 loss=0.207425 time: 16.669393
INFO:root:[Epoch 92] train=0.929647 val=0.852000 loss=0.199549 time: 17.680445
INFO:root:[Epoch 93] train=0.926462 val=0.847800 loss=0.209273 time: 18.090547
INFO:root:[Epoch 94] train=0.929527 val=0.862700 loss=0.199082 time: 18.112524
INFO:root:[Epoch 95] train=0.925661 val=0.876200 loss=0.209027 time: 16.980229
INFO:root:[Epoch 96] train=0.928245 val=0.863400 loss=0.202458 time: 18.498731
INFO:root:[Epoch 97] train=0.929667 val=0.864100 loss=0.202488 time: 16.662344
INFO:root:[Epoch 98] train=0.927404 val=0.879000 loss=0.204763 time: 18.843898
INFO:root:[Epoch 99] train=0.927985 val=0.861700 loss=0.203154 time: 17.128526
INFO:root:[Epoch 100] train=0.957452 val=0.911900 loss=0.126109 time: 16.809654
INFO:root:[Epoch 101] train=0.966767 val=0.916600 loss=0.099085 time: 19.326236
INFO:root:[Epoch 102] train=0.970893 val=0.913800 loss=0.086540 time: 16.692310
INFO:root:[Epoch 103] train=0.973037 val=0.912700 loss=0.080303 time: 17.827291
INFO:root:[Epoch 104] train=0.975321 val=0.916200 loss=0.075543 time: 16.360289
INFO:root:[Epoch 105] train=0.975881 val=0.916300 loss=0.071310 time: 19.507369
INFO:root:[Epoch 106] train=0.977664 val=0.917400 loss=0.067711 time: 17.070454
INFO:root:[Epoch 107] train=0.979006 val=0.914900 loss=0.064654 time: 16.151596
INFO:root:[Epoch 108] train=0.979387 val=0.914800 loss=0.062549 time: 16.571643
INFO:root:[Epoch 109] train=0.980929 val=0.916200 loss=0.058658 time: 18.762188
INFO:root:[Epoch 110] train=0.980869 val=0.916400 loss=0.057642 time: 16.711497
INFO:root:[Epoch 111] train=0.982933 val=0.915500 loss=0.052887 time: 19.109183
INFO:root:[Epoch 112] train=0.982933 val=0.915900 loss=0.052722 time: 19.535912
INFO:root:[Epoch 113] train=0.983554 val=0.914000 loss=0.050711 time: 19.139939
INFO:root:[Epoch 114] train=0.983433 val=0.914800 loss=0.050031 time: 17.291708
INFO:root:[Epoch 115] train=0.984635 val=0.914000 loss=0.047098 time: 18.172263
INFO:root:[Epoch 116] train=0.983934 val=0.916300 loss=0.048074 time: 20.127100
INFO:root:[Epoch 117] train=0.985076 val=0.918300 loss=0.045279 time: 18.965375
INFO:root:[Epoch 118] train=0.985056 val=0.916300 loss=0.044352 time: 17.512378
INFO:root:[Epoch 119] train=0.986198 val=0.913500 loss=0.042310 time: 17.216322
INFO:root:[Epoch 120] train=0.986018 val=0.914100 loss=0.042480 time: 17.331459
INFO:root:[Epoch 121] train=0.987200 val=0.912400 loss=0.041555 time: 16.292409
INFO:root:[Epoch 122] train=0.986879 val=0.913200 loss=0.040878 time: 16.917249
INFO:root:[Epoch 123] train=0.987300 val=0.913600 loss=0.038375 time: 17.425002
INFO:root:[Epoch 124] train=0.987640 val=0.914000 loss=0.038129 time: 16.175208
INFO:root:[Epoch 125] train=0.988341 val=0.915400 loss=0.036467 time: 17.980954
INFO:root:[Epoch 126] train=0.989203 val=0.915200 loss=0.035225 time: 18.834620
INFO:root:[Epoch 127] train=0.988221 val=0.912500 loss=0.036260 time: 16.763904
INFO:root:[Epoch 128] train=0.988462 val=0.914600 loss=0.034599 time: 17.484155
INFO:root:[Epoch 129] train=0.989263 val=0.912500 loss=0.033855 time: 18.087083
INFO:root:[Epoch 130] train=0.988882 val=0.912500 loss=0.034840 time: 17.359344
INFO:root:[Epoch 131] train=0.989243 val=0.916100 loss=0.033334 time: 17.014468
INFO:root:[Epoch 132] train=0.990465 val=0.912000 loss=0.030701 time: 17.350973
INFO:root:[Epoch 133] train=0.990465 val=0.915000 loss=0.030851 time: 16.952564
INFO:root:[Epoch 134] train=0.989804 val=0.910900 loss=0.031777 time: 17.786000
INFO:root:[Epoch 135] train=0.989864 val=0.913700 loss=0.031040 time: 18.309742
INFO:root:[Epoch 136] train=0.989804 val=0.914200 loss=0.030489 time: 18.071528
INFO:root:[Epoch 137] train=0.991026 val=0.914100 loss=0.028223 time: 18.260291
INFO:root:[Epoch 138] train=0.990765 val=0.913000 loss=0.029461 time: 17.863836
INFO:root:[Epoch 139] train=0.991286 val=0.913500 loss=0.028741 time: 17.317204
INFO:root:[Epoch 140] train=0.990745 val=0.911700 loss=0.029499 time: 18.058885
INFO:root:[Epoch 141] train=0.992208 val=0.914400 loss=0.026729 time: 17.305938
INFO:root:[Epoch 142] train=0.991787 val=0.915300 loss=0.027422 time: 17.088295
INFO:root:[Epoch 143] train=0.991266 val=0.913200 loss=0.027905 time: 18.049428
INFO:root:[Epoch 144] train=0.991386 val=0.912900 loss=0.027729 time: 16.574686
INFO:root:[Epoch 145] train=0.991186 val=0.912000 loss=0.027273 time: 18.078166
INFO:root:[Epoch 146] train=0.991226 val=0.911600 loss=0.026700 time: 16.390974
INFO:root:[Epoch 147] train=0.991567 val=0.913700 loss=0.027465 time: 17.300863
INFO:root:[Epoch 148] train=0.992408 val=0.915400 loss=0.024602 time: 17.173429
INFO:root:[Epoch 149] train=0.992348 val=0.912300 loss=0.025130 time: 18.896570
INFO:root:[Epoch 150] train=0.993269 val=0.915800 loss=0.022255 time: 17.421001
INFO:root:[Epoch 151] train=0.994311 val=0.915100 loss=0.020667 time: 18.724158
INFO:root:[Epoch 152] train=0.995192 val=0.914400 loss=0.018973 time: 16.596439
INFO:root:[Epoch 153] train=0.994692 val=0.914300 loss=0.018846 time: 16.317951
INFO:root:[Epoch 154] train=0.995393 val=0.914100 loss=0.017797 time: 17.937471
INFO:root:[Epoch 155] train=0.995152 val=0.914700 loss=0.017468 time: 16.516472
INFO:root:[Epoch 156] train=0.995232 val=0.915700 loss=0.017591 time: 18.890800
INFO:root:[Epoch 157] train=0.995473 val=0.915000 loss=0.017478 time: 18.012743
INFO:root:[Epoch 158] train=0.995132 val=0.914300 loss=0.017929 time: 17.906232
INFO:root:[Epoch 159] train=0.995313 val=0.915400 loss=0.017439 time: 17.184664
INFO:root:[Epoch 160] train=0.995653 val=0.915200 loss=0.017091 time: 16.760278
INFO:root:[Epoch 161] train=0.995673 val=0.915400 loss=0.016875 time: 16.605814
INFO:root:[Epoch 162] train=0.995693 val=0.915300 loss=0.016710 time: 17.439249
INFO:root:[Epoch 163] train=0.995473 val=0.914700 loss=0.017323 time: 18.524607
INFO:root:[Epoch 164] train=0.995633 val=0.915400 loss=0.016449 time: 17.281809
INFO:root:[Epoch 165] train=0.995493 val=0.915100 loss=0.017121 time: 17.796130
INFO:root:[Epoch 166] train=0.995753 val=0.916400 loss=0.016339 time: 17.229864
INFO:root:[Epoch 167] train=0.996174 val=0.915100 loss=0.015630 time: 17.332078
INFO:root:[Epoch 168] train=0.995833 val=0.915400 loss=0.016286 time: 17.113916
INFO:root:[Epoch 169] train=0.995773 val=0.915900 loss=0.016307 time: 18.227504
INFO:root:[Epoch 170] train=0.995773 val=0.915100 loss=0.015904 time: 17.856770
INFO:root:[Epoch 171] train=0.995693 val=0.916100 loss=0.016025 time: 20.560825
INFO:root:[Epoch 172] train=0.996214 val=0.916600 loss=0.015469 time: 19.932344
INFO:root:[Epoch 173] train=0.996134 val=0.916400 loss=0.015117 time: 18.940572
INFO:root:[Epoch 174] train=0.995954 val=0.915200 loss=0.015650 time: 19.233961
INFO:root:[Epoch 175] train=0.995733 val=0.916300 loss=0.016363 time: 19.587241
INFO:root:[Epoch 176] train=0.996254 val=0.917300 loss=0.015333 time: 19.503316
INFO:root:[Epoch 177] train=0.996695 val=0.916300 loss=0.015311 time: 19.438955
INFO:root:[Epoch 178] train=0.996454 val=0.916600 loss=0.014396 time: 19.986145
INFO:root:[Epoch 179] train=0.996034 val=0.917000 loss=0.015602 time: 19.438179
INFO:root:[Epoch 180] train=0.996314 val=0.916300 loss=0.014749 time: 18.446665
INFO:root:[Epoch 181] train=0.996034 val=0.916800 loss=0.015296 time: 19.497630
INFO:root:[Epoch 182] train=0.996454 val=0.916000 loss=0.014778 time: 19.167978
INFO:root:[Epoch 183] train=0.996554 val=0.916800 loss=0.014513 time: 18.435718
INFO:root:[Epoch 184] train=0.996675 val=0.916900 loss=0.014338 time: 17.770036
INFO:root:[Epoch 185] train=0.995673 val=0.915200 loss=0.015577 time: 19.050893
INFO:root:[Epoch 186] train=0.996675 val=0.916800 loss=0.014302 time: 20.856997
INFO:root:[Epoch 187] train=0.996394 val=0.916500 loss=0.014731 time: 20.572123
INFO:root:[Epoch 188] train=0.996294 val=0.917100 loss=0.014329 time: 20.743149
INFO:root:[Epoch 189] train=0.996274 val=0.916700 loss=0.014162 time: 22.797826
INFO:root:[Epoch 190] train=0.996134 val=0.915800 loss=0.014693 time: 23.495241
INFO:root:[Epoch 191] train=0.996595 val=0.916100 loss=0.014396 time: 23.908357
INFO:root:[Epoch 192] train=0.996334 val=0.916500 loss=0.014891 time: 24.455502
INFO:root:[Epoch 193] train=0.996935 val=0.916700 loss=0.013861 time: 24.804893
INFO:root:[Epoch 194] train=0.996034 val=0.915900 loss=0.015178 time: 24.523551
INFO:root:[Epoch 195] train=0.996454 val=0.916000 loss=0.014280 time: 23.318866
INFO:root:[Epoch 196] train=0.996314 val=0.915800 loss=0.014449 time: 22.817267
INFO:root:[Epoch 197] train=0.996274 val=0.916100 loss=0.014497 time: 24.165969
INFO:root:[Epoch 198] train=0.996514 val=0.916100 loss=0.014573 time: 24.891149
INFO:root:[Epoch 199] train=0.996354 val=0.916500 loss=0.014863 time: 24.218266
