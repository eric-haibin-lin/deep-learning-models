INFO:root:Namespace(batch_size=256, drop_rate=0.0, gpus='0,1', lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_256_gpu_2_0.4.0', save_period=10, save_plot_dir='bs_256_gpu_2_0.4.0', wd=0.0001)
[07:32:31] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.142196 val=0.139800 loss=2.356686 time: 17.797871
INFO:root:[Epoch 1] train=0.261356 val=0.295700 loss=1.895582 time: 16.177387
INFO:root:[Epoch 2] train=0.382309 val=0.365900 loss=1.605638 time: 16.285328
INFO:root:[Epoch 3] train=0.510027 val=0.498500 loss=1.339127 time: 16.079930
INFO:root:[Epoch 4] train=0.582535 val=0.558300 loss=1.155693 time: 16.181976
INFO:root:[Epoch 5] train=0.637705 val=0.611500 loss=1.009149 time: 15.973289
INFO:root:[Epoch 6] train=0.680553 val=0.647600 loss=0.900492 time: 15.761138
INFO:root:[Epoch 7] train=0.717522 val=0.656000 loss=0.803844 time: 15.916441
INFO:root:[Epoch 8] train=0.744986 val=0.709600 loss=0.726986 time: 16.128065
INFO:root:[Epoch 9] train=0.769793 val=0.667900 loss=0.667241 time: 15.641129
INFO:root:[Epoch 10] train=0.788237 val=0.664300 loss=0.610648 time: 16.309743
INFO:root:[Epoch 11] train=0.797922 val=0.768100 loss=0.579363 time: 16.176567
INFO:root:[Epoch 12] train=0.810225 val=0.778100 loss=0.547015 time: 17.175425
INFO:root:[Epoch 13] train=0.819205 val=0.712800 loss=0.522406 time: 17.206968
INFO:root:[Epoch 14] train=0.826957 val=0.741700 loss=0.499067 time: 16.832433
INFO:root:[Epoch 15] train=0.834548 val=0.783600 loss=0.477488 time: 16.578407
INFO:root:[Epoch 16] train=0.839501 val=0.774500 loss=0.462851 time: 17.638449
INFO:root:[Epoch 17] train=0.845300 val=0.806700 loss=0.446962 time: 16.948287
INFO:root:[Epoch 18] train=0.850495 val=0.772600 loss=0.432063 time: 17.474144
INFO:root:[Epoch 19] train=0.854482 val=0.812100 loss=0.422237 time: 16.612979
INFO:root:[Epoch 20] train=0.860261 val=0.817900 loss=0.404510 time: 17.228695
INFO:root:[Epoch 21] train=0.861348 val=0.825300 loss=0.400934 time: 16.906200
INFO:root:[Epoch 22] train=0.865557 val=0.788900 loss=0.386508 time: 16.904159
INFO:root:[Epoch 23] train=0.870248 val=0.789100 loss=0.377883 time: 16.948435
INFO:root:[Epoch 24] train=0.870691 val=0.839700 loss=0.374301 time: 17.203585
INFO:root:[Epoch 25] train=0.873148 val=0.789800 loss=0.362474 time: 16.934779
INFO:root:[Epoch 26] train=0.877356 val=0.830400 loss=0.353886 time: 16.728365
INFO:root:[Epoch 27] train=0.879772 val=0.845900 loss=0.345839 time: 17.118441
INFO:root:[Epoch 28] train=0.880477 val=0.803900 loss=0.340821 time: 16.930525
INFO:root:[Epoch 29] train=0.882651 val=0.817900 loss=0.334998 time: 16.857760
INFO:root:[Epoch 30] train=0.883819 val=0.824200 loss=0.330839 time: 17.444798
INFO:root:[Epoch 31] train=0.887222 val=0.782000 loss=0.319619 time: 17.081878
INFO:root:[Epoch 32] train=0.892075 val=0.830800 loss=0.312865 time: 17.757139
INFO:root:[Epoch 33] train=0.890504 val=0.848300 loss=0.312742 time: 17.052148
INFO:root:[Epoch 34] train=0.892498 val=0.809200 loss=0.311806 time: 15.986857
INFO:root:[Epoch 35] train=0.897028 val=0.832800 loss=0.299622 time: 16.292188
INFO:root:[Epoch 36] train=0.892779 val=0.836400 loss=0.303403 time: 16.177846
INFO:root:[Epoch 37] train=0.897149 val=0.838000 loss=0.295746 time: 16.333161
INFO:root:[Epoch 38] train=0.899787 val=0.841800 loss=0.289758 time: 15.978972
INFO:root:[Epoch 39] train=0.902163 val=0.813500 loss=0.283025 time: 16.298426
INFO:root:[Epoch 40] train=0.901095 val=0.807700 loss=0.281690 time: 15.816270
INFO:root:[Epoch 41] train=0.899867 val=0.822400 loss=0.284152 time: 15.821193
INFO:root:[Epoch 42] train=0.903612 val=0.812600 loss=0.276281 time: 16.294263
INFO:root:[Epoch 43] train=0.903793 val=0.851700 loss=0.274993 time: 16.170816
INFO:root:[Epoch 44] train=0.905263 val=0.836800 loss=0.272482 time: 15.900403
INFO:root:[Epoch 45] train=0.907478 val=0.831600 loss=0.267757 time: 16.142721
INFO:root:[Epoch 46] train=0.904398 val=0.860900 loss=0.271444 time: 16.107440
INFO:root:[Epoch 47] train=0.907317 val=0.855200 loss=0.262950 time: 16.278966
INFO:root:[Epoch 48] train=0.908163 val=0.855300 loss=0.265172 time: 16.704126
INFO:root:[Epoch 49] train=0.908485 val=0.840900 loss=0.261279 time: 16.611857
INFO:root:[Epoch 50] train=0.911223 val=0.832100 loss=0.256609 time: 16.041299
INFO:root:[Epoch 51] train=0.910821 val=0.839400 loss=0.253291 time: 15.968624
INFO:root:[Epoch 52] train=0.910881 val=0.800200 loss=0.254943 time: 16.270602
INFO:root:[Epoch 53] train=0.911304 val=0.812300 loss=0.252270 time: 16.250321
INFO:root:[Epoch 54] train=0.912230 val=0.829100 loss=0.251501 time: 15.965788
INFO:root:[Epoch 55] train=0.917385 val=0.824000 loss=0.235849 time: 16.234880
INFO:root:[Epoch 56] train=0.914385 val=0.839000 loss=0.248024 time: 16.320618
INFO:root:[Epoch 57] train=0.915553 val=0.801800 loss=0.243066 time: 15.914251
INFO:root:[Epoch 58] train=0.915553 val=0.827900 loss=0.239803 time: 16.095127
INFO:root:[Epoch 59] train=0.917868 val=0.836700 loss=0.238059 time: 16.495025
INFO:root:[Epoch 60] train=0.916398 val=0.817400 loss=0.237625 time: 16.496404
INFO:root:[Epoch 61] train=0.917284 val=0.842600 loss=0.234479 time: 16.199916
INFO:root:[Epoch 62] train=0.917647 val=0.854700 loss=0.233679 time: 16.482612
INFO:root:[Epoch 63] train=0.914284 val=0.835000 loss=0.241391 time: 16.250897
INFO:root:[Epoch 64] train=0.917566 val=0.817200 loss=0.236255 time: 16.367354
INFO:root:[Epoch 65] train=0.916902 val=0.834500 loss=0.235127 time: 16.070560
INFO:root:[Epoch 66] train=0.918855 val=0.851700 loss=0.229357 time: 16.175632
INFO:root:[Epoch 67] train=0.918573 val=0.777000 loss=0.233406 time: 16.185065
INFO:root:[Epoch 68] train=0.919499 val=0.840000 loss=0.228560 time: 16.585111
INFO:root:[Epoch 69] train=0.920284 val=0.797600 loss=0.224541 time: 16.444623
INFO:root:[Epoch 70] train=0.922580 val=0.858800 loss=0.223701 time: 16.463986
INFO:root:[Epoch 71] train=0.924472 val=0.821800 loss=0.218086 time: 16.109550
INFO:root:[Epoch 72] train=0.921070 val=0.856400 loss=0.223420 time: 16.338369
INFO:root:[Epoch 73] train=0.923083 val=0.823400 loss=0.216880 time: 16.058438
INFO:root:[Epoch 74] train=0.922076 val=0.859500 loss=0.221824 time: 15.851845
INFO:root:[Epoch 75] train=0.922358 val=0.851500 loss=0.219279 time: 16.433488
INFO:root:[Epoch 76] train=0.922922 val=0.827400 loss=0.220771 time: 16.278234
INFO:root:[Epoch 77] train=0.924090 val=0.834400 loss=0.219196 time: 16.054631
INFO:root:[Epoch 78] train=0.923526 val=0.829800 loss=0.218551 time: 16.458696
INFO:root:[Epoch 79] train=0.922358 val=0.851300 loss=0.218924 time: 16.032319
INFO:root:[Epoch 80] train=0.923667 val=0.812400 loss=0.216468 time: 16.282513
INFO:root:[Epoch 81] train=0.924211 val=0.861200 loss=0.216693 time: 16.124474
INFO:root:[Epoch 82] train=0.925137 val=0.855400 loss=0.211409 time: 16.540553
INFO:root:[Epoch 83] train=0.924191 val=0.803900 loss=0.214617 time: 16.412338
INFO:root:[Epoch 84] train=0.924110 val=0.854300 loss=0.214267 time: 16.815287
INFO:root:[Epoch 85] train=0.926244 val=0.848500 loss=0.209415 time: 16.804512
INFO:root:[Epoch 86] train=0.924070 val=0.828500 loss=0.210420 time: 16.282744
INFO:root:[Epoch 87] train=0.926526 val=0.849800 loss=0.209404 time: 16.324682
INFO:root:[Epoch 88] train=0.926506 val=0.864500 loss=0.208032 time: 16.162580
INFO:root:[Epoch 89] train=0.926164 val=0.834600 loss=0.210250 time: 16.292383
INFO:root:[Epoch 90] train=0.926345 val=0.827200 loss=0.207809 time: 16.150393
INFO:root:[Epoch 91] train=0.926325 val=0.853700 loss=0.210023 time: 16.291526
INFO:root:[Epoch 92] train=0.926385 val=0.860300 loss=0.207202 time: 15.869950
INFO:root:[Epoch 93] train=0.928902 val=0.875000 loss=0.203949 time: 16.461182
INFO:root:[Epoch 94] train=0.926164 val=0.854300 loss=0.208597 time: 16.699476
INFO:root:[Epoch 95] train=0.927553 val=0.853000 loss=0.204392 time: 16.339392
INFO:root:[Epoch 96] train=0.926204 val=0.830000 loss=0.207257 time: 15.870208
INFO:root:[Epoch 97] train=0.928318 val=0.867000 loss=0.204099 time: 16.682339
INFO:root:[Epoch 98] train=0.931520 val=0.858100 loss=0.197318 time: 15.980329
INFO:root:[Epoch 99] train=0.928137 val=0.841100 loss=0.203220 time: 16.157838
INFO:root:[Epoch 100] train=0.953991 val=0.914800 loss=0.133587 time: 16.206156
INFO:root:[Epoch 101] train=0.967320 val=0.913500 loss=0.099271 time: 15.925061
INFO:root:[Epoch 102] train=0.970683 val=0.914600 loss=0.090172 time: 15.358678
INFO:root:[Epoch 103] train=0.971931 val=0.914000 loss=0.083597 time: 15.899607
INFO:root:[Epoch 104] train=0.974770 val=0.914000 loss=0.077147 time: 15.787596
INFO:root:[Epoch 105] train=0.975536 val=0.916600 loss=0.072667 time: 14.871881
INFO:root:[Epoch 106] train=0.977610 val=0.915300 loss=0.068976 time: 14.609352
INFO:root:[Epoch 107] train=0.977207 val=0.915000 loss=0.067987 time: 14.773725
INFO:root:[Epoch 108] train=0.979965 val=0.916800 loss=0.062725 time: 15.057406
INFO:root:[Epoch 109] train=0.980690 val=0.917700 loss=0.059639 time: 14.835347
INFO:root:[Epoch 110] train=0.981073 val=0.915500 loss=0.057200 time: 14.638521
INFO:root:[Epoch 111] train=0.981576 val=0.918700 loss=0.055749 time: 14.568643
INFO:root:[Epoch 112] train=0.983288 val=0.917400 loss=0.052852 time: 14.434090
INFO:root:[Epoch 113] train=0.982583 val=0.918200 loss=0.052670 time: 14.570307
INFO:root:[Epoch 114] train=0.982885 val=0.919100 loss=0.051201 time: 14.804360
INFO:root:[Epoch 115] train=0.983851 val=0.917400 loss=0.049231 time: 14.801983
INFO:root:[Epoch 116] train=0.984254 val=0.917100 loss=0.048613 time: 14.998199
INFO:root:[Epoch 117] train=0.984697 val=0.917000 loss=0.046346 time: 14.790521
INFO:root:[Epoch 118] train=0.985764 val=0.917500 loss=0.044952 time: 14.490467
INFO:root:[Epoch 119] train=0.985986 val=0.917700 loss=0.043010 time: 14.725360
INFO:root:[Epoch 120] train=0.986268 val=0.916500 loss=0.042597 time: 14.846354
INFO:root:[Epoch 121] train=0.986751 val=0.916300 loss=0.040373 time: 14.923585
INFO:root:[Epoch 122] train=0.986328 val=0.915200 loss=0.042475 time: 14.838346
INFO:root:[Epoch 123] train=0.986892 val=0.918700 loss=0.039308 time: 14.885486
INFO:root:[Epoch 124] train=0.986912 val=0.914600 loss=0.039191 time: 14.938317
INFO:root:[Epoch 125] train=0.987375 val=0.918400 loss=0.038486 time: 15.248203
INFO:root:[Epoch 126] train=0.987717 val=0.916900 loss=0.037574 time: 14.689962
INFO:root:[Epoch 127] train=0.988483 val=0.916700 loss=0.036682 time: 14.784832
INFO:root:[Epoch 128] train=0.988946 val=0.915900 loss=0.034411 time: 14.580669
INFO:root:[Epoch 129] train=0.989046 val=0.916500 loss=0.034719 time: 14.503818
INFO:root:[Epoch 130] train=0.988704 val=0.915800 loss=0.034866 time: 14.720700
INFO:root:[Epoch 131] train=0.989067 val=0.917100 loss=0.034701 time: 14.831642
INFO:root:[Epoch 132] train=0.990275 val=0.915900 loss=0.031982 time: 14.423172
INFO:root:[Epoch 133] train=0.989731 val=0.914900 loss=0.032357 time: 14.745433
INFO:root:[Epoch 134] train=0.989328 val=0.915600 loss=0.032630 time: 15.016176
INFO:root:[Epoch 135] train=0.988885 val=0.916600 loss=0.033526 time: 15.140902
INFO:root:[Epoch 136] train=0.989167 val=0.913700 loss=0.032443 time: 14.781971
INFO:root:[Epoch 137] train=0.990194 val=0.914000 loss=0.030198 time: 14.984546
INFO:root:[Epoch 138] train=0.990818 val=0.913300 loss=0.030009 time: 15.242635
INFO:root:[Epoch 139] train=0.990315 val=0.914900 loss=0.029109 time: 14.976681
INFO:root:[Epoch 140] train=0.991362 val=0.913500 loss=0.027944 time: 14.879947
INFO:root:[Epoch 141] train=0.990959 val=0.917700 loss=0.029186 time: 15.066848
INFO:root:[Epoch 142] train=0.991000 val=0.916100 loss=0.027363 time: 15.286457
INFO:root:[Epoch 143] train=0.990899 val=0.915500 loss=0.028849 time: 14.861455
INFO:root:[Epoch 144] train=0.991644 val=0.913000 loss=0.026534 time: 14.996269
INFO:root:[Epoch 145] train=0.991865 val=0.916200 loss=0.026334 time: 14.898733
INFO:root:[Epoch 146] train=0.991604 val=0.913800 loss=0.026530 time: 14.960715
INFO:root:[Epoch 147] train=0.992409 val=0.915500 loss=0.025272 time: 14.764586
INFO:root:[Epoch 148] train=0.991684 val=0.916500 loss=0.025560 time: 14.889260
INFO:root:[Epoch 149] train=0.991765 val=0.910900 loss=0.025771 time: 14.983845
INFO:root:[Epoch 150] train=0.993295 val=0.916200 loss=0.022345 time: 14.482776
INFO:root:[Epoch 151] train=0.994765 val=0.917500 loss=0.018889 time: 14.672910
INFO:root:[Epoch 152] train=0.994805 val=0.916500 loss=0.018027 time: 14.990194
INFO:root:[Epoch 153] train=0.994423 val=0.917200 loss=0.018971 time: 15.226650
INFO:root:[Epoch 154] train=0.994825 val=0.916900 loss=0.018387 time: 15.144145
INFO:root:[Epoch 155] train=0.995006 val=0.915700 loss=0.018089 time: 15.282193
INFO:root:[Epoch 156] train=0.995973 val=0.917600 loss=0.016224 time: 14.699066
INFO:root:[Epoch 157] train=0.995993 val=0.917200 loss=0.015821 time: 15.610510
INFO:root:[Epoch 158] train=0.995913 val=0.918000 loss=0.015902 time: 14.730235
INFO:root:[Epoch 159] train=0.995711 val=0.917000 loss=0.016071 time: 14.765568
INFO:root:[Epoch 160] train=0.995268 val=0.918200 loss=0.016425 time: 15.162791
INFO:root:[Epoch 161] train=0.995892 val=0.918400 loss=0.016234 time: 14.837208
INFO:root:[Epoch 162] train=0.995973 val=0.919500 loss=0.015518 time: 14.928981
INFO:root:[Epoch 163] train=0.995993 val=0.917800 loss=0.015330 time: 14.533755
INFO:root:[Epoch 164] train=0.996134 val=0.918200 loss=0.015413 time: 14.540566
INFO:root:[Epoch 165] train=0.996013 val=0.917100 loss=0.015559 time: 15.023927
INFO:root:[Epoch 166] train=0.996134 val=0.919200 loss=0.014962 time: 14.927731
INFO:root:[Epoch 167] train=0.995993 val=0.918100 loss=0.015335 time: 14.817152
INFO:root:[Epoch 168] train=0.996174 val=0.918300 loss=0.014831 time: 14.865434
INFO:root:[Epoch 169] train=0.996194 val=0.918100 loss=0.014748 time: 15.008582
INFO:root:[Epoch 170] train=0.995711 val=0.919100 loss=0.015819 time: 14.963013
INFO:root:[Epoch 171] train=0.996315 val=0.918900 loss=0.014738 time: 14.911706
INFO:root:[Epoch 172] train=0.996416 val=0.919200 loss=0.015031 time: 14.742812
INFO:root:[Epoch 173] train=0.995913 val=0.918000 loss=0.015576 time: 14.564677
INFO:root:[Epoch 174] train=0.996033 val=0.918800 loss=0.015101 time: 14.841270
INFO:root:[Epoch 175] train=0.996315 val=0.918000 loss=0.014627 time: 14.802945
INFO:root:[Epoch 176] train=0.996537 val=0.919900 loss=0.014233 time: 15.197674
INFO:root:[Epoch 177] train=0.996335 val=0.918300 loss=0.013780 time: 14.641270
INFO:root:[Epoch 178] train=0.996315 val=0.918300 loss=0.014411 time: 15.143015
INFO:root:[Epoch 179] train=0.996396 val=0.918500 loss=0.014353 time: 14.857457
INFO:root:[Epoch 180] train=0.996758 val=0.917600 loss=0.013639 time: 15.022725
INFO:root:[Epoch 181] train=0.996517 val=0.918300 loss=0.014395 time: 15.200588
INFO:root:[Epoch 182] train=0.996416 val=0.918100 loss=0.013907 time: 15.567275
INFO:root:[Epoch 183] train=0.996476 val=0.919100 loss=0.014656 time: 15.178260
INFO:root:[Epoch 184] train=0.996637 val=0.917800 loss=0.013800 time: 15.321668
INFO:root:[Epoch 185] train=0.996919 val=0.918100 loss=0.013708 time: 15.246099
INFO:root:[Epoch 186] train=0.997000 val=0.917500 loss=0.012822 time: 15.049155
INFO:root:[Epoch 187] train=0.996839 val=0.917100 loss=0.013977 time: 14.646061
INFO:root:[Epoch 188] train=0.996899 val=0.918000 loss=0.013320 time: 14.782212
INFO:root:[Epoch 189] train=0.996416 val=0.917900 loss=0.013723 time: 15.041764
INFO:root:[Epoch 190] train=0.996899 val=0.918700 loss=0.013375 time: 15.371441
INFO:root:[Epoch 191] train=0.996476 val=0.917400 loss=0.013739 time: 14.854291
INFO:root:[Epoch 192] train=0.997201 val=0.918300 loss=0.012961 time: 14.573956
INFO:root:[Epoch 193] train=0.996476 val=0.916900 loss=0.014111 time: 14.890597
INFO:root:[Epoch 194] train=0.996859 val=0.916800 loss=0.013432 time: 14.635809
INFO:root:[Epoch 195] train=0.997101 val=0.917500 loss=0.012741 time: 15.172659
INFO:root:[Epoch 196] train=0.996899 val=0.918600 loss=0.012892 time: 14.872219
INFO:root:[Epoch 197] train=0.996919 val=0.918300 loss=0.012670 time: 14.908632
INFO:root:[Epoch 198] train=0.996879 val=0.917800 loss=0.013198 time: 14.934888
INFO:root:[Epoch 199] train=0.997040 val=0.917900 loss=0.012416 time: 14.626708
