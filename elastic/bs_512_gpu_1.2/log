INFO:root:Namespace(batch_size=512, drop_rate=0.0, gpus='3', last_gamma=False, lr=0.4, lr_decay=0.1, lr_decay_epoch='100,150', mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=200, num_workers=2, resume_from=None, save_dir='bs_512_gpu_1.2', save_period=10, save_plot_dir='bs_512_gpu_1.2', warmup_epochs=0, wd=0.0001)
[03:50:11] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.357885 val=0.393000 loss=1.718952 time: 17.062493 lr: 0.400000
INFO:root:[Epoch 1] train=0.582615 val=0.585500 loss=1.149989 time: 16.593492 lr: 0.400000
INFO:root:[Epoch 2] train=0.683433 val=0.663700 loss=0.889029 time: 16.535469 lr: 0.400000
INFO:root:[Epoch 3] train=0.742026 val=0.662600 loss=0.734171 time: 16.454533 lr: 0.400000
INFO:root:[Epoch 4] train=0.778189 val=0.715000 loss=0.637178 time: 16.646623 lr: 0.400000
INFO:root:[Epoch 5] train=0.798325 val=0.765600 loss=0.581587 time: 16.192258 lr: 0.400000
INFO:root:[Epoch 6] train=0.816447 val=0.789400 loss=0.532900 time: 16.173409 lr: 0.400000
INFO:root:[Epoch 7] train=0.828346 val=0.719500 loss=0.496307 time: 16.013312 lr: 0.400000
INFO:root:[Epoch 8] train=0.837085 val=0.765000 loss=0.469702 time: 16.479870 lr: 0.400000
INFO:root:[Epoch 9] train=0.845582 val=0.725500 loss=0.443105 time: 16.577812 lr: 0.400000
INFO:root:[Epoch 10] train=0.852871 val=0.803300 loss=0.426715 time: 16.149627 lr: 0.400000
INFO:root:[Epoch 11] train=0.859093 val=0.788400 loss=0.407061 time: 16.344349 lr: 0.400000
INFO:root:[Epoch 12] train=0.862254 val=0.773600 loss=0.394848 time: 16.611538 lr: 0.400000
INFO:root:[Epoch 13] train=0.869382 val=0.793200 loss=0.378881 time: 16.688052 lr: 0.400000
INFO:root:[Epoch 14] train=0.872624 val=0.784100 loss=0.366075 time: 16.503420 lr: 0.400000
INFO:root:[Epoch 15] train=0.875201 val=0.828800 loss=0.357657 time: 16.856740 lr: 0.400000
INFO:root:[Epoch 16] train=0.880839 val=0.818700 loss=0.346577 time: 17.081792 lr: 0.400000
INFO:root:[Epoch 17] train=0.880497 val=0.802300 loss=0.342350 time: 18.175525 lr: 0.400000
INFO:root:[Epoch 18] train=0.885027 val=0.809300 loss=0.330947 time: 18.348300 lr: 0.400000
INFO:root:[Epoch 19] train=0.886538 val=0.829700 loss=0.324217 time: 18.442908 lr: 0.400000
INFO:root:[Epoch 20] train=0.889618 val=0.840800 loss=0.316986 time: 18.969545 lr: 0.400000
INFO:root:[Epoch 21] train=0.892598 val=0.834200 loss=0.308639 time: 17.935271 lr: 0.400000
INFO:root:[Epoch 22] train=0.892941 val=0.828100 loss=0.306028 time: 17.999779 lr: 0.400000
INFO:root:[Epoch 23] train=0.897552 val=0.826100 loss=0.293789 time: 18.414987 lr: 0.400000
INFO:root:[Epoch 24] train=0.898840 val=0.812600 loss=0.288859 time: 18.078192 lr: 0.400000
INFO:root:[Epoch 25] train=0.897390 val=0.810000 loss=0.290403 time: 17.953107 lr: 0.400000
INFO:root:[Epoch 26] train=0.901216 val=0.822300 loss=0.282584 time: 17.803265 lr: 0.400000
INFO:root:[Epoch 27] train=0.901478 val=0.838300 loss=0.281961 time: 18.034070 lr: 0.400000
INFO:root:[Epoch 28] train=0.901397 val=0.851900 loss=0.280921 time: 18.268459 lr: 0.400000
INFO:root:[Epoch 29] train=0.905445 val=0.829700 loss=0.270870 time: 18.158353 lr: 0.400000
INFO:root:[Epoch 30] train=0.905666 val=0.858800 loss=0.267248 time: 17.944912 lr: 0.400000
INFO:root:[Epoch 31] train=0.905263 val=0.807300 loss=0.267507 time: 17.930561 lr: 0.400000
INFO:root:[Epoch 32] train=0.908666 val=0.854200 loss=0.261029 time: 18.059675 lr: 0.400000
INFO:root:[Epoch 33] train=0.908928 val=0.833800 loss=0.256830 time: 18.181068 lr: 0.400000
INFO:root:[Epoch 34] train=0.910680 val=0.845400 loss=0.255820 time: 17.794747 lr: 0.400000
INFO:root:[Epoch 35] train=0.911002 val=0.841700 loss=0.256924 time: 17.609907 lr: 0.400000
INFO:root:[Epoch 36] train=0.911405 val=0.846000 loss=0.254085 time: 18.210913 lr: 0.400000
INFO:root:[Epoch 37] train=0.913257 val=0.822700 loss=0.249193 time: 18.177943 lr: 0.400000
INFO:root:[Epoch 38] train=0.912190 val=0.834700 loss=0.250236 time: 17.843339 lr: 0.400000
INFO:root:[Epoch 39] train=0.915693 val=0.854600 loss=0.243591 time: 18.260085 lr: 0.400000
INFO:root:[Epoch 40] train=0.913720 val=0.854000 loss=0.245741 time: 17.925419 lr: 0.400000
INFO:root:[Epoch 41] train=0.915532 val=0.832000 loss=0.241659 time: 17.775176 lr: 0.400000
INFO:root:[Epoch 42] train=0.916076 val=0.859500 loss=0.238779 time: 18.572762 lr: 0.400000
INFO:root:[Epoch 43] train=0.914365 val=0.837300 loss=0.240829 time: 17.970367 lr: 0.400000
INFO:root:[Epoch 44] train=0.917043 val=0.815300 loss=0.237451 time: 17.959409 lr: 0.400000
INFO:root:[Epoch 45] train=0.918734 val=0.831300 loss=0.232561 time: 17.989861 lr: 0.400000
INFO:root:[Epoch 46] train=0.920184 val=0.866100 loss=0.225411 time: 18.000266 lr: 0.400000
INFO:root:[Epoch 47] train=0.916640 val=0.861500 loss=0.234070 time: 17.927921 lr: 0.400000
INFO:root:[Epoch 48] train=0.918835 val=0.853400 loss=0.226386 time: 17.912027 lr: 0.400000
INFO:root:[Epoch 49] train=0.920385 val=0.841700 loss=0.229419 time: 18.164210 lr: 0.400000
INFO:root:[Epoch 50] train=0.922358 val=0.834400 loss=0.224388 time: 17.988122 lr: 0.400000
INFO:root:[Epoch 51] train=0.919721 val=0.794300 loss=0.227256 time: 17.917839 lr: 0.400000
INFO:root:[Epoch 52] train=0.919157 val=0.865000 loss=0.228234 time: 17.916950 lr: 0.400000
INFO:root:[Epoch 53] train=0.922177 val=0.849200 loss=0.220495 time: 18.344547 lr: 0.400000
INFO:root:[Epoch 54] train=0.921875 val=0.825500 loss=0.222379 time: 18.125937 lr: 0.400000
INFO:root:[Epoch 55] train=0.924191 val=0.837500 loss=0.217565 time: 18.107073 lr: 0.400000
INFO:root:[Epoch 56] train=0.923828 val=0.859100 loss=0.219026 time: 18.084405 lr: 0.400000
INFO:root:[Epoch 57] train=0.923184 val=0.851700 loss=0.219486 time: 18.668026 lr: 0.400000
INFO:root:[Epoch 58] train=0.922620 val=0.863800 loss=0.220794 time: 18.131427 lr: 0.400000
INFO:root:[Epoch 59] train=0.923969 val=0.829300 loss=0.217357 time: 18.334148 lr: 0.400000
INFO:root:[Epoch 60] train=0.925338 val=0.861800 loss=0.212275 time: 18.130273 lr: 0.400000
INFO:root:[Epoch 61] train=0.923929 val=0.865500 loss=0.214686 time: 17.774364 lr: 0.400000
INFO:root:[Epoch 62] train=0.924029 val=0.842700 loss=0.213778 time: 17.725795 lr: 0.400000
INFO:root:[Epoch 63] train=0.925298 val=0.851700 loss=0.213112 time: 17.822670 lr: 0.400000
INFO:root:[Epoch 64] train=0.924915 val=0.817200 loss=0.212271 time: 17.853220 lr: 0.400000
INFO:root:[Epoch 65] train=0.924915 val=0.851500 loss=0.212864 time: 18.481782 lr: 0.400000
INFO:root:[Epoch 66] train=0.927231 val=0.854200 loss=0.206911 time: 18.012678 lr: 0.400000
INFO:root:[Epoch 67] train=0.926647 val=0.832300 loss=0.205999 time: 18.599744 lr: 0.400000
INFO:root:[Epoch 68] train=0.924976 val=0.845700 loss=0.212551 time: 18.126235 lr: 0.400000
INFO:root:[Epoch 69] train=0.926808 val=0.860700 loss=0.208797 time: 18.180412 lr: 0.400000
INFO:root:[Epoch 70] train=0.929345 val=0.859100 loss=0.202011 time: 18.249842 lr: 0.400000
INFO:root:[Epoch 71] train=0.925983 val=0.826800 loss=0.210248 time: 17.938487 lr: 0.400000
INFO:root:[Epoch 72] train=0.928540 val=0.857200 loss=0.202901 time: 18.072833 lr: 0.400000
INFO:root:[Epoch 73] train=0.929023 val=0.868900 loss=0.201434 time: 18.665138 lr: 0.400000
INFO:root:[Epoch 74] train=0.929587 val=0.781900 loss=0.201638 time: 18.233756 lr: 0.400000
INFO:root:[Epoch 75] train=0.925077 val=0.876500 loss=0.210595 time: 18.636676 lr: 0.400000
INFO:root:[Epoch 76] train=0.930573 val=0.863100 loss=0.199341 time: 17.803169 lr: 0.400000
INFO:root:[Epoch 77] train=0.927171 val=0.839600 loss=0.206208 time: 17.971331 lr: 0.400000
INFO:root:[Epoch 78] train=0.928439 val=0.851800 loss=0.205240 time: 18.116222 lr: 0.400000
INFO:root:[Epoch 79] train=0.930775 val=0.867100 loss=0.196359 time: 17.817253 lr: 0.400000
INFO:root:[Epoch 80] train=0.929768 val=0.842400 loss=0.198701 time: 18.211025 lr: 0.400000
INFO:root:[Epoch 81] train=0.927895 val=0.859400 loss=0.205247 time: 18.281502 lr: 0.400000
INFO:root:[Epoch 82] train=0.928540 val=0.849700 loss=0.199892 time: 18.061349 lr: 0.400000
INFO:root:[Epoch 83] train=0.931037 val=0.852100 loss=0.196701 time: 18.240804 lr: 0.400000
INFO:root:[Epoch 84] train=0.930271 val=0.856300 loss=0.195589 time: 18.075166 lr: 0.400000
INFO:root:[Epoch 85] train=0.929728 val=0.845700 loss=0.198942 time: 17.760676 lr: 0.400000
INFO:root:[Epoch 86] train=0.930875 val=0.850300 loss=0.198102 time: 18.160173 lr: 0.400000
INFO:root:[Epoch 87] train=0.932003 val=0.862500 loss=0.194307 time: 18.102465 lr: 0.400000
INFO:root:[Epoch 88] train=0.930372 val=0.846100 loss=0.195684 time: 18.326895 lr: 0.400000
INFO:root:[Epoch 89] train=0.930855 val=0.863600 loss=0.195973 time: 18.060253 lr: 0.400000
INFO:root:[Epoch 90] train=0.931419 val=0.840000 loss=0.193840 time: 18.457091 lr: 0.400000
INFO:root:[Epoch 91] train=0.931902 val=0.853500 loss=0.195399 time: 17.905869 lr: 0.400000
INFO:root:[Epoch 92] train=0.931379 val=0.853600 loss=0.193108 time: 18.000935 lr: 0.400000
INFO:root:[Epoch 93] train=0.930594 val=0.857900 loss=0.196303 time: 18.357774 lr: 0.400000
INFO:root:[Epoch 94] train=0.932990 val=0.866300 loss=0.190351 time: 18.306630 lr: 0.400000
INFO:root:[Epoch 95] train=0.931721 val=0.857200 loss=0.193128 time: 17.774753 lr: 0.400000
INFO:root:[Epoch 96] train=0.931218 val=0.856200 loss=0.194129 time: 18.111208 lr: 0.400000
INFO:root:[Epoch 97] train=0.932748 val=0.878100 loss=0.190697 time: 17.738821 lr: 0.400000
INFO:root:[Epoch 98] train=0.932204 val=0.863500 loss=0.192566 time: 18.158754 lr: 0.400000
INFO:root:[Epoch 99] train=0.933493 val=0.852500 loss=0.187870 time: 17.694495 lr: 0.400000
INFO:root:[Epoch 100] train=0.956387 val=0.910800 loss=0.126282 time: 18.402945 lr: 0.040000
INFO:root:[Epoch 101] train=0.968690 val=0.914700 loss=0.093276 time: 18.969566 lr: 0.040000
INFO:root:[Epoch 102] train=0.971992 val=0.914400 loss=0.081454 time: 18.267577 lr: 0.040000
INFO:root:[Epoch 103] train=0.974932 val=0.914600 loss=0.074465 time: 18.011423 lr: 0.040000
INFO:root:[Epoch 104] train=0.977912 val=0.914600 loss=0.067627 time: 18.038791 lr: 0.040000
INFO:root:[Epoch 105] train=0.977730 val=0.915900 loss=0.066448 time: 18.592500 lr: 0.040000
INFO:root:[Epoch 106] train=0.979643 val=0.915500 loss=0.062008 time: 18.159468 lr: 0.040000
INFO:root:[Epoch 107] train=0.980549 val=0.914200 loss=0.059467 time: 18.209570 lr: 0.040000
INFO:root:[Epoch 108] train=0.981596 val=0.915100 loss=0.056462 time: 18.114161 lr: 0.040000
INFO:root:[Epoch 109] train=0.983711 val=0.914200 loss=0.050701 time: 18.172824 lr: 0.040000
INFO:root:[Epoch 110] train=0.984254 val=0.910800 loss=0.050547 time: 17.763658 lr: 0.040000
INFO:root:[Epoch 111] train=0.984596 val=0.914300 loss=0.047946 time: 18.441491 lr: 0.040000
INFO:root:[Epoch 112] train=0.985140 val=0.914000 loss=0.046834 time: 18.224061 lr: 0.040000
INFO:root:[Epoch 113] train=0.985563 val=0.915600 loss=0.044543 time: 17.995811 lr: 0.040000
INFO:root:[Epoch 114] train=0.986972 val=0.915700 loss=0.041496 time: 18.513710 lr: 0.040000
INFO:root:[Epoch 115] train=0.986509 val=0.916100 loss=0.041716 time: 18.622746 lr: 0.040000
INFO:root:[Epoch 116] train=0.986952 val=0.915400 loss=0.040519 time: 18.566521 lr: 0.040000
INFO:root:[Epoch 117] train=0.987999 val=0.916000 loss=0.038173 time: 18.311031 lr: 0.040000
INFO:root:[Epoch 118] train=0.987476 val=0.915400 loss=0.038626 time: 18.155994 lr: 0.040000
INFO:root:[Epoch 119] train=0.988644 val=0.914900 loss=0.035648 time: 18.215155 lr: 0.040000
INFO:root:[Epoch 120] train=0.989409 val=0.916000 loss=0.034505 time: 18.311417 lr: 0.040000
INFO:root:[Epoch 121] train=0.989268 val=0.917100 loss=0.033841 time: 18.725414 lr: 0.040000
INFO:root:[Epoch 122] train=0.989409 val=0.914800 loss=0.034000 time: 18.015668 lr: 0.040000
INFO:root:[Epoch 123] train=0.988744 val=0.916900 loss=0.034653 time: 17.893054 lr: 0.040000
INFO:root:[Epoch 124] train=0.990657 val=0.916500 loss=0.031428 time: 18.038315 lr: 0.040000
INFO:root:[Epoch 125] train=0.990093 val=0.913700 loss=0.031567 time: 18.259357 lr: 0.040000
INFO:root:[Epoch 126] train=0.989711 val=0.911200 loss=0.031797 time: 18.286053 lr: 0.040000
INFO:root:[Epoch 127] train=0.990496 val=0.918100 loss=0.030753 time: 18.367636 lr: 0.040000
INFO:root:[Epoch 128] train=0.990758 val=0.914900 loss=0.029160 time: 17.868862 lr: 0.040000
INFO:root:[Epoch 129] train=0.990899 val=0.915300 loss=0.029675 time: 17.839690 lr: 0.040000
INFO:root:[Epoch 130] train=0.990697 val=0.913700 loss=0.029763 time: 18.367544 lr: 0.040000
INFO:root:[Epoch 131] train=0.990818 val=0.914000 loss=0.028675 time: 18.045139 lr: 0.040000
INFO:root:[Epoch 132] train=0.991181 val=0.916100 loss=0.028008 time: 17.768961 lr: 0.040000
INFO:root:[Epoch 133] train=0.991563 val=0.915900 loss=0.027411 time: 18.120993 lr: 0.040000
INFO:root:[Epoch 134] train=0.991684 val=0.914600 loss=0.026340 time: 18.015644 lr: 0.040000
INFO:root:[Epoch 135] train=0.992147 val=0.916300 loss=0.025106 time: 18.473738 lr: 0.040000
INFO:root:[Epoch 136] train=0.991704 val=0.910300 loss=0.025856 time: 18.029211 lr: 0.040000
INFO:root:[Epoch 137] train=0.992188 val=0.913000 loss=0.025504 time: 18.042714 lr: 0.040000
INFO:root:[Epoch 138] train=0.991765 val=0.916600 loss=0.025275 time: 18.055228 lr: 0.040000
INFO:root:[Epoch 139] train=0.992067 val=0.916600 loss=0.024392 time: 18.154344 lr: 0.040000
INFO:root:[Epoch 140] train=0.992832 val=0.915800 loss=0.023029 time: 18.019142 lr: 0.040000
INFO:root:[Epoch 141] train=0.992731 val=0.917400 loss=0.023470 time: 18.019417 lr: 0.040000
INFO:root:[Epoch 142] train=0.992610 val=0.913300 loss=0.024108 time: 18.119035 lr: 0.040000
INFO:root:[Epoch 143] train=0.991724 val=0.913800 loss=0.025331 time: 17.789807 lr: 0.040000
INFO:root:[Epoch 144] train=0.992469 val=0.914600 loss=0.023779 time: 18.062451 lr: 0.040000
INFO:root:[Epoch 145] train=0.993114 val=0.913500 loss=0.022535 time: 17.956630 lr: 0.040000
INFO:root:[Epoch 146] train=0.993516 val=0.913600 loss=0.022033 time: 17.745085 lr: 0.040000
INFO:root:[Epoch 147] train=0.993617 val=0.916800 loss=0.020848 time: 17.984233 lr: 0.040000
INFO:root:[Epoch 148] train=0.993537 val=0.915600 loss=0.021261 time: 18.071932 lr: 0.040000
INFO:root:[Epoch 149] train=0.993496 val=0.918100 loss=0.021798 time: 18.107269 lr: 0.040000
INFO:root:[Epoch 150] train=0.994241 val=0.918600 loss=0.018781 time: 18.416690 lr: 0.004000
INFO:root:[Epoch 151] train=0.995127 val=0.918800 loss=0.016912 time: 18.618318 lr: 0.004000
INFO:root:[Epoch 152] train=0.995329 val=0.918600 loss=0.016945 time: 17.917064 lr: 0.004000
INFO:root:[Epoch 153] train=0.995832 val=0.919100 loss=0.015734 time: 18.896045 lr: 0.004000
INFO:root:[Epoch 154] train=0.995953 val=0.918900 loss=0.014828 time: 18.207675 lr: 0.004000
INFO:root:[Epoch 155] train=0.996013 val=0.919200 loss=0.014790 time: 19.531225 lr: 0.004000
INFO:root:[Epoch 156] train=0.996215 val=0.918300 loss=0.014291 time: 18.322829 lr: 0.004000
INFO:root:[Epoch 157] train=0.996476 val=0.918800 loss=0.014231 time: 18.172697 lr: 0.004000
INFO:root:[Epoch 158] train=0.996738 val=0.918900 loss=0.013483 time: 18.440517 lr: 0.004000
INFO:root:[Epoch 159] train=0.996295 val=0.918400 loss=0.014448 time: 18.249738 lr: 0.004000
INFO:root:[Epoch 160] train=0.996678 val=0.920100 loss=0.013201 time: 18.542496 lr: 0.004000
INFO:root:[Epoch 161] train=0.996416 val=0.918700 loss=0.014149 time: 18.256333 lr: 0.004000
INFO:root:[Epoch 162] train=0.996637 val=0.918300 loss=0.013414 time: 18.152865 lr: 0.004000
INFO:root:[Epoch 163] train=0.996476 val=0.918500 loss=0.013894 time: 18.261616 lr: 0.004000
INFO:root:[Epoch 164] train=0.997040 val=0.918300 loss=0.012902 time: 17.957310 lr: 0.004000
INFO:root:[Epoch 165] train=0.996517 val=0.919200 loss=0.013428 time: 18.275221 lr: 0.004000
INFO:root:[Epoch 166] train=0.997362 val=0.918900 loss=0.012901 time: 18.023275 lr: 0.004000
INFO:root:[Epoch 167] train=0.997141 val=0.918300 loss=0.013379 time: 17.776592 lr: 0.004000
INFO:root:[Epoch 168] train=0.996819 val=0.919100 loss=0.012701 time: 18.192371 lr: 0.004000
INFO:root:[Epoch 169] train=0.996939 val=0.918200 loss=0.013048 time: 18.273842 lr: 0.004000
INFO:root:[Epoch 170] train=0.996456 val=0.918700 loss=0.013297 time: 18.336178 lr: 0.004000
INFO:root:[Epoch 171] train=0.996678 val=0.918800 loss=0.012663 time: 18.075372 lr: 0.004000
INFO:root:[Epoch 172] train=0.997101 val=0.918500 loss=0.012646 time: 18.095915 lr: 0.004000
INFO:root:[Epoch 173] train=0.997201 val=0.917900 loss=0.012657 time: 18.038344 lr: 0.004000
INFO:root:[Epoch 174] train=0.997221 val=0.918900 loss=0.012380 time: 17.977500 lr: 0.004000
INFO:root:[Epoch 175] train=0.996879 val=0.919300 loss=0.012377 time: 18.353565 lr: 0.004000
INFO:root:[Epoch 176] train=0.996496 val=0.918300 loss=0.012719 time: 18.283422 lr: 0.004000
INFO:root:[Epoch 177] train=0.997282 val=0.918300 loss=0.012049 time: 18.426304 lr: 0.004000
INFO:root:[Epoch 178] train=0.997201 val=0.919200 loss=0.012545 time: 18.069429 lr: 0.004000
INFO:root:[Epoch 179] train=0.997302 val=0.918000 loss=0.011628 time: 18.142280 lr: 0.004000
INFO:root:[Epoch 180] train=0.996939 val=0.918700 loss=0.012684 time: 18.748869 lr: 0.004000
INFO:root:[Epoch 181] train=0.997101 val=0.918200 loss=0.011879 time: 18.337788 lr: 0.004000
INFO:root:[Epoch 182] train=0.996758 val=0.917900 loss=0.012132 time: 18.367514 lr: 0.004000
INFO:root:[Epoch 183] train=0.997584 val=0.918300 loss=0.010980 time: 18.183449 lr: 0.004000
INFO:root:[Epoch 184] train=0.997020 val=0.918400 loss=0.012333 time: 17.473790 lr: 0.004000
INFO:root:[Epoch 185] train=0.997564 val=0.918800 loss=0.011551 time: 17.058276 lr: 0.004000
INFO:root:[Epoch 186] train=0.997684 val=0.918300 loss=0.011472 time: 17.437808 lr: 0.004000
INFO:root:[Epoch 187] train=0.997101 val=0.917800 loss=0.012410 time: 17.763109 lr: 0.004000
INFO:root:[Epoch 188] train=0.997282 val=0.917900 loss=0.011868 time: 17.539651 lr: 0.004000
INFO:root:[Epoch 189] train=0.997302 val=0.918100 loss=0.012273 time: 16.020489 lr: 0.004000
INFO:root:[Epoch 190] train=0.997463 val=0.917700 loss=0.011375 time: 16.907794 lr: 0.004000
INFO:root:[Epoch 191] train=0.997362 val=0.918300 loss=0.011679 time: 16.410402 lr: 0.004000
INFO:root:[Epoch 192] train=0.997543 val=0.918400 loss=0.010913 time: 16.768489 lr: 0.004000
INFO:root:[Epoch 193] train=0.997543 val=0.918500 loss=0.011308 time: 17.186108 lr: 0.004000
INFO:root:[Epoch 194] train=0.997443 val=0.918200 loss=0.011334 time: 16.754470 lr: 0.004000
INFO:root:[Epoch 195] train=0.997181 val=0.919700 loss=0.011835 time: 16.660261 lr: 0.004000
INFO:root:[Epoch 196] train=0.997382 val=0.918500 loss=0.011153 time: 17.314608 lr: 0.004000
INFO:root:[Epoch 197] train=0.997141 val=0.918100 loss=0.011531 time: 16.135519 lr: 0.004000
INFO:root:[Epoch 198] train=0.996899 val=0.917600 loss=0.011829 time: 15.656896 lr: 0.004000
INFO:root:[Epoch 199] train=0.997362 val=0.918400 loss=0.011693 time: 14.784097 lr: 0.004000
